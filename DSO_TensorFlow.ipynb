{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytest cython tensorflow numba sympy pandas scikit-learn click deap pathos seaborn progress tqdm commentjson PyYAML prettytable\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3P0JRu9_LPj",
        "outputId": "7116b57f-9c6c-4b1b-f4c6-3961b32a6083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathos\n",
            "  Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Collecting progress\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Collecting commentjson\n",
            "  Downloading commentjson-0.9.0.tar.gz (8.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Collecting ppft>=1.7.6.8 (from pathos)\n",
            "  Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.8 (from pathos)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.4 (from pathos)\n",
            "  Downloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.16 (from pathos)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Collecting lark-parser<0.8.0,>=0.7.1 (from commentjson)\n",
            "  Downloading lark-parser-0.7.8.tar.gz (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.2/276.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable) (0.2.13)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: progress, commentjson, lark-parser\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9614 sha256=53cc52ae141fec1dab25eff12bcdf7e8d8d7d406aba2a8b304628bd36a233063\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n",
            "  Building wheel for commentjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for commentjson: filename=commentjson-0.9.0-py3-none-any.whl size=12074 sha256=cef050bfa4a9abdefeb7401472000ea449944bf1edcf627550c9cb21ac04b764\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/90/23/6358a234ca5b4ec0866d447079b97fedf9883387d1d7d074e5\n",
            "  Building wheel for lark-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lark-parser: filename=lark_parser-0.7.8-py2.py3-none-any.whl size=62510 sha256=f2680fc25246608aa4ccc5a5e276aeac6ef1f1fe3ee5e66bb39bdc515ec965ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/30/94/33e8b58318aa05cb1842b365843036e0280af5983abb966b83\n",
            "Successfully built progress commentjson lark-parser\n",
            "Installing collected packages: progress, lark-parser, ppft, pox, dill, deap, commentjson, multiprocess, pathos\n",
            "Successfully installed commentjson-0.9.0 deap-1.4.1 dill-0.3.8 lark-parser-0.7.8 multiprocess-0.70.16 pathos-0.3.2 pox-0.3.4 ppft-1.7.6.8 progress-1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy.parsing.sympy_parser as sympy_parser\n",
        "import sympy\n",
        "\n",
        "from typing import Callable"
      ],
      "metadata": {
        "id": "2PBx86EG_dDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import copy\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "import importlib\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import sympy.parsing.sympy_parser as sympy_parser\n",
        "import sympy\n",
        "\n",
        "from typing import Callable"
      ],
      "metadata": {
        "id": "d95aIvHxBDp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utilsvs\n",
        "def preserve_global_rng_state(f: Callable):\n",
        "    \"\"\"\n",
        "    Decorator that saves the internal state of the global random number\n",
        "    generator before call to function and sets it back to that state\n",
        "    after the call\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    f : Callable\n",
        "        Function to decorate\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "    Callable\n",
        "        Decorated function that saves global random state and resets to it after\n",
        "    \"\"\"\n",
        "    @functools.wraps(f)\n",
        "    def decorated(*args, **kwargs):\n",
        "        rng_state = random.getstate()\n",
        "        result = f(*args, **kwargs)\n",
        "        random.setstate(rng_state)\n",
        "        return result\n",
        "    return decorated\n",
        "\n",
        "\n",
        "# We wrap the sympy functions with preserve_global_rng_state\n",
        "# as the sympy routines appear to non-deterministically\n",
        "# re-seed the global random generator which can influence GP results.\n",
        "# This problem seems to be resolved in sympy in commit\n",
        "# https://github.com/sympy/sympy/pull/22433\n",
        "# These functions should be used instead of the sympy functions directly\n",
        "pretty = preserve_global_rng_state(sympy.pretty)\n",
        "parse_expr = preserve_global_rng_state(sympy_parser.parse_expr)\n",
        "\n",
        "\n",
        "def is_float(s):\n",
        "    \"\"\"Determine whether the input variable can be cast to float.\"\"\"\n",
        "\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "# Adapted from: https://stackoverflow.com/questions/32791911/fast-calculation-of-pareto-front-in-python\n",
        "def is_pareto_efficient(costs):\n",
        "    \"\"\"\n",
        "    Find the pareto-efficient points given an array of costs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    costs : np.ndarray\n",
        "        Array of shape (n_points, n_costs).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    is_efficient_maek : np.ndarray (dtype:bool)\n",
        "        Array of which elements in costs are pareto-efficient.\n",
        "    \"\"\"\n",
        "\n",
        "    is_efficient = np.arange(costs.shape[0])\n",
        "    n_points = costs.shape[0]\n",
        "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
        "    while next_point_index<len(costs):\n",
        "        nondominated_point_mask = np.any(costs<costs[next_point_index], axis=1)\n",
        "        nondominated_point_mask[next_point_index] = True\n",
        "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
        "        costs = costs[nondominated_point_mask]\n",
        "        next_point_index = np.sum(nondominated_point_mask[:next_point_index])+1\n",
        "    is_efficient_mask = np.zeros(n_points, dtype=bool)\n",
        "    is_efficient_mask[is_efficient] = True\n",
        "    return is_efficient_mask\n",
        "\n",
        "\n",
        "class cached_property(object):\n",
        "    \"\"\"\n",
        "    Decorator used for lazy evaluation of an object attribute. The property\n",
        "    should be non-mutable, since it replaces itself.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, getter):\n",
        "        self.getter = getter\n",
        "\n",
        "        functools.update_wrapper(self, getter)\n",
        "\n",
        "    def __get__(self, obj, cls):\n",
        "        if obj is None:\n",
        "            return self\n",
        "\n",
        "        value = self.getter(obj)\n",
        "        setattr(obj, self.getter.__name__, value)\n",
        "        return value\n",
        "\n",
        "\n",
        "def weighted_quantile(values, weights, q):\n",
        "    \"\"\"\n",
        "    Computes the weighted quantile, equivalent to the exact quantile of the\n",
        "    empirical distribution.\n",
        "\n",
        "    Given ordered samples x_1 <= ... <= x_n, with corresponding weights w_1,\n",
        "    ..., w_n, where sum_i(w_i) = 1.0, the weighted quantile is the minimum x_i\n",
        "    for which the cumulative sum up to x_i is greater than or equal to 1.\n",
        "\n",
        "    Quantile = min{ x_i | x_1 + ... + x_i >= q }\n",
        "    \"\"\"\n",
        "\n",
        "    sorted_indices = np.argsort(values)\n",
        "    sorted_weights = weights[sorted_indices]\n",
        "    sorted_values = values[sorted_indices]\n",
        "    cum_sorted_weights = np.cumsum(sorted_weights)\n",
        "    i_quantile = np.argmax(cum_sorted_weights >= q)\n",
        "    quantile = sorted_values[i_quantile]\n",
        "\n",
        "    # NOTE: This implementation is equivalent to (but much faster than) the\n",
        "    # following:\n",
        "    # from scipy import stats\n",
        "    # empirical_dist = stats.rv_discrete(name='empirical_dist', values=(values, weights))\n",
        "    # quantile = empirical_dist.ppf(q)\n",
        "\n",
        "    return quantile\n",
        "\n",
        "\n",
        "# Entropy computation in batch\n",
        "def empirical_entropy(labels):\n",
        "\n",
        "    n_labels = len(labels)\n",
        "\n",
        "    if n_labels <= 1:\n",
        "        return 0\n",
        "\n",
        "    value,counts = np.unique(labels, return_counts=True)\n",
        "    probs = counts / n_labels\n",
        "    n_classes = np.count_nonzero(probs)\n",
        "\n",
        "    if n_classes <= 1:\n",
        "        return 0\n",
        "\n",
        "    ent = 0.\n",
        "    # Compute entropy\n",
        "    for i in probs:\n",
        "        ent -= i * np.log(i)\n",
        "\n",
        "    return np.array(ent, dtype=np.float32)\n",
        "\n",
        "\n",
        "def get_duration(start_time):\n",
        "    return get_human_readable_time(time.time() - start_time)\n",
        "\n",
        "\n",
        "def get_human_readable_time(s):\n",
        "    m, s = divmod(s, 60)\n",
        "    h, m = divmod(m, 60)\n",
        "    d, h = divmod(h, 24)\n",
        "    return \"{:02d}:{:02d}:{:02d}:{:05.2f}\".format(int(d), int(h), int(m), s)\n",
        "\n",
        "\n",
        "def safe_merge_dicts(base_dict, update_dict):\n",
        "    \"\"\"Merges two dictionaries without changing the source dictionaries.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        base_dict : dict\n",
        "            Source dictionary with initial values.\n",
        "        update_dict : dict\n",
        "            Dictionary with changed values to update the base dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        new_dict : dict\n",
        "            Dictionary containing values from the merged dictionaries.\n",
        "    \"\"\"\n",
        "    if base_dict is None:\n",
        "        return update_dict\n",
        "    base_dict = copy.deepcopy(base_dict)\n",
        "    for key, value in update_dict.items():\n",
        "        if isinstance(value, collections.Mapping):\n",
        "            base_dict[key] = safe_merge_dicts(base_dict.get(key, {}), value)\n",
        "        else:\n",
        "            base_dict[key] = value\n",
        "    return base_dict\n",
        "\n",
        "\n",
        "def safe_update_summary(csv_path, new_data):\n",
        "    \"\"\"Updates a summary csv file with new rows. Adds new columns\n",
        "    in existing data if necessary. New rows are distinguished by\n",
        "    the run seed.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        csv_path : str\n",
        "            String with the path to the csv file.\n",
        "        new_data : dict\n",
        "            Dictionary containing values to be saved in the csv file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        bool\n",
        "            Boolean value to indicate if saving the data to file worked.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        new_data_pd = pd.DataFrame(new_data, index=[0])\n",
        "        new_data_pd.set_index('seed', inplace=True)\n",
        "        if os.path.isfile(csv_path):\n",
        "            old_data_pd = pd.read_csv(csv_path)\n",
        "            old_data_pd.set_index('seed', inplace=True)\n",
        "            merged_df = pd.concat([old_data_pd, new_data_pd], axis=0, ignore_index=False)\n",
        "            merged_df.to_csv(csv_path, header=True, mode='w+', index=True)\n",
        "        else:\n",
        "            new_data_pd.to_csv(csv_path, header=True, mode='w+', index=True)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "\n",
        "def import_custom_source(import_source):\n",
        "    \"\"\"\n",
        "    Provides a way to import custom modules. The return will be a reference to the desired source\n",
        "    Parameters\n",
        "    ----------\n",
        "        import_source : import path\n",
        "            Source to import from, for most purposes: <module_name>:<class or function name>\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        mod : ref\n",
        "            reference to the imported module\n",
        "    \"\"\"\n",
        "\n",
        "    # Partially validates if the import_source is in correct format\n",
        "    regex = '[\\w._]+:[\\w._]+' #lib_name:class_name\n",
        "    m = re.match(pattern=regex, string=import_source)\n",
        "    # Partial matches mean that the import will fail\n",
        "    assert m is not None and m.end() == len(import_source), \"*** Failed to import malformed source string: \"+import_source\n",
        "\n",
        "    source, type = import_source.split(':')\n",
        "\n",
        "    # Dynamically imports the configured source\n",
        "    mod = importlib.import_module(source)\n",
        "    func = getattr(mod, type)\n",
        "\n",
        "    return func\n",
        "\n",
        "def pad_action_obs_priors(actions, obs, priors, pad_length):\n",
        "    \"\"\"\n",
        "    Will pad action, obs, priors with zeros.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        actions : np array\n",
        "            Standard actions array of tokens\n",
        "        obs : np array\n",
        "            Standard observations array\n",
        "        priors : np array\n",
        "            Standard priors array\n",
        "        pdd_length : int\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        actions : np array\n",
        "            Standard actions array of tokens padded with zeros at the end columns\n",
        "        obs : np array\n",
        "            Standard observations array padded with zeros at the end columns\n",
        "        priors : np array\n",
        "            Standard priors array padded with zeros at the end columns\n",
        "    \"\"\"\n",
        "    assert isinstance(pad_length,int)\n",
        "    assert pad_length >= 0\n",
        "\n",
        "    actions = np.pad(actions, ((0,0),(0,pad_length)), 'constant', constant_values=((0,0),(0,0)))\n",
        "    obs = [ np.pad(o, ((0,0),(0,pad_length)), 'constant', constant_values=((0,0),(0,0))) for o in obs ]\n",
        "    priors = np.pad(priors, ((0,0),(0,pad_length),(0,0)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
        "\n",
        "    return actions, obs, priors\n",
        "\n",
        "\n",
        "def make_batch_ph(name : str, n_choices : int):\n",
        "    \"\"\"\n",
        "    Generates dictionary containing placeholders needed for a batch of sequences.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        names : str\n",
        "            Name of tensorflow scope for this batch\n",
        "\n",
        "        n_choices : int\n",
        "            Number of choices in priors\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        batch_ph : dict\n",
        "            Dictionary of placeholders\n",
        "    \"\"\"\n",
        "\n",
        "    # Lazy import\n",
        "    import tensorflow as tf\n",
        "    from dso.memory import Batch\n",
        "    from dso.program import Program\n",
        "\n",
        "    with tf.name_scope(name):\n",
        "        batch_ph = {\n",
        "            \"actions\": tf.placeholder(tf.int32, [None, None]),\n",
        "            \"obs\": tf.placeholder(tf.float32, [None, Program.task.OBS_DIM, None]),\n",
        "            \"priors\": tf.placeholder(tf.float32, [None, None, n_choices]),\n",
        "            \"lengths\": tf.placeholder(tf.int32, [None, ]),\n",
        "            \"rewards\": tf.placeholder(tf.float32, [None], name=\"r\"),\n",
        "            \"on_policy\": tf.placeholder(tf.int32, [None, ])\n",
        "         }\n",
        "        batch_ph = Batch(**batch_ph)\n",
        "    return batch_ph"
      ],
      "metadata": {
        "id": "9ufYImE4ApAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Iy_PbthOEc6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#library\n",
        "class Token():\n",
        "    \"\"\"\n",
        "    An arbitrary token or \"building block\" of a Program object.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    name : str\n",
        "        Name of token.\n",
        "\n",
        "    arity : int\n",
        "        Arity (number of arguments) of token.\n",
        "\n",
        "    complexity : float\n",
        "        Complexity of token.\n",
        "\n",
        "    function : callable\n",
        "        Function associated with the token; used for exectuable Programs.\n",
        "\n",
        "    input_var : int or None\n",
        "        Index of input if this Token is an input variable, otherwise None.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __call__(input)\n",
        "        Call the Token's function according to input.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, function, name, arity, complexity, input_var=None):\n",
        "        self.function = function\n",
        "        self.name = name\n",
        "        self.arity = arity\n",
        "        self.complexity = complexity\n",
        "        self.input_var = input_var\n",
        "\n",
        "        if input_var is not None:\n",
        "            assert function is None, \"Input variables should not have functions.\"\n",
        "            assert arity == 0, \"Input variables should have arity zero.\"\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        assert self.function is not None, \\\n",
        "            \"Token {} is not callable.\".format(self.name)\n",
        "\n",
        "        return self.function(*args)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.name\n",
        "\n",
        "\n",
        "class HardCodedConstant(Token):\n",
        "    \"\"\"\n",
        "    A Token with a \"value\" attribute, whose function returns the value.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    value : float\n",
        "        Value of the constant.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, value=None, name=None):\n",
        "        assert value is not None, \"Constant is not callable with value None. Must provide a floating point number or string of a float.\"\n",
        "        assert U.is_float(value)\n",
        "        value = np.atleast_1d(np.float32(value))\n",
        "        self.value = value\n",
        "        if name is None:\n",
        "            name = str(self.value[0])\n",
        "        super().__init__(function=self.function, name=name, arity=0, complexity=1)\n",
        "\n",
        "    def function(self):\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class PlaceholderConstant(Token):\n",
        "    \"\"\"\n",
        "    A Token for placeholder constants that will be optimized with respect to\n",
        "    the reward function. The function simply returns the \"value\" attribute.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    value : float or None\n",
        "        Current value of the constant, or None if not yet set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, value=None):\n",
        "        if value is not None:\n",
        "            value = np.atleast_1d(value)\n",
        "        self.value = value\n",
        "        super().__init__(function=self.function, name=\"const\", arity=0, complexity=1)\n",
        "\n",
        "    def function(self):\n",
        "        assert self.value is not None, \\\n",
        "            \"Constant is not callable with value None.\"\n",
        "        return self.value\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.value is None:\n",
        "            return self.name\n",
        "        return str(self.value[0])\n",
        "\n",
        "\n",
        "class Polynomial(Token):\n",
        "    \"\"\"\n",
        "    A Token representing a polynomial of the input variables of the form:\n",
        "        p(x1, ..., xn) = c1 * x1**e11 * ... * xn**e1n + ... + cm * x1**em1 * ... * xn**emn.\n",
        "    Note that only the terms with a nonzero coefficient are stored.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    exponents : list of tuples of nonnegative integers\n",
        "        Exponents of the nonzero terms [(e11, ..., e1n), ..., (em1, ..., emn)].\n",
        "    coef : list of float\n",
        "        A list of coefficients [c1, c2, ..., cm] corresponding to the terms in exponents.\n",
        "    \"\"\"\n",
        "    def __init__(self, exponents=None, coef=None):\n",
        "        self.exponents = exponents\n",
        "        self.coef = coef\n",
        "        complexity = 1 if coef is None else len(coef)\n",
        "        super().__init__(self.eval_poly, \"poly\", arity=0, complexity=complexity)\n",
        "\n",
        "    @staticmethod\n",
        "    def eval_monomials(X, monomials_exponents):\n",
        "        \"\"\"\n",
        "        Compute the monomials x1**ej1 * ... * xn**ejn for each data point [x1, ..., xn] in X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray\n",
        "            A dataset of shape (number of points, number of variables).\n",
        "        monomials_exponents : list of tuples of nonnegative integers\n",
        "            Exponents of the monomials to be computed: [(e11, ..., e1n), ..., (em1, ..., emn)].\n",
        "        \"\"\"\n",
        "        monomials = np.ones(shape=(X.shape[0], len(monomials_exponents)))\n",
        "        for basis_count, exponents in enumerate(monomials_exponents):\n",
        "            for i in range(len(exponents)):\n",
        "                if exponents[i] != 0:\n",
        "                    monomials[:, basis_count] *= X[:, i] ** exponents[i]\n",
        "        return monomials\n",
        "\n",
        "    def eval_poly(self, X):\n",
        "        assert self.exponents is not None and self.coef is not None\n",
        "        if len(self.coef) == 0:\n",
        "            return np.zeros(shape=(X.shape[0], 1))\n",
        "        return np.dot(self.eval_monomials(X, self.exponents), self.coef)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.exponents is None and self.coef is None:\n",
        "            return self.name\n",
        "\n",
        "        if len(self.coef) == 0:\n",
        "            return \"0.0\"\n",
        "\n",
        "        assert len(self.exponents) == self.coef.shape[0]\n",
        "        names = [\"-\" if self.coef[0] < 0 else \"\"]\n",
        "        for basis_count, exponents in enumerate(self.exponents):\n",
        "            basis_name = [str(format(np.abs(self.coef[basis_count]), '.6'))]\n",
        "            for i in range(len(exponents)):\n",
        "                if exponents[i] == 1:\n",
        "                    basis_name.append(\"x{}\".format(i + 1))\n",
        "                elif exponents[i] > 1:\n",
        "                    basis_name.append(\"x{}**{}\".format(i + 1, int(exponents[i])))\n",
        "            names.append(\"*\".join(basis_name))\n",
        "            if basis_count < len(self.coef) - 1:\n",
        "                names.append(\"-\" if self.coef[basis_count + 1] < 0 else \"+\")\n",
        "        return \"\".join(names)\n",
        "\n",
        "    def to_str_tokens(self):\n",
        "        \"\"\"\n",
        "        Return a list of tokens of add, mul, inputs, and constants that\n",
        "        is equivalent to this poly token.\n",
        "        \"\"\"\n",
        "        if self.exponents is None and self.coef is None:\n",
        "            return []\n",
        "\n",
        "        assert len(self.exponents) == self.coef.shape[0]\n",
        "        out = [] if len(self.coef) == 0 else [\"add\"]*(len(self.coef)-1)\n",
        "        for n, exponents in enumerate(self.exponents):\n",
        "            out.extend([\"mul\"]*np.count_nonzero(exponents))\n",
        "            for i in range(len(exponents)):\n",
        "                if exponents[i] >= 1:\n",
        "                    out.extend([\"mul\"]*(exponents[i]-1))\n",
        "                    out.extend([\"x{}\".format(i + 1)]*exponents[i])\n",
        "            out.append(self.coef[n])\n",
        "        return out\n",
        "\n",
        "\n",
        "class StateChecker(Token):\n",
        "    \"\"\"\n",
        "    A Token for making decisions in decision trees. Given the i-th state\n",
        "    variable xi and a threshold tj, the associated function is:\n",
        "        xi_<_tj(f, g) = f if xi < tj else g.\n",
        "    Here, the index i is indicated by state_index in __init__.\n",
        "\n",
        "    Note that:\n",
        "        1. The arity of StateChecker is 2, so subroutines designed for Tokens\n",
        "           of arity <= 2 can also be applied to StateChecker.\n",
        "        2. If StateCheckers are included in the library, it is recommended to\n",
        "           turn on the StateCheckerConstraint, which prevents sampling of\n",
        "           Tokens that lead to degenerate situations like \"checking if xi < 6\n",
        "           when we know xi < 3\".\n",
        "        3. When a StateChecker is initialized, state_value (the value of xi)\n",
        "           is unknown. In order to evaluate the return value of the associated\n",
        "           function, state_value needs to be set before the evaluation\n",
        "           (typically during the execution of a Program). See cyfunc.pyx for\n",
        "           an example usage.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    state_index : int\n",
        "        Index of the state variable associated with the token.\n",
        "\n",
        "    threshold : float\n",
        "        Value to which the state variable is compared when making decisions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, state_index, threshold):\n",
        "        assert threshold is not None, \\\n",
        "                \"StateChecker requires a float value for threshold.\"\n",
        "        self.state_index = state_index\n",
        "        self.state_value = None\n",
        "        self.threshold = threshold\n",
        "\n",
        "        name = \"x{} < {}\".format(state_index + 1, self.threshold)\n",
        "        super().__init__(function=self.function, name=name, arity=2, complexity=1)\n",
        "\n",
        "    def set_state_value(self, state_value):\n",
        "        self.state_value = state_value\n",
        "\n",
        "    def function(self, value_if_true, value_if_false):\n",
        "        assert self.state_value is not None, \"StateChecker.state_value has not been set.\"\n",
        "        return np.where(np.less(self.state_value, self.threshold), value_if_true, value_if_false)\n",
        "\n",
        "\n",
        "class DiscreteAction(HardCodedConstant):\n",
        "    \"\"\"\n",
        "    This class is intended to be used for learning decision tree policies when\n",
        "    the env of the control problem has a Discrete action space.\n",
        "    Discrete action a_i corresponds to constant value i-1, i = 1, 2, 3, ...\n",
        "    \"\"\"\n",
        "    def __init__(self, value):\n",
        "        assert isinstance(value, int) and value >= 0\n",
        "        super().__init__(value, \"a_{}\".format(value+1))\n",
        "\n",
        "\n",
        "class MultiDiscreteAction(Token):\n",
        "    \"\"\"\n",
        "    This class is intended to be used for learning decision tree policies when\n",
        "    the env of the control problem has a MultiDiscrete action space.\n",
        "\n",
        "    Tokens in this class are ai_j (unary) and STOP (terminal). When executed:\n",
        "        - ai_j returns an array that sets the (i-1)-th value of input to j-1.\n",
        "        - STOP returns an array of default actions of all dimensions.\n",
        "    For example, supposed the default actions are set to be [2, 1, 0].\n",
        "    The traversal [a1_2, STOP] corresponds to the constant action [1, 1, 0],\n",
        "    while the traversal [a1_3, a3_3, a2_1, STOP] corresponds to [2, 0, 2].\n",
        "    \"\"\"\n",
        "    n_dims = None # total number of action dimensions\n",
        "    def __init__(self, value, action_dim=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        value : int or list of int\n",
        "            If action_dim is not None, the token corresponds to the value-th\n",
        "            discrete action in action dimension action_dim.\n",
        "            Otherwise, it is a list of integers specifying the default discrete\n",
        "            actions of all action dimensions.\n",
        "\n",
        "        action_dim : int or None\n",
        "            Action dimension. If None, the STOP token will be constructed.\n",
        "        \"\"\"\n",
        "        self.value = value\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        if action_dim is None:\n",
        "            assert isinstance(self.value, list)\n",
        "            MultiDiscreteAction.n_dims = len(self.value)\n",
        "            self.value = np.array(self.value)\n",
        "            name = \"STOP\"\n",
        "            super().__init__(function=self.apply_action, name=name, arity=0, complexity=1)\n",
        "        else:\n",
        "            assert isinstance(value, int) and value >= 0\n",
        "            name = \"a{}_{}\".format(action_dim+1, value+1)\n",
        "            super().__init__(function=self.apply_action, name=name, arity=1, complexity=1)\n",
        "\n",
        "    def apply_action(self, *args):\n",
        "        if self.action_dim is None:\n",
        "            return np.array([self.value.copy()])\n",
        "        else:\n",
        "            args[0][0, self.action_dim] = self.value\n",
        "            return args[0]\n",
        "\n",
        "\n",
        "class Library():\n",
        "    \"\"\"\n",
        "    Library of Tokens. We use a list of Tokens (instead of set or dict) since\n",
        "    we so often index by integers given by the Controller.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    tokens : list of Token\n",
        "        List of available Tokens in the library.\n",
        "\n",
        "    names : list of str\n",
        "        Names corresponding to Tokens in the library.\n",
        "\n",
        "    arities : list of int\n",
        "        Arities corresponding to Tokens in the library.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokens):\n",
        "\n",
        "        self.tokens = tokens\n",
        "        self.L = len(tokens)\n",
        "        self.names = [t.name for t in tokens]\n",
        "        self.arities = np.array([t.arity for t in tokens], dtype=np.int32)\n",
        "\n",
        "        self.input_tokens = np.array(\n",
        "            [i for i, t in enumerate(self.tokens) if t.input_var is not None],\n",
        "            dtype=np.int32)\n",
        "\n",
        "        self.state_checker_tokens = np.array(\n",
        "            [i for i, t in enumerate(self.tokens) if isinstance(t, StateChecker)],\n",
        "            dtype=np.int32)\n",
        "\n",
        "        self.multi_discrete_tokens = np.array(\n",
        "            [i for i, t in enumerate(self.tokens) if isinstance(t, MultiDiscreteAction)],\n",
        "            dtype=np.int32)\n",
        "\n",
        "        def get_tokens_of_arity(arity):\n",
        "            _tokens = [i for i in range(self.L) if self.arities[i] == arity]\n",
        "            return np.array(_tokens, dtype=np.int32)\n",
        "\n",
        "        self.tokens_of_arity = defaultdict(lambda : np.array([], dtype=np.int32))\n",
        "        for arity in self.arities:\n",
        "            self.tokens_of_arity[arity] = get_tokens_of_arity(arity)\n",
        "        self.terminal_tokens = self.tokens_of_arity[0]\n",
        "        self.unary_tokens = self.tokens_of_arity[1]\n",
        "        self.binary_tokens = self.tokens_of_arity[2]\n",
        "\n",
        "        try:\n",
        "            self.const_token = self.names.index(\"const\")\n",
        "        except ValueError:\n",
        "            self.const_token = None\n",
        "        try:\n",
        "            self.poly_token = self.names.index(\"poly\")\n",
        "        except ValueError:\n",
        "            self.poly_token = None\n",
        "        self.parent_adjust = np.full_like(self.arities, -1)\n",
        "        count = 0\n",
        "        for i in range(len(self.arities)):\n",
        "            if self.arities[i] > 0:\n",
        "                self.parent_adjust[i] = count\n",
        "                count += 1\n",
        "\n",
        "        trig_names = [\"sin\", \"cos\", \"tan\", \"csc\", \"sec\", \"cot\"]\n",
        "        trig_names += [\"arc\" + name for name in trig_names]\n",
        "\n",
        "        self.float_tokens = np.array(\n",
        "            [i for i, t in enumerate(self.tokens) if t.arity == 0 and t.input_var is None],\n",
        "            dtype=np.int32)\n",
        "        self.trig_tokens = np.array(\n",
        "            [i for i, t in enumerate(self.tokens) if t.name in trig_names],\n",
        "            dtype=np.int32)\n",
        "\n",
        "        inverse_tokens = {\n",
        "            \"inv\" : \"inv\",\n",
        "            \"neg\" : \"neg\",\n",
        "            \"exp\" : \"log\",\n",
        "            \"log\" : \"exp\",\n",
        "            \"sqrt\" : \"n2\",\n",
        "            \"n2\" : \"sqrt\"\n",
        "        }\n",
        "        token_from_name = {t.name : i for i, t in enumerate(self.tokens)}\n",
        "        self.inverse_tokens = {token_from_name[k] : token_from_name[v] for k, v in inverse_tokens.items() if k in token_from_name and v in token_from_name}\n",
        "\n",
        "        self.n_action_inputs = self.L + 1 # Library tokens + empty token\n",
        "        self.n_parent_inputs = self.L + 1 - len(self.terminal_tokens) # Parent sub-lib tokens + empty token\n",
        "        self.n_sibling_inputs = self.L + 1 # Library tokens + empty token\n",
        "        self.n_input_tokens = len(self.input_tokens)\n",
        "        self.EMPTY_ACTION = self.n_action_inputs - 1\n",
        "        self.EMPTY_PARENT = self.n_parent_inputs - 1\n",
        "        self.EMPTY_SIBLING = self.n_sibling_inputs - 1\n",
        "\n",
        "    def __getitem__(self, val):\n",
        "        \"\"\"Shortcut to get Token by name or index.\"\"\"\n",
        "\n",
        "        if isinstance(val, str):\n",
        "            try:\n",
        "                i = self.names.index(val)\n",
        "            except ValueError:\n",
        "                raise TokenNotFoundError(\"Token {} does not exist.\".format(val))\n",
        "        elif isinstance(val, (int, np.integer)):\n",
        "            i = val\n",
        "        else:\n",
        "            raise TokenNotFoundError(\"Library must be indexed by str or int, not {}.\".format(type(val)))\n",
        "\n",
        "        try:\n",
        "            token = self.tokens[i]\n",
        "        except IndexError:\n",
        "            raise TokenNotFoundError(\"Token index {} does not exist\".format(i))\n",
        "        return token\n",
        "\n",
        "    def tokenize(self, inputs):\n",
        "        \"\"\"Convert inputs to list of Tokens.\"\"\"\n",
        "\n",
        "        # TBD non-list should return non-list\n",
        "\n",
        "        if isinstance(inputs, str):\n",
        "            inputs = inputs.split(',')\n",
        "        elif not isinstance(inputs, list) and not isinstance(inputs, np.ndarray): # TBD FIX HACK\n",
        "            inputs = [inputs]\n",
        "        tokens = [input_ if isinstance(input_, Token) else self[input_] for input_ in inputs]\n",
        "        return tokens\n",
        "\n",
        "    def actionize(self, inputs):\n",
        "        \"\"\"Convert inputs to array of 'actions', i.e. ints corresponding to\n",
        "        Tokens in the Library.\"\"\"\n",
        "\n",
        "        tokens = self.tokenize(inputs)\n",
        "        actions = np.array([self.tokens.index(t) for t in tokens],\n",
        "                           dtype=np.int32)\n",
        "        return actions\n",
        "\n",
        "\n",
        "class TokenNotFoundError(Exception):\n",
        "    pass"
      ],
      "metadata": {
        "id": "UQ0L9LUAEeCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize"
      ],
      "metadata": {
        "id": "u0u0qv3iEofE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#const\n",
        "def make_const_optimizer(name, **kwargs):\n",
        "    \"\"\"Returns a ConstOptimizer given a name and keyword arguments\"\"\"\n",
        "\n",
        "    const_optimizers = {\n",
        "        None : Dummy,\n",
        "        \"dummy\" : Dummy,\n",
        "        \"scipy\" : ScipyMinimize,\n",
        "    }\n",
        "\n",
        "    return const_optimizers[name](**kwargs)\n",
        "\n",
        "\n",
        "class ConstOptimizer(object):\n",
        "    \"\"\"Base class for constant optimizer\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "\n",
        "    def __call__(self, f, x0):\n",
        "        \"\"\"\n",
        "        Optimizes an objective function from an initial guess.\n",
        "\n",
        "        The objective function is the negative of the base reward (reward\n",
        "        without penalty) used for training. Optimization excludes any penalties\n",
        "        because they are constant w.r.t. to the constants being optimized.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        f : function mapping np.ndarray to float\n",
        "            Objective function (negative base reward).\n",
        "\n",
        "        x0 : np.ndarray\n",
        "            Initial guess for constant placeholders.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x : np.ndarray\n",
        "            Vector of optimized constants.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class Dummy(ConstOptimizer):\n",
        "    \"\"\"Dummy class that selects the initial guess for each constant\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Dummy, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def __call__(self, f, x0):\n",
        "        return x0\n",
        "\n",
        "\n",
        "class ScipyMinimize(ConstOptimizer):\n",
        "    \"\"\"SciPy's non-linear optimizer\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ScipyMinimize, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def __call__(self, f, x0):\n",
        "        with np.errstate(divide='ignore'):\n",
        "            opt_result = partial(minimize, **self.kwargs)(f, x0)\n",
        "        x = opt_result['x']\n",
        "        return x"
      ],
      "metadata": {
        "id": "ltfdpIeIE5Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from textwrap import indent"
      ],
      "metadata": {
        "id": "8ZGyyQaiFSDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#program\n",
        "def _finish_tokens(tokens):\n",
        "\n",
        "    \"\"\"\n",
        "    Complete a possibly unfinished string of tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tokens : list of integers\n",
        "        A list of integers corresponding to tokens in the library. The list\n",
        "        defines an expression's pre-order traversal.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "    tokens : list of ints\n",
        "        A list of integers corresponding to tokens in the library. The list\n",
        "        defines an expression's pre-order traversal. \"Dangling\" programs are\n",
        "        completed with repeated \"x1\" until the expression completes.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if Program.task.task_type == \"binding\":\n",
        "        return tokens\n",
        "\n",
        "    arities = np.array([Program.library.arities[t] for t in tokens])\n",
        "    # Number of dangling nodes, returns the cumsum up to each point\n",
        "    # Note that terminal nodes are -1 while functions will be >= 0 since arities - 1\n",
        "    dangling = 1 + np.cumsum(arities - 1)\n",
        "\n",
        "    if -1 in (dangling - 1):\n",
        "        # chop off tokens once the cumsum reaches 0, this is the last valid point in the tokens\n",
        "        expr_length = 1 + np.argmax((dangling - 1) == -1)\n",
        "        tokens = tokens[:expr_length]\n",
        "    else:\n",
        "        # Extend with valid variables until string is valid\n",
        "        # NOTE: This only appends onto the end of a set of tokens, even in the multi-object case!\n",
        "        if Program.task.task_type != 'binding':\n",
        "            tokens = np.append(tokens, np.random.choice(Program.library.input_tokens, size=dangling[-1]))\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def from_str_tokens(str_tokens, skip_cache=False):\n",
        "    \"\"\"\n",
        "    Memoized function to generate a Program from a list of str and/or float.\n",
        "    See from_tokens() for details.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    str_tokens : str | list of (str | float)\n",
        "        Either a comma-separated string of tokens and/or floats, or a list of\n",
        "        str and/or floats.\n",
        "\n",
        "    skip_cache : bool\n",
        "        See from_tokens().\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    program : Program\n",
        "        See from_tokens().\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert str to list of str\n",
        "    if isinstance(str_tokens, str):\n",
        "        str_tokens = str_tokens.split(\",\")\n",
        "\n",
        "    # Convert list of str|float to list of tokens\n",
        "    if isinstance(str_tokens, list):\n",
        "        traversal = []\n",
        "        constants = []\n",
        "        for s in str_tokens:\n",
        "            if s in Program.library.names:\n",
        "                t = Program.library.names.index(s.lower())\n",
        "            elif U.is_float(s):\n",
        "                assert \"const\" not in str_tokens, \"Currently does not support both placeholder and hard-coded constants.\"\n",
        "                t = Program.library.const_token\n",
        "                constants.append(float(s))\n",
        "            else:\n",
        "                raise ValueError(\"Did not recognize token {}.\".format(s))\n",
        "            traversal.append(t)\n",
        "        traversal = np.array(traversal, dtype=np.int32)\n",
        "    else:\n",
        "        raise ValueError(\"Input must be list or string.\")\n",
        "\n",
        "    # Generate base Program (with \"const\" for constants)\n",
        "    p = from_tokens(traversal, skip_cache=skip_cache)\n",
        "\n",
        "    # Replace any constants\n",
        "    p.set_constants(constants)\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "def from_tokens(tokens, skip_cache=False, on_policy=True, finish_tokens=True):\n",
        "\n",
        "    \"\"\"\n",
        "    Memoized function to generate a Program from a list of tokens.\n",
        "\n",
        "    Since some tokens are nonfunctional, this first computes the corresponding\n",
        "    traversal. If that traversal exists in the cache, the corresponding Program\n",
        "    is returned. Otherwise, a new Program is returned.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tokens : list of integers\n",
        "        A list of integers corresponding to tokens in the library. The list\n",
        "        defines an expression's pre-order traversal. \"Dangling\" programs are\n",
        "        completed with repeated \"x1\" until the expression completes.\n",
        "\n",
        "    skip_cache : bool\n",
        "        Whether to bypass the cache when creating the program (used for\n",
        "        previously learned symbolic actions in DSP).\n",
        "\n",
        "    finish_tokens: bool\n",
        "        Do we need to finish this token. There are instances where we have\n",
        "        already done this. Most likely you will want this to be True.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "    program : Program\n",
        "        The Program corresponding to the tokens, either pulled from memoization\n",
        "        or generated from scratch.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "        Truncate expressions that complete early; extend ones that don't complete\n",
        "    '''\n",
        "\n",
        "    if finish_tokens:\n",
        "        tokens = _finish_tokens(tokens)\n",
        "\n",
        "    # For stochastic Tasks, there is no cache; always generate a new Program.\n",
        "    # For deterministic Programs, if the Program is in the cache, return it;\n",
        "    # otherwise, create a new one and add it to the cache.\n",
        "    if skip_cache or Program.task.stochastic:\n",
        "        p = Program(tokens, on_policy=on_policy)\n",
        "    else:\n",
        "        key = tokens.tostring()\n",
        "        try:\n",
        "            p = Program.cache[key]\n",
        "            if on_policy:\n",
        "                p.on_policy_count += 1\n",
        "            else:\n",
        "                p.off_policy_count += 1\n",
        "        except KeyError:\n",
        "            p = Program(tokens, on_policy=on_policy)\n",
        "            Program.cache[key] = p\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "class Program(object):\n",
        "    \"\"\"\n",
        "    The executable program representing the symbolic expression.\n",
        "\n",
        "    The program comprises unary/binary operators, constant placeholders\n",
        "    (to-be-optimized), input variables, and hard-coded constants.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tokens : list of integers\n",
        "        A list of integers corresponding to tokens in the library. \"Dangling\"\n",
        "        programs are completed with repeated \"x1\" until the expression\n",
        "        completes.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    traversal : list\n",
        "        List of operators (type: Function) and terminals (type: int, float, or\n",
        "        str (\"const\")) encoding the pre-order traversal of the expression tree.\n",
        "\n",
        "    tokens : np.ndarry (dtype: int)\n",
        "        Array of integers whose values correspond to indices\n",
        "\n",
        "    const_pos : list of int\n",
        "        A list of indicies of constant placeholders along the traversal.\n",
        "\n",
        "    float_pos : list of float\n",
        "        A list of indices of constants placeholders or floating-point constants\n",
        "        along the traversal.\n",
        "\n",
        "    poly_pos : int\n",
        "        Index of poly token in the traversal if it has one.\n",
        "\n",
        "    sympy_expr : str\n",
        "        The (lazily calculated) SymPy expression corresponding to the program.\n",
        "        Used for pretty printing _only_.\n",
        "\n",
        "    complexity : float\n",
        "        The (lazily calcualted) complexity of the program.\n",
        "\n",
        "    r : float\n",
        "        The (lazily calculated) reward of the program.\n",
        "\n",
        "    count : int\n",
        "        The number of times this Program has been sampled.\n",
        "\n",
        "    str : str\n",
        "        String representation of tokens. Useful as unique identifier.\n",
        "    \"\"\"\n",
        "\n",
        "    # Static variables\n",
        "    task = None             # Task\n",
        "    library = None          # Library\n",
        "    const_optimizer = None  # Function to optimize constants\n",
        "    cache = {}\n",
        "\n",
        "    # Cython-related static variables\n",
        "    have_cython = None      # Do we have cython installed\n",
        "    execute = None          # Link to execute. Either cython or python\n",
        "\n",
        "    def __init__(self, tokens=None, on_policy=True):\n",
        "        \"\"\"\n",
        "        Builds the Program from a list of of integers corresponding to Tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        # Can be empty if we are unpickling\n",
        "        if tokens is not None:\n",
        "            self._init(tokens, on_policy)\n",
        "\n",
        "    def _init(self, tokens, on_policy=True):\n",
        "\n",
        "        self.traversal = [Program.library[t] for t in tokens]\n",
        "        self.const_pos = [i for i, t in enumerate(self.traversal) if isinstance(t, PlaceholderConstant)]\n",
        "        poly_pos = [i for i, t in enumerate(self.traversal) if isinstance(t, Polynomial)]\n",
        "        assert len(poly_pos) <= 1, \"A program cannot contain more than one 'poly' token\"\n",
        "        self.poly_pos = poly_pos[0] if len(poly_pos) > 0 else None\n",
        "        self.len_traversal = len(self.traversal)\n",
        "\n",
        "        if self.have_cython and self.len_traversal > 1:\n",
        "            self.is_input_var = array.array('i', [t.input_var is not None for t in self.traversal])\n",
        "\n",
        "        self.invalid = False\n",
        "        self.str = tokens.tostring()\n",
        "        self.tokens = tokens\n",
        "\n",
        "        self.on_policy_count = 1 if on_policy else 0\n",
        "        self.off_policy_count = 0 if on_policy else 1\n",
        "        self.originally_on_policy = on_policy # Note if a program was created on policy\n",
        "\n",
        "    def execute(self, X):\n",
        "        \"\"\"\n",
        "        Execute program on input X.\n",
        "\n",
        "        Parameters\n",
        "        ==========\n",
        "\n",
        "        X : np.array\n",
        "            Input to execute the Program over.\n",
        "\n",
        "        Returns\n",
        "        =======\n",
        "\n",
        "        result : np.array or list of np.array\n",
        "            In a single-object Program, returns just an array. In a multi-object Program, returns a list of arrays.\n",
        "        \"\"\"\n",
        "        if not Program.protected:\n",
        "            result, self.invalid, self.error_node, self.error_type = Program.execute_function(self.traversal, X)\n",
        "        else:\n",
        "            result = Program.execute_function(self.traversal, X)\n",
        "        return result\n",
        "\n",
        "    def optimize(self):\n",
        "        \"\"\"\n",
        "        Optimizes PlaceholderConstant tokens against the reward function. The\n",
        "        optimized values are stored in the traversal.\n",
        "        \"\"\"\n",
        "\n",
        "        # TBD: Should use np.float32\n",
        "\n",
        "        if len(self.const_pos) == 0:\n",
        "            return\n",
        "\n",
        "        # Define the objective function: negative reward\n",
        "        def f(consts):\n",
        "            self.set_constants(consts)\n",
        "            r = self.task.reward_function(self, optimizing=True)\n",
        "            obj = -r # Constant optimizer minimizes the objective function\n",
        "\n",
        "            # Need to reset to False so that a single invalid call during\n",
        "            # constant optimization doesn't render the whole Program invalid.\n",
        "            self.invalid = False\n",
        "\n",
        "            return obj\n",
        "\n",
        "        # Do the optimization\n",
        "        x0 = np.ones(len(self.const_pos)) # Initial guess\n",
        "        optimized_constants = Program.const_optimizer(f, x0)\n",
        "\n",
        "        # Set the optimized constants\n",
        "        self.set_constants(optimized_constants)\n",
        "\n",
        "    def get_constants(self):\n",
        "        \"\"\"Returns the values of a Program's constants.\"\"\"\n",
        "\n",
        "        return [t.value for t in self.traversal if isinstance(t, PlaceholderConstant)]\n",
        "\n",
        "    def set_constants(self, consts):\n",
        "        \"\"\"Sets the program's constants to the given values\"\"\"\n",
        "\n",
        "        for i, const in enumerate(consts):\n",
        "            assert U.is_float, \"Input to program constants must be of a floating point type\"\n",
        "            # Create a new instance of PlaceholderConstant instead of changing\n",
        "            # the \"values\" attribute, otherwise all Programs will have the same\n",
        "            # instance and just overwrite each other's value.\n",
        "            self.traversal[self.const_pos[i]] = PlaceholderConstant(const)\n",
        "\n",
        "    def get_poly(self):\n",
        "        \"\"\"Returns a Program's Polynomial token if it has one.\"\"\"\n",
        "\n",
        "        return None if self.poly_pos is None else self.traversal[self.poly_pos]\n",
        "\n",
        "    def set_poly(self, poly_token):\n",
        "        \"\"\"Sets the program's Polynomial token to the given token\"\"\"\n",
        "\n",
        "        if self.poly_pos is not None:\n",
        "            self.traversal[self.poly_pos] = poly_token\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def clear_cache(cls):\n",
        "        \"\"\"Clears the class' cache\"\"\"\n",
        "\n",
        "        cls.cache = {}\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def set_task(cls, task):\n",
        "        \"\"\"Sets the class' Task\"\"\"\n",
        "\n",
        "        Program.task = task\n",
        "        Program.library = task.library\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def set_const_optimizer(cls, name, **kwargs):\n",
        "        \"\"\"Sets the class' constant optimizer\"\"\"\n",
        "\n",
        "        const_optimizer = make_const_optimizer(name, **kwargs)\n",
        "        Program.const_optimizer = const_optimizer\n",
        "\n",
        "    @classmethod\n",
        "    def set_complexity(cls, name):\n",
        "        \"\"\"Sets the class' complexity function\"\"\"\n",
        "\n",
        "        all_functions = {\n",
        "            # No complexity\n",
        "            None : lambda p : 0.0,\n",
        "\n",
        "            # Length of sequence\n",
        "            \"length\" : lambda p : len(p.traversal),\n",
        "\n",
        "            # Sum of token-wise complexities\n",
        "            \"token\" : lambda p : sum([t.complexity for t in p.traversal]),\n",
        "\n",
        "            # Binding complexity: % of mutations relative to master seq\n",
        "            \"mutations\" : lambda p : Program.task.compute_mutational_distance(p)\n",
        "        }\n",
        "\n",
        "        assert name in all_functions, \"Unrecognized complexity function name.\"\n",
        "\n",
        "        Program.complexity_function = lambda p : all_functions[name](p)\n",
        "\n",
        "    @classmethod\n",
        "    def set_execute(cls, protected):\n",
        "        \"\"\"Sets which execute method to use\"\"\"\n",
        "\n",
        "        # Check if cython_execute can be imported; if not, fall back to python_execute\n",
        "        try:\n",
        "            from dso.execute import cython_execute\n",
        "            execute_function = cython_execute\n",
        "            Program.have_cython = True\n",
        "        except ImportError:\n",
        "            from dso.execute import python_execute\n",
        "            execute_function = python_execute\n",
        "            Program.have_cython = False\n",
        "\n",
        "        if protected:\n",
        "            Program.protected = True\n",
        "            Program.execute_function = execute_function\n",
        "        else:\n",
        "            Program.protected = False\n",
        "            class InvalidLog():\n",
        "                \"\"\"Log class to catch and record numpy warning messages\"\"\"\n",
        "\n",
        "                def __init__(self):\n",
        "                    self.error_type = None # One of ['divide', 'overflow', 'underflow', 'invalid']\n",
        "                    self.error_node = None # E.g. 'exp', 'log', 'true_divide'\n",
        "                    self.new_entry = False # Flag for whether a warning has been encountered during a call to Program.execute()\n",
        "\n",
        "                def write(self, message):\n",
        "                    \"\"\"This is called by numpy when encountering a warning\"\"\"\n",
        "\n",
        "                    if not self.new_entry: # Only record the first warning encounter\n",
        "                        message = message.strip().split(' ')\n",
        "                        self.error_type = message[1]\n",
        "                        self.error_node = message[-1]\n",
        "                    self.new_entry = True\n",
        "\n",
        "                def update(self):\n",
        "                    \"\"\"If a floating-point error was encountered, set Program.invalid\n",
        "                    to True and record the error type and error node.\"\"\"\n",
        "\n",
        "                    if self.new_entry:\n",
        "                        self.new_entry = False\n",
        "                        return True, self.error_type, self.error_node\n",
        "                    else:\n",
        "                        return False, None, None\n",
        "\n",
        "\n",
        "            invalid_log = InvalidLog()\n",
        "            np.seterrcall(invalid_log) # Tells numpy to call InvalidLog.write() when encountering a warning\n",
        "\n",
        "            # Define closure for execute function\n",
        "            def unsafe_execute(traversal, X):\n",
        "                \"\"\"This is a wrapper for execute_function. If a floating-point error\n",
        "                would be hit, a warning is logged instead, p.invalid is set to True,\n",
        "                and the appropriate nan/inf value is returned. It's up to the task's\n",
        "                reward function to decide how to handle nans/infs.\"\"\"\n",
        "\n",
        "                with np.errstate(all='log'):\n",
        "                    y = execute_function(traversal, X)\n",
        "                    invalid, error_node, error_type = invalid_log.update()\n",
        "                    return y, invalid, error_node, error_type\n",
        "\n",
        "            Program.execute_function = unsafe_execute\n",
        "\n",
        "    @cached_property\n",
        "    def r(self):\n",
        "        \"\"\"Evaluates and returns the reward of the program\"\"\"\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            # Optimize any PlaceholderConstants\n",
        "            self.optimize()\n",
        "\n",
        "            # Return final reward after optimizing\n",
        "            return self.task.reward_function(self)\n",
        "\n",
        "    @cached_property\n",
        "    def complexity(self):\n",
        "        \"\"\"Evaluates and returns the complexity of the program\"\"\"\n",
        "\n",
        "        return Program.complexity_function(self)\n",
        "\n",
        "    @cached_property\n",
        "    def evaluate(self):\n",
        "        \"\"\"Evaluates and returns the evaluation metrics of the program.\"\"\"\n",
        "\n",
        "        # Program must be optimized before computing evaluate\n",
        "        if \"r\" not in self.__dict__:\n",
        "            print(\"WARNING: Evaluating Program before computing its reward.\" \\\n",
        "                  \"Program will be optimized first.\")\n",
        "            self.optimize()\n",
        "\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            return self.task.evaluate(self)\n",
        "\n",
        "    @cached_property\n",
        "    def sympy_expr(self):\n",
        "        \"\"\"\n",
        "        Returns the attribute self.sympy_expr.\n",
        "\n",
        "        This is actually a bit complicated because we have to go: traversal -->\n",
        "        tree --> serialized tree --> SymPy expression\n",
        "        \"\"\"\n",
        "\n",
        "        tree = self.traversal.copy()\n",
        "        tree = build_tree(tree)\n",
        "        tree = convert_to_sympy(tree)\n",
        "        try:\n",
        "            expr = U.parse_expr(tree.__repr__()) # SymPy expression\n",
        "        except:\n",
        "            expr = tree.__repr__()\n",
        "        return expr\n",
        "\n",
        "    def pretty(self):\n",
        "        \"\"\"Returns pretty printed string of the program\"\"\"\n",
        "\n",
        "        if self.task.task_type != \"binding\":\n",
        "            return U.pretty(self.sympy_expr)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def print_stats(self):\n",
        "        \"\"\"Prints the statistics of the program\n",
        "\n",
        "            We will print the most honest reward possible when using validation.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\tReward: {}\".format(self.r))\n",
        "        print(\"\\tCount Off-policy: {}\".format(self.off_policy_count))\n",
        "        print(\"\\tCount On-policy: {}\".format(self.on_policy_count))\n",
        "        print(\"\\tOriginally on Policy: {}\".format(self.originally_on_policy))\n",
        "        print(\"\\tInvalid: {}\".format(self.invalid))\n",
        "        print(\"\\tTraversal: {}\".format(self))\n",
        "        if self.task.task_type != 'binding':\n",
        "            print(\"\\tExpression:\")\n",
        "            print(\"{}\\n\".format(indent(self.pretty(), '\\t  ')))\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Prints the program's traversal\"\"\"\n",
        "        return ','.join([repr(t) for t in self.traversal])\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Everything below this line is currently only being used for pretty printing #\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "# Possible library elements that sympy capitalizes\n",
        "capital = [\"add\", \"mul\", \"pow\"]\n",
        "\n",
        "\n",
        "class Node(object):\n",
        "    \"\"\"Basic tree class supporting printing\"\"\"\n",
        "\n",
        "    def __init__(self, val):\n",
        "        self.val = val\n",
        "        self.children = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        children_repr = \",\".join(repr(child) for child in self.children)\n",
        "        if len(self.children) == 0:\n",
        "            return self.val # Avoids unnecessary parantheses, e.g. x1()\n",
        "        return \"{}({})\".format(self.val, children_repr)\n",
        "\n",
        "\n",
        "def build_tree(traversal):\n",
        "    \"\"\"Recursively builds tree from pre-order traversal\"\"\"\n",
        "\n",
        "    op = traversal.pop(0)\n",
        "    n_children = op.arity\n",
        "    val = repr(op)\n",
        "    if val in capital:\n",
        "        val = val.capitalize()\n",
        "\n",
        "    node = Node(val)\n",
        "\n",
        "    for _ in range(n_children):\n",
        "        node.children.append(build_tree(traversal))\n",
        "\n",
        "    return node\n",
        "\n",
        "\n",
        "def convert_to_sympy(node):\n",
        "    \"\"\"Adjusts trees to only use node values supported by sympy\"\"\"\n",
        "\n",
        "    if node.val == \"div\":\n",
        "        node.val = \"Mul\"\n",
        "        new_right = Node(\"Pow\")\n",
        "        new_right.children.append(node.children[1])\n",
        "        new_right.children.append(Node(\"-1\"))\n",
        "        node.children[1] = new_right\n",
        "\n",
        "    elif node.val == \"sub\":\n",
        "        node.val = \"Add\"\n",
        "        new_right = Node(\"Mul\")\n",
        "        new_right.children.append(node.children[1])\n",
        "        new_right.children.append(Node(\"-1\"))\n",
        "        node.children[1] = new_right\n",
        "\n",
        "    elif node.val == \"inv\":\n",
        "        node.val = Node(\"Pow\")\n",
        "        node.children.append(Node(\"-1\"))\n",
        "\n",
        "    elif node.val == \"neg\":\n",
        "        node.val = Node(\"Mul\")\n",
        "        node.children.append(Node(\"-1\"))\n",
        "\n",
        "    elif node.val == \"n2\":\n",
        "        node.val = \"Pow\"\n",
        "        node.children.append(Node(\"2\"))\n",
        "\n",
        "    elif node.val == \"n3\":\n",
        "        node.val = \"Pow\"\n",
        "        node.children.append(Node(\"3\"))\n",
        "\n",
        "    elif node.val == \"n4\":\n",
        "        node.val = \"Pow\"\n",
        "        node.children.append(Node(\"4\"))\n",
        "\n",
        "    for child in node.children:\n",
        "        convert_to_sympy(child)\n",
        "\n",
        "    return node"
      ],
      "metadata": {
        "id": "rF8HTtwWFSY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import jit, prange\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DK92n4KnFkbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subrotines\n",
        "@jit(nopython=True, parallel=True)\n",
        "def parents_siblings(tokens, arities, parent_adjust, empty_parent, empty_sibling):\n",
        "    \"\"\"\n",
        "    Given a batch of action sequences, computes and returns the parents and\n",
        "    siblings of the next element of the sequence.\n",
        "\n",
        "    The batch has shape (N, L), where N is the number of sequences (i.e. batch\n",
        "    size) and L is the length of each sequence. In some cases, expressions may\n",
        "    already be complete; in these cases, this function sees the start of a new\n",
        "    expression, even though the return value for these elements won't matter\n",
        "    because their gradients will be zero because of sequence_length.\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    tokens : np.ndarray, shape=(N, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    arities : np.ndarray, dtype=np.int32\n",
        "        Array of arities corresponding to library indices.\n",
        "\n",
        "    parent_adjust : np.ndarray, dtype=np.int32\n",
        "        Array of parent sub-library index corresponding to library indices.\n",
        "\n",
        "    empty_parent : int\n",
        "        Integer value for an empty parent token. This is initially computed in controller.py.\n",
        "\n",
        "    empty_sibling : int\n",
        "        Integer value for an empty sibling token. This is intially computed in controller.py\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    adj_parents : np.ndarray, shape=(N,), dtype=np.int32\n",
        "        Adjusted parents of the next element of each action sequence.\n",
        "\n",
        "    siblings : np.ndarray, shape=(N,), dtype=np.int32\n",
        "        Siblings of the next element of each action sequence.\n",
        "\n",
        "    \"\"\"\n",
        "    N, L = tokens.shape\n",
        "\n",
        "    adj_parents = np.full(shape=(N,), fill_value=empty_parent, dtype=np.int32)\n",
        "    siblings = np.full(shape=(N,), fill_value=empty_sibling, dtype=np.int32)\n",
        "    # Parallelized loop over action sequences\n",
        "    for r in prange(N):\n",
        "        arity = arities[tokens[r, -1]]\n",
        "        if arity > 0: # Parent is the previous element; no sibling\n",
        "            adj_parents[r] = parent_adjust[tokens[r, -1]]\n",
        "            continue\n",
        "        dangling = 0\n",
        "        # Loop over elements in an action sequence\n",
        "        for c in range(L):\n",
        "            arity = arities[tokens[r, L - c - 1]]\n",
        "            dangling += arity - 1\n",
        "            if dangling == 0: # Parent is L-c-1, sibling is the next\n",
        "                adj_parents[r] = parent_adjust[tokens[r, L - c - 1]]\n",
        "                siblings[r] = tokens[r, L - c]\n",
        "                break\n",
        "    return adj_parents, siblings\n",
        "\n",
        "\n",
        "# TBD: Refactor to compute hierarchical obs\n",
        "@jit(nopython=True, parallel=False)\n",
        "def jit_parents_siblings_at_once(tokens, arities, parent_adjust):\n",
        "    \"\"\"\n",
        "    Given a batch of action sequences, computes and returns the parents and\n",
        "    siblings over the entire sequence at once.\n",
        "\n",
        "    This version will give all parents and siblings at once over the full\n",
        "    and complete set of tokens. This is useful for Deap because it generates\n",
        "    each sequence in one go rather than one token at a time.\n",
        "\n",
        "    The batch has shape (N, L), where N is the number of sequences (i.e. batch\n",
        "    size) and L is the length of each sequence. In some cases, expressions may\n",
        "    already be complete; in these cases, this function sees the start of a new\n",
        "    expression, even though the return value for these elements won't matter\n",
        "    because their gradients will be zero because of sequence_length.\n",
        "\n",
        "    >>> This has been tested and gives the same answer as the regular parent_sibling class for\n",
        "        DEAP functions.\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    tokens : np.ndarray, shape=(N, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    arities : np.ndarray, dtype=np.int32\n",
        "        Array of arities corresponding to library indices.\n",
        "\n",
        "    parent_adjust : np.ndarray, dtype=np.int32\n",
        "        Array of parent sub-library index corresponding to library indices.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    adj_parents : np.ndarray, shape=(N, L), dtype=np.int32\n",
        "        Adjusted parents of the next element of each action sequence.\n",
        "\n",
        "    siblings : np.ndarray, shape=(N, L), dtype=np.int32\n",
        "        Siblings of the next element of each action sequence.\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    N, L = tokens.shape\n",
        "\n",
        "    empty_parent    = np.max(parent_adjust) + 1 # Empty token is after all non-empty tokens\n",
        "    empty_sibling   = len(arities) # Empty token is after all non-empty tokens\n",
        "    adj_parents     = np.full(shape=(N,L), fill_value=empty_parent, dtype=np.int32)\n",
        "    siblings        = np.full(shape=(N,L), fill_value=empty_sibling, dtype=np.int32)\n",
        "\n",
        "    # Parallelization is slower here ...\n",
        "\n",
        "    # We loop over actions since frequently, N is 1 when used with Deap.\n",
        "    for b in range(1, L):\n",
        "        for r in range(N):\n",
        "            # This part is optimal\n",
        "            arity = arities[tokens[r, b - 1]]\n",
        "            if arity > 0: # Parent is the previous element; no sibling\n",
        "                adj_parents[r, b]   = parent_adjust[tokens[r, b - 1]]\n",
        "                continue\n",
        "\n",
        "            # This part may not be optimal here, but is fast enough for now\n",
        "            dangling = 0\n",
        "            # Loop over elements in an action sequence GOING BACKWARDS\n",
        "            for c in range(b):\n",
        "                arity = arities[tokens[r, b - c - 1]]\n",
        "                dangling += arity - 1\n",
        "\n",
        "                # Most recent non-dangling action\n",
        "                if dangling == 0:\n",
        "                    # Parent is b-c-1, sibling is the next\n",
        "                    adj_parents[r, b]   = parent_adjust[tokens[r, b - c - 1]]\n",
        "                    siblings[r, b]      = tokens[r, b - c]\n",
        "                    break\n",
        "\n",
        "    return adj_parents, siblings\n",
        "\n",
        "\n",
        "@jit(nopython=True, parallel=True)\n",
        "def ancestors(actions, arities, ancestor_tokens):\n",
        "    \"\"\"\n",
        "    Given a batch of action sequences, determines whether the next element of\n",
        "    the sequence has an ancestor in ancestor_tokens.\n",
        "\n",
        "    The batch has shape (N, L), where N is the number of sequences (i.e. batch\n",
        "    size) and L is the length of each sequence. In some cases, expressions may\n",
        "    already be complete; in these cases, this function sees the start of a new\n",
        "    expression, even though the return value for these elements won't matter\n",
        "    because their gradients will be zero because of sequence_length.\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    actions : np.ndarray, shape=(N, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    arities : np.ndarray, dtype=np.int32\n",
        "        Array of arities corresponding to library indices.\n",
        "\n",
        "    ancestor_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of ancestor library indices to check.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    mask : np.ndarray, shape=(N,), dtype=np.bool_\n",
        "        Mask of whether the next element of each sequence has an ancestor in\n",
        "        ancestor_tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    for token in ancestor_tokens:\n",
        "        assert arities[token] == 1, \"subroutine 'ancestors' may not work\" \\\n",
        "            \"properly for non-unary ancestor_tokens\"\n",
        "\n",
        "    N, L = actions.shape\n",
        "    mask = np.zeros(shape=(N,), dtype=np.bool_)\n",
        "    # Parallelized loop over action sequences\n",
        "    for r in prange(N):\n",
        "        dangling = 0\n",
        "        threshold = None # If None, current branch does not have trig ancestor\n",
        "        for c in range(L):\n",
        "            arity = arities[actions[r, c]]\n",
        "            dangling += arity - 1\n",
        "            # Turn \"on\" if a trig function is found\n",
        "            # Remain \"on\" until branch completes\n",
        "            if threshold is None:\n",
        "                for trig_token in ancestor_tokens:\n",
        "                    if actions[r, c] == trig_token:\n",
        "                        threshold = dangling - 1\n",
        "                        break\n",
        "            # Turn \"off\" once the branch completes\n",
        "            else:\n",
        "                if dangling == threshold:\n",
        "                    threshold = None\n",
        "        # If the sequences ended \"on\", then there is a trig ancestor\n",
        "        if threshold is not None:\n",
        "            mask[r] = True\n",
        "    return mask\n",
        "\n",
        "\n",
        "@jit(nopython=True, parallel=False)\n",
        "def jit_check_constraint_violation(actions, actions_tokens, other, other_tokens):\n",
        "    r\"\"\"\n",
        "    Given an action sequence, another type of sequences such as siblings\n",
        "    or children and constraint tokens, this will return a bool which tells if\n",
        "    the constraint was violated.\n",
        "\n",
        "    The batch has shape (1, L), L is the length of the sequence.\n",
        "\n",
        "    This does the same thing as:\n",
        "\n",
        "        np.any(np.logical_and(np.isin(actions, actions_tokens), np.isin(other, other_tokens)))\n",
        "\n",
        "    but is much faster because it can quit when a single constraint is violated.\n",
        "\n",
        "    >>> This has been tested against the old inverse token constraint and gives the same answer.\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    actions : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    actions_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match action against.\n",
        "\n",
        "    other : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of other sequences. Values correspond to library indices.\n",
        "\n",
        "    other_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match other against.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    bool : Was the constraint violated.\n",
        "\n",
        "    \"\"\"\n",
        "    # Is this token item A found in the list of tokens in B?\n",
        "    def a_in_b(a, B_tokens, B):\n",
        "        for b in range(B):\n",
        "            if a == B_tokens[b]:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    _,L     = actions.shape\n",
        "    A       = actions_tokens.shape[0]\n",
        "    O       = other_tokens.shape[0]\n",
        "\n",
        "    # For each action:\n",
        "    for l in range(L):\n",
        "        # Check if this token matches a constraint token\n",
        "        # And check if the other also matches one of its constraints\n",
        "        if a_in_b(actions[0,l], actions_tokens, A) and a_in_b(other[0,l], other_tokens, O):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "@jit(nopython=True, parallel=False)\n",
        "def jit_check_constraint_violation_uchild(actions, parent, sibling, actions_tokens,\n",
        "                                          adj_unary_effectors, adj_effectors):\n",
        "    r\"\"\"\n",
        "    Given an action sequence, another type of sequences such as siblings\n",
        "    or children and constraint tokens, this will return a bool which tells if\n",
        "    the constraint was violated.\n",
        "\n",
        "    The batch has shape (1, L), L is the length of the sequence.\n",
        "\n",
        "    This does the same thing as:\n",
        "\n",
        "        for i, a in enumerate(actions):\n",
        "            if (parent[i] in adj_unary_effectors) or (sibling[i] in self.targets and parent[i] in adj_effectors)\n",
        "                if a in self.targets:\n",
        "                    return True\n",
        "\n",
        "    but is much faster because it can quit when a single constraint is violated.\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    actions : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    parent  : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of parent sequences. Values correspond to library indices.\n",
        "\n",
        "    sibling : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of sibling sequences. Values correspond to library indices.\n",
        "\n",
        "    actions_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match action against.\n",
        "\n",
        "    adj_unary_effectorss : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match action against.\n",
        "\n",
        "    adj_effectors : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match action against.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    bool : Was the constraint violated.\n",
        "\n",
        "    \"\"\"\n",
        "    # Is this token item A found in the list of tokens in B?\n",
        "    def a_in_b(a, B_tokens, B):\n",
        "        for b in range(B):\n",
        "            if a == B_tokens[b]:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    _,L     = actions.shape\n",
        "    A       = actions_tokens.shape[0]\n",
        "    U       = adj_unary_effectors.shape[0]\n",
        "    E       = adj_effectors.shape[0]\n",
        "\n",
        "    # For each action:\n",
        "    for l in range(L):\n",
        "\n",
        "        # Is this the right action?\n",
        "        if a_in_b(actions[0,l], actions_tokens, A):\n",
        "            # CASE 1: parent is a unary effector\n",
        "            if a_in_b(parent[0,l], adj_unary_effectors, U):\n",
        "                return True\n",
        "\n",
        "            # CASE 2: sibling is a target and parent is an effector\n",
        "            if a_in_b(sibling[0,l], actions_tokens, A) and a_in_b(parent[0,l], adj_effectors, E):\n",
        "                return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "@jit(nopython=True, parallel=False)\n",
        "def jit_check_constraint_violation_descendant_no_target_tokens(\\\n",
        "        actions, effector_tokens, binary_tokens, unary_tokens):\n",
        "\n",
        "    r\"\"\"\n",
        "    Given an action sequence, another type of sequences such as siblings\n",
        "    or children and constraint tokens, this will return a bool which tells if\n",
        "    the constraint was violated.\n",
        "\n",
        "    The batch has shape (1, L), L is the length of the sequence.\n",
        "\n",
        "    This can be used (for instance) to check for trig constraints.\n",
        "\n",
        "    This does the same thing as:\n",
        "\n",
        "        descendant = False # True when current node is a descendant of operator\n",
        "\n",
        "        for a in actions:\n",
        "            if a in self.targets:\n",
        "                if descendant:\n",
        "                    return True\n",
        "                descendant = True\n",
        "                dangling   = 1\n",
        "            elif descendant:\n",
        "                if a in library.binary_tokens:\n",
        "                    dangling += 1\n",
        "                elif a not in library.unary_tokens:\n",
        "                    dangling -= 1\n",
        "                if dangling == 0:\n",
        "                    descendant = False\n",
        "\n",
        "        return False\n",
        "\n",
        "    >>> This has been tested against the old Trig constraint and gives the same answer\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    actions : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    effector_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match action against.\n",
        "\n",
        "    binrary_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of binary function tokens in the current library.\n",
        "\n",
        "    uniary_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of unary function tokens in the current library.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    bool : Was the constraint violated.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Is this token item A found in the list of tokens in B?\n",
        "    def a_in_b(a, B_tokens, B):\n",
        "        for b in range(B):\n",
        "            if a == B_tokens[b]:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # Is this token item A NOT found in the list of tokens in B?\n",
        "    def a_not_in_b(a, B_tokens, B):\n",
        "        for b in range(B):\n",
        "            if a == B_tokens[b]:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    _,L     = actions.shape\n",
        "    E       = effector_tokens.shape[0]\n",
        "    B       = binary_tokens.shape[0]\n",
        "    U       = unary_tokens.shape[0]\n",
        "\n",
        "    descendant = False # True when current node is a descendant of operator\n",
        "\n",
        "    # For each action:\n",
        "    for l in range(L):\n",
        "\n",
        "        action = actions[0,l]\n",
        "\n",
        "        if a_in_b(action, effector_tokens, E):\n",
        "            # Does action match a target token?\n",
        "            if descendant:\n",
        "                # a token was found previously, but\n",
        "                # we are still in a dangling node, therefore\n",
        "                # we have a token inside a token expression\n",
        "                # that we are not allowed to have e.g.\n",
        "                # sin(sin(x)) .\n",
        "\n",
        "                return True\n",
        "            descendant  = True\n",
        "            dangling    = 1\n",
        "        elif descendant:\n",
        "            if a_in_b(action, binary_tokens, B):\n",
        "                # Does action match a binary token?\n",
        "                # Then add one to dangling.\n",
        "                dangling += 1\n",
        "            elif a_not_in_b(action, unary_tokens, U):\n",
        "                # Does action match a terminal token?\n",
        "                # Then subtract one from dangling.\n",
        "                # We skip the instance of unary since\n",
        "                # this leaves dangling to be += 0\n",
        "                # and assume that any token not binary\n",
        "                # and unary is a terminal.\n",
        "                dangling -= 1\n",
        "\n",
        "            # If we no longer have any dangling nodes,\n",
        "            # Then we cannot be a descendant.\n",
        "            if dangling == 0:\n",
        "                descendant = False\n",
        "\n",
        "    return False\n",
        "\n",
        "@jit(nopython=True, parallel=False)\n",
        "def jit_check_constraint_violation_descendant_with_target_tokens(\\\n",
        "        actions, target_tokens, effector_tokens, binary_tokens, unary_tokens):\n",
        "\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "\n",
        "    actions : np.ndarray, shape=(1, L), dtype=np.int32\n",
        "        Batch of action sequences. Values correspond to library indices.\n",
        "\n",
        "    target_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of constraint tokens to match action against.\n",
        "\n",
        "    binrary_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of binary function tokens in the current library.\n",
        "\n",
        "    uniary_tokens : np.ndarray, dtype=np.int32\n",
        "        Array of unary function tokens in the current library.\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "\n",
        "    bool : Was the constraint violated.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Is this token item A found in the list of tokens in B?\n",
        "    def a_in_b(a, B_tokens, B):\n",
        "        for b in range(B):\n",
        "            if a == B_tokens[b]:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # Is this token item A NOT found in the list of tokens in B?\n",
        "    def a_not_in_b(a, B_tokens, B):\n",
        "        for b in range(B):\n",
        "            if a == B_tokens[b]:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    _,L     = actions.shape\n",
        "    T       = target_tokens.shape[0]\n",
        "    B       = binary_tokens.shape[0]\n",
        "    U       = unary_tokens.shape[0]\n",
        "\n",
        "    descendant = False # True when current node is a descendant of operator\n",
        "\n",
        "    # For each action:\n",
        "    for l in range(L):\n",
        "\n",
        "        action = actions[0,l]\n",
        "\n",
        "        if a_in_b(action, effector_tokens, T):\n",
        "            # Does action match a target token?\n",
        "            descendant  = True\n",
        "            dangling    = 1\n",
        "        elif a_in_b(action, target_tokens, T):\n",
        "            if descendant:\n",
        "                return True\n",
        "        elif descendant:\n",
        "            if a_in_b(action, binary_tokens, B):\n",
        "                # Does action match a binary token?\n",
        "                # Then add one to dangling.\n",
        "                dangling += 1\n",
        "            elif a_not_in_b(action, unary_tokens, U):\n",
        "                # Does action match a terminal token?\n",
        "                # Then subtract one from dangling.\n",
        "                # We skip the instance of unary since\n",
        "                # this leaves dangling to be += 0\n",
        "                # and assume that any token not binary\n",
        "                # and unary is a terminal.\n",
        "                dangling -= 1\n",
        "\n",
        "            # If we no longer have any dangling nodes,\n",
        "            # Then we cannot be a descendant.\n",
        "            if dangling == 0:\n",
        "                descendant = False\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "jSJys7PpFroS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TVpXHMB0GCx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#task\n",
        "class Task(ABC):\n",
        "    \"\"\"\n",
        "    Object specifying a symbolic search task.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    library : Library\n",
        "        Library of Tokens.\n",
        "\n",
        "    stochastic : bool\n",
        "        Whether the reward function of the task is stochastic.\n",
        "\n",
        "    task_type : str\n",
        "        Task type: regression, control, or binding.\n",
        "\n",
        "    name : str\n",
        "        Unique name for instance of this task.\n",
        "    \"\"\"\n",
        "\n",
        "    task_type = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def reward_function(self, program, optimizing=False):\n",
        "        \"\"\"\n",
        "        The reward function for this task.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        program : dso.program.Program\n",
        "\n",
        "            The Program to compute reward of.\n",
        "\n",
        "        optimizing : bool\n",
        "\n",
        "            Whether the reward is computed for PlaceholderConstant optimization.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        reward : float\n",
        "\n",
        "            Fitness/reward of the program.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, program):\n",
        "        \"\"\"\n",
        "        The evaluation metric for this task.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        program : dso.program.Program\n",
        "\n",
        "            The Program to evaluate.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        info : dict\n",
        "\n",
        "            Dictionary of evaluation metrics. Special key \"success\" is used to\n",
        "            trigger early stopping.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "        \"\"\"\n",
        "        Produce the next observation and prior from the current observation and\n",
        "        list of actions so far. Observations must be 1-D np.float32 vectors.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        actions : np.ndarray (dtype=np.int32)\n",
        "            Actions selected so far, shape (batch_size, current_length)\n",
        "\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Previous observation, shape (batch_size, OBS_DIM).\n",
        "\n",
        "        already_finished : np.ndarray (dtype=bool)\n",
        "            Whether the object has *already* been completed.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        next_obs : np.ndarray (dtype=np.float32)\n",
        "            The next observation, shape (batch_size, OBS_DIM).\n",
        "\n",
        "        prior : np.ndarray (dtype=np.float32)\n",
        "            Prior for selecting the next token, shape (batch_size,\n",
        "            self.library.L).\n",
        "\n",
        "        finished : np.ndarray (dtype=bool)\n",
        "            Whether the object has *ever* been completed.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset_task(self):\n",
        "        \"\"\"\n",
        "        Create the starting observation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Starting observation, shape (batch_size, OBS_DIM).\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class HierarchicalTask(Task):\n",
        "    \"\"\"\n",
        "    A Task in which the search space is a binary tree. Observations include\n",
        "    the previous action, the parent, the sibling, and/or the number of dangling\n",
        "    (unselected) nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    OBS_DIM = 4 # action, parent, sibling, dangling\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Task).__init__()\n",
        "\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "\n",
        "        dangling = obs[:, 3] # Shape of obs: (?, 4)\n",
        "        action = actions[:, -1] # Current action\n",
        "        lib = self.library\n",
        "\n",
        "        # Compute parents and siblings\n",
        "        parent, sibling = parents_siblings(actions,\n",
        "                                           arities=lib.arities,\n",
        "                                           parent_adjust=lib.parent_adjust,\n",
        "                                           empty_parent=lib.EMPTY_PARENT,\n",
        "                                           empty_sibling=lib.EMPTY_SIBLING)\n",
        "\n",
        "        # Compute dangling\n",
        "        dangling += lib.arities[action] - 1\n",
        "\n",
        "        # Compute finished\n",
        "        just_finished = (dangling == 0) # Trees that completed _this_ time step\n",
        "        # [batch_size]\n",
        "        finished = np.logical_or(just_finished,\n",
        "                                 already_finished)\n",
        "\n",
        "        # Compute priors\n",
        "        prior = self.prior(actions, parent, sibling, dangling, finished) # (?, n_choices)\n",
        "\n",
        "        # Combine observation dimensions\n",
        "        next_obs = np.stack([action, parent, sibling, dangling], axis=1) # (?, 4)\n",
        "        next_obs = next_obs.astype(np.float32)\n",
        "\n",
        "        return next_obs, prior, finished\n",
        "\n",
        "    def reset_task(self, prior):\n",
        "        \"\"\"\n",
        "        Returns the initial observation: empty action, parent, and sibling, and\n",
        "        dangling is 1.\n",
        "        \"\"\"\n",
        "\n",
        "        self.prior = prior\n",
        "\n",
        "        # Order of observations: action, parent, sibling, dangling\n",
        "        initial_obs = np.array([self.library.EMPTY_ACTION,\n",
        "                                self.library.EMPTY_PARENT,\n",
        "                                self.library.EMPTY_SIBLING,\n",
        "                                1],\n",
        "                               dtype=np.float32)\n",
        "        return initial_obs\n",
        "\n",
        "\n",
        "class SequentialTask(Task):\n",
        "    \"\"\"\n",
        "    A Task in which the search space is a (possibly variable-length) sequence.\n",
        "    The observation is simply the previous action.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_task(task_type, **config_task):\n",
        "    \"\"\"\n",
        "    Factory function for Task object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    task_type : str\n",
        "        Type of task:\n",
        "        \"regression\" : Symbolic regression task.\n",
        "        \"control\" : Episodic reinforcement learning task.\n",
        "        \"binding\": AbAg binding affinity optimization task.\n",
        "\n",
        "    config_task : kwargs\n",
        "        Task-specific arguments. See specifications of task_dict.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    task : Task\n",
        "        Task object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Lazy import of task factory functions\n",
        "    if task_type == 'binding':\n",
        "        from dso.task.binding.binding import BindingTask\n",
        "        task_class = BindingTask\n",
        "    elif task_type == \"regression\":\n",
        "        from dso.task.regression.regression import RegressionTask\n",
        "        task_class = RegressionTask\n",
        "    elif task_type == \"control\":\n",
        "        from dso.task.control.control import ControlTask\n",
        "        task_class = ControlTask\n",
        "    else:\n",
        "        # Custom task import\n",
        "        task_class = import_custom_source(task_type)\n",
        "        assert issubclass(task_class, Task), \\\n",
        "            \"Custom task {} must subclass dso.task.Task.\".format(task_class)\n",
        "\n",
        "    task = task_class(**config_task)\n",
        "    return task\n",
        "\n",
        "\n",
        "def set_task(config_task):\n",
        "    \"\"\"Helper function to make set the Program class Task and execute function\n",
        "    from task config.\"\"\"\n",
        "\n",
        "    # Use of protected functions is the same for all tasks, so it's handled separately\n",
        "    protected = config_task[\"protected\"] if \"protected\" in config_task else False\n",
        "\n",
        "    Program.set_execute(protected)\n",
        "    task = make_task(**config_task)\n",
        "    Program.set_task(task)"
      ],
      "metadata": {
        "id": "qs9F8bZPGDxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qVVYqxssHJkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#memory\n",
        "\n",
        "Batch = namedtuple(\n",
        "    \"Batch\", [\"actions\", \"obs\", \"priors\", \"lengths\", \"rewards\", \"on_policy\"])\n",
        "\n",
        "\n",
        "# TBD: This should be member function of Batch class\n",
        "def save_batch(B, save_path):\n",
        "    \"\"\"Save Batch to file.\"\"\"\n",
        "\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        np.savez(f, **dict(B._asdict()))\n",
        "\n",
        "\n",
        "# TBD: This should be class function of Batch class\n",
        "def load_batch(save_path):\n",
        "    \"\"\"Load Batch from file.\"\"\"\n",
        "\n",
        "    B = np.load(save_path)\n",
        "    B = Batch(**B)\n",
        "    return B\n",
        "\n",
        "\n",
        "def make_queue(policy=None, priority=False, capacity=np.inf, seed=0):\n",
        "    \"\"\"Factory function for various Queues.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    policy : dso.policy.Policy\n",
        "        Reference to the Policy, used to compute probabilities of items in\n",
        "        the Queue.\n",
        "\n",
        "    priority : bool\n",
        "        If True, returns an object inheriting UniquePriorityQueue. Otherwise,\n",
        "        returns an object inheriting from UniqueQueue.\n",
        "\n",
        "    capacity : int\n",
        "        Maximum queue length.\n",
        "\n",
        "    seed : int\n",
        "        RNG seed used for random sampling.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    queue : ProgramQueue\n",
        "        Dynamic class inheriting from ProgramQueueMixin and a Queue subclass.\n",
        "    \"\"\"\n",
        "\n",
        "    if priority:\n",
        "        Base = UniquePriorityQueue\n",
        "    else:\n",
        "        Base = UniqueQueue\n",
        "\n",
        "    class ProgramQueue(ProgramQueueMixin, Base):\n",
        "        def __init__(self, policy, capacity, seed):\n",
        "            ProgramQueueMixin.__init__(self, policy)\n",
        "            Base.__init__(self, capacity, seed)\n",
        "\n",
        "    queue = ProgramQueue(policy, capacity, seed)\n",
        "    return queue\n",
        "\n",
        "\n",
        "def get_samples(batch, key):\n",
        "    \"\"\"\n",
        "    Returns a sub-Batch with samples from the given indices.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    key : int or slice\n",
        "        Indices of samples to return.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    batch : Batch\n",
        "        Sub-Batch with samples from the given indices.\n",
        "    \"\"\"\n",
        "\n",
        "    batch = Batch(\n",
        "        actions=batch.actions[key],\n",
        "        obs=batch.obs[key],\n",
        "        priors=batch.priors[key],\n",
        "        lengths=batch.lengths[key],\n",
        "        rewards=batch.rewards[key],\n",
        "        on_policy=batch.on_policy[key])\n",
        "    return batch\n",
        "\n",
        "\n",
        "# Adapted from https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/research/brain_coder/common/utils.py\n",
        "class ItemContainer(object):\n",
        "    \"\"\"Class for holding an item with its score.\n",
        "\n",
        "    Defines a comparison function for use in the heap-queue.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, score, item, extra_data):\n",
        "        self.item = item\n",
        "        self.score = score\n",
        "        self.extra_data = extra_data\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        assert isinstance(other, type(self))\n",
        "        return self.score < other.score\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        assert isinstance(other, type(self))\n",
        "        return self.item == other.item\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Allows unpacking like a tuple.\"\"\"\n",
        "        yield self.score\n",
        "        yield self.item\n",
        "        yield self.extra_data\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"String representation of this item.\n",
        "\n",
        "        `extra_data` is not included in the representation. We are assuming that\n",
        "        `extra_data` is not easily interpreted by a human (if it was, it should be\n",
        "        hashable, like a string or tuple).\n",
        "\n",
        "        Returns:\n",
        "            String representation of `self`.\n",
        "        \"\"\"\n",
        "        return str((self.score, self.item))\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)\n",
        "\n",
        "\n",
        "class Queue(object):\n",
        "    \"\"\"Abstract class for queue that must define a push and pop routine\"\"\"\n",
        "\n",
        "    def __init__(self, capacity, seed=0):\n",
        "        self.capacity = capacity\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "        self.heap = []\n",
        "        self.unique_items = set()\n",
        "\n",
        "    def push(self, score, item, extra_data):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def pop(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def random_sample(self, sample_size):\n",
        "        \"\"\"Uniform randomly select items from the queue.\n",
        "\n",
        "        Args:\n",
        "            sample_size: Number of random samples to draw. The same item can be\n",
        "                    sampled multiple times.\n",
        "\n",
        "        Returns:\n",
        "            List of sampled items (of length `sample_size`). Each element in the list\n",
        "            is a tuple: (item, extra_data).\n",
        "        \"\"\"\n",
        "        idx = self.rng.choice(len(self.heap), sample_size, )\n",
        "        return [(self.heap[i].item, self.heap[i].extra_data) for i in idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.heap)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _, item, _ in self.heap:\n",
        "            yield item\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '[' + ', '.join(repr(c) for c in self.heap) + ']'\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)\n",
        "\n",
        "\n",
        "class UniqueQueue(Queue):\n",
        "    \"\"\"A queue in which duplicates are not allowed. Instead, adding a duplicate\n",
        "    moves that item to the back of the queue.\"\"\"\n",
        "\n",
        "    def push(self, score, item, extra_data=None):\n",
        "        \"\"\"Push an item onto the queue, or move it to the back if already\n",
        "        present.\n",
        "\n",
        "        Score is unused but included as an argument to follow the interface.\n",
        "        \"\"\"\n",
        "\n",
        "        container = ItemContainer(None, item, extra_data)\n",
        "\n",
        "        # If the item is already in the queue, move it to the back of the queue\n",
        "        # and return\n",
        "        if item in self.unique_items:\n",
        "            self.heap.remove(container)\n",
        "            self.heap.append(container)\n",
        "            return\n",
        "\n",
        "        # If the queue is at capacity, first pop the front of the queue\n",
        "        if len(self.heap) >= self.capacity:\n",
        "            self.pop()\n",
        "\n",
        "        # Add the item\n",
        "        self.heap.append(container)\n",
        "        self.unique_items.add(item)\n",
        "\n",
        "    def pop(self):\n",
        "        \"\"\"Pop the front of the queue (the oldest item).\"\"\"\n",
        "\n",
        "        if not self.heap:\n",
        "            return ()\n",
        "        score, item, extra_data = self.heap.pop(0)\n",
        "        self.unique_items.remove(item)\n",
        "        return (score, item, extra_data)\n",
        "\n",
        "\n",
        "# Adapted from https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/research/brain_coder/common/utils.py\n",
        "class UniquePriorityQueue(Queue):\n",
        "    \"\"\"A priority queue where duplicates are not added.\n",
        "\n",
        "    The top items by score remain in the queue. When the capacity is reached,\n",
        "    the lowest scored item in the queue will be dropped.\n",
        "    \"\"\"\n",
        "\n",
        "    def push(self, score, item, extra_data=None):\n",
        "        \"\"\"Push an item onto the queue.\n",
        "\n",
        "        If the queue is at capacity, the item with the smallest score will be\n",
        "        dropped. Note that it is assumed each item has exactly one score. The same\n",
        "        item with a different score will still be dropped.\n",
        "\n",
        "        Args:\n",
        "            score: Number used to prioritize items in the queue. Largest scores are\n",
        "                    kept in the queue.\n",
        "            item: A hashable item to be stored. Duplicates of this item will not be\n",
        "                    added to the queue.\n",
        "            extra_data: An extra (possible not hashable) data to store with the item.\n",
        "        \"\"\"\n",
        "        if item in self.unique_items:\n",
        "            return\n",
        "        if len(self.heap) >= self.capacity:\n",
        "            _, popped_item, _ = heapq.heappushpop(\n",
        "                self.heap, ItemContainer(score, item, extra_data))\n",
        "            self.unique_items.add(item)\n",
        "            self.unique_items.remove(popped_item)\n",
        "        else:\n",
        "            heapq.heappush(self.heap, ItemContainer(score, item, extra_data))\n",
        "            self.unique_items.add(item)\n",
        "\n",
        "    def pop(self):\n",
        "        \"\"\"Pop the item with the lowest score.\n",
        "\n",
        "        Returns:\n",
        "            score: Item's score.\n",
        "            item: The item that was popped.\n",
        "            extra_data: Any extra data stored with the item.\n",
        "        \"\"\"\n",
        "        if not self.heap:\n",
        "            return ()\n",
        "        score, item, extra_data = heapq.heappop(self.heap)\n",
        "        self.unique_items.remove(item)\n",
        "        return score, item, extra_data\n",
        "\n",
        "    def get_max(self):\n",
        "        \"\"\"Peek at the item with the highest score.\n",
        "\n",
        "        Returns:\n",
        "            Same as `pop`.\n",
        "        \"\"\"\n",
        "        if not self.heap:\n",
        "            return ()\n",
        "        score, item, extra_data = heapq.nlargest(1, self.heap)[0]\n",
        "        return score, item, extra_data\n",
        "\n",
        "    def get_min(self):\n",
        "        \"\"\"Peek at the item with the lowest score.\n",
        "\n",
        "        Returns:\n",
        "            Same as `pop`.\n",
        "        \"\"\"\n",
        "        if not self.heap:\n",
        "            return ()\n",
        "        score, item, extra_data = heapq.nsmallest(1, self.heap)[0]\n",
        "        return score, item, extra_data\n",
        "\n",
        "    def iter_in_order(self):\n",
        "        \"\"\"Iterate over items in the queue from largest score to smallest.\n",
        "\n",
        "        Yields:\n",
        "            item: Hashable item.\n",
        "            extra_data: Extra data stored with the item.\n",
        "        \"\"\"\n",
        "        for _, item, extra_data in heapq.nlargest(len(self.heap), self.heap):\n",
        "            yield item, extra_data\n",
        "\n",
        "\n",
        "class ProgramQueueMixin():\n",
        "    \"\"\"A mixin for Queues with additional utilities specific to Batch and\n",
        "    Program.\"\"\"\n",
        "\n",
        "    def __init__(self, policy=None):\n",
        "        self.policy = policy\n",
        "\n",
        "    def push_sample(self, sample, program):\n",
        "        \"\"\"\n",
        "        Push a single sample corresponding to Program to the queue.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        sample : Batch\n",
        "            A Batch comprising a single sample.\n",
        "\n",
        "        program : Program\n",
        "            Program corresponding to the sample.\n",
        "        \"\"\"\n",
        "\n",
        "        id_ = program.str\n",
        "        score = sample.rewards\n",
        "        self.push(score, id_, sample)\n",
        "\n",
        "    def push_batch(self, batch, programs):\n",
        "        \"\"\"Push a Batch corresponding to Programs to the queue.\"\"\"\n",
        "\n",
        "        for i, program in enumerate(programs):\n",
        "            sample = get_samples(batch, i)\n",
        "            self.push_sample(sample, program)\n",
        "\n",
        "    def push_best(self, batch, programs):\n",
        "        \"\"\"Push the single best sample from a Batch\"\"\"\n",
        "\n",
        "        i = np.argmax(batch.rewards)\n",
        "        sample = get_samples(batch, i)\n",
        "        program = programs[i]\n",
        "        self.push_sample(sample, program)\n",
        "\n",
        "    def sample_batch(self, sample_size):\n",
        "        \"\"\"Randomly select items from the queue and return them as a Batch.\"\"\"\n",
        "\n",
        "        assert len(self.heap) > 0, \"Cannot sample from an empty queue.\"\n",
        "        samples = [sample for (id_, sample) in self.random_sample(sample_size)]\n",
        "        batch = self._make_batch(samples)\n",
        "        return batch\n",
        "\n",
        "    def _make_batch(self, samples):\n",
        "        \"\"\"Turns a list of samples into a Batch.\"\"\"\n",
        "\n",
        "        # Pad up to max length across samples\n",
        "        max_len = max([s.actions.shape[0] for s in samples])\n",
        "        padded_aop = [pad_action_obs_priors(np.expand_dims(s.actions, axis=0),\n",
        "                                            np.expand_dims(s.obs, axis=0),\n",
        "                                            np.expand_dims(s.priors, axis=0),\n",
        "                                            pad_length=max_len - s.actions.shape[0]) for s in samples]\n",
        "\n",
        "        actions, obs, priors = zip(*padded_aop)\n",
        "        actions = np.concatenate(actions, axis=0)\n",
        "        obs = np.concatenate(obs, axis=0)\n",
        "        priors = np.concatenate(priors, axis=0)\n",
        "        lengths = np.array([s.lengths for s in samples], dtype=np.int32)\n",
        "        rewards = np.array([s.rewards for s in samples], dtype=np.float32)\n",
        "        on_policy = np.array([s.on_policy for s in samples], dtype=np.bool)\n",
        "        batch = Batch(actions=actions, obs=obs, priors=priors,\n",
        "                      lengths=lengths, rewards=rewards, on_policy=on_policy)\n",
        "        return batch\n",
        "\n",
        "    def to_batch(self):\n",
        "        \"\"\"Return the entire queue as a Batch.\"\"\"\n",
        "\n",
        "        samples = [container.extra_data for container in self.heap]\n",
        "        batch = self._make_batch(samples)\n",
        "        return batch\n",
        "\n",
        "    def compute_probs(self):\n",
        "        \"\"\"Computes the probabilities of items in the queue according to the\n",
        "        Policy.\"\"\"\n",
        "\n",
        "        if self.policy is None:\n",
        "            raise RuntimeError(\"Cannot compute probabilities. This Queue does \\\n",
        "                not have a Policy.\")\n",
        "        return self.policy.compute_probs(self.to_batch())\n",
        "\n",
        "    def get_rewards(self):\n",
        "        \"\"\"Returns the rewards\"\"\"\n",
        "\n",
        "        r = [container.extra_data.rewards for container in self.heap]\n",
        "        return r\n",
        "\n",
        "    def save(self, save_path):\n",
        "        \"\"\"Save the contents of the queue to file.\"\"\"\n",
        "\n",
        "        B = self.to_batch()\n",
        "        save_batch(B, save_path)\n",
        "\n",
        "    def load(self, load_path):\n",
        "        \"\"\"Load the contents of the queue from file.\"\"\"\n",
        "\n",
        "        B = load_batch(load_path)\n",
        "        programs = [from_tokens(np.array(tokens, dtype=np.int32)) for tokens in B.actions]\n",
        "        for p, r in zip(programs, B.rewards):\n",
        "            p.r = r\n",
        "        self.push_batch(B, programs)"
      ],
      "metadata": {
        "id": "VwTnIa8LHKzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#variance\n",
        "\n",
        "def quantile_variance(memory_queue, policy, batch_size, epsilon, step,\n",
        "                      n_experiments=1000, estimate_bias=True,\n",
        "                      n_samples_bias=1e6):\n",
        "\n",
        "    print(\"Running quantile variance/bias experiments...\")\n",
        "    empirical_quantiles = []\n",
        "    memory_augmented_quantiles = []\n",
        "\n",
        "    if len(memory_queue) < memory_queue.capacity:\n",
        "        print(\"WARNING: Memory queue not yet at capacity.\")\n",
        "\n",
        "    memory_r = memory_queue.get_rewards()\n",
        "    memory_w = memory_queue.compute_probs()\n",
        "    for exp in range(n_experiments):\n",
        "        actions, obs, priors = policy.sample(batch_size)\n",
        "        programs = [from_tokens(a) for a in actions]\n",
        "        r = np.array([p.r for p in programs])\n",
        "        quantile = np.quantile(r, 1 - epsilon, interpolation=\"higher\")\n",
        "        empirical_quantiles.append(quantile)\n",
        "        unique_programs = [p for p in programs if p.str not in memory_queue.unique_items]\n",
        "        N = len(unique_programs)\n",
        "        sample_r = [p.r for p in unique_programs]\n",
        "        combined_r = np.concatenate([memory_r, sample_r])\n",
        "        if N == 0:\n",
        "            print(\"WARNING: Found no unique samples in batch!\")\n",
        "            combined_w = memory_w / memory_w.sum() # Renormalize\n",
        "        else:\n",
        "            sample_w = np.repeat((1 - memory_w.sum()) / N, N)\n",
        "            combined_w = np.concatenate([memory_w, sample_w])\n",
        "\n",
        "        # Compute the weighted quantile\n",
        "        quantile = weighted_quantile(values=combined_r, weights=combined_w, q=1 - epsilon)\n",
        "        memory_augmented_quantiles.append(quantile)\n",
        "\n",
        "    empirical_quantiles = np.array(empirical_quantiles)\n",
        "    memory_augmented_quantiles = np.array(memory_augmented_quantiles)\n",
        "    print(\"Train step:\", step)\n",
        "    print(\"Memory weight:\", memory_w.sum())\n",
        "    print(\"Mean(empirical quantile):\", np.mean(empirical_quantiles))\n",
        "    print(\"Var(empirical quantile):\", np.var(empirical_quantiles))\n",
        "    print(\"Mean(Memory augmented quantile):\", np.mean(memory_augmented_quantiles))\n",
        "    print(\"Var(Memory augmented quantile):\", np.var(memory_augmented_quantiles))\n",
        "    if estimate_bias:\n",
        "        actions, obs, priors = policy.sample(int(n_samples_bias))\n",
        "        programs = [from_tokens(a) for a in actions]\n",
        "        r = np.array([p.r for p in programs])\n",
        "        true_quantile = np.quantile(r, 1 - epsilon, interpolation=\"higher\")\n",
        "        print(\"'True' empirical quantile:\", true_quantile)\n",
        "        print(\"Empirical quantile bias:\", np.mean(np.abs(empirical_quantiles - true_quantile)))\n",
        "        print(\"Memory-augmented quantile bias:\", np.mean(np.abs(memory_augmented_quantiles - true_quantile)))\n",
        "    exit()"
      ],
      "metadata": {
        "id": "jRXZ4tmaHYma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from itertools import compress"
      ],
      "metadata": {
        "id": "WF1oqsMZHuE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "W1vul3i4ICc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.random import set_seed\n"
      ],
      "metadata": {
        "id": "dhel3-bqIXHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf"
      ],
      "metadata": {
        "id": "cg-px5i3Ives"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "# Ignore TensorFlow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()  # Enable v1 behavior\n",
        "tf.set_random_seed(0)\n",
        "\n",
        "# Work for multiprocessing pool: compute reward\n",
        "def work(p):\n",
        "    \"\"\"Compute reward and return it with optimized constants\"\"\"\n",
        "    r = p.r\n",
        "    return p\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, sess, policy, policy_optimizer, gp_controller, logger,\n",
        "                 pool, n_samples=2000000, batch_size=1000, alpha=0.5,\n",
        "                 epsilon=0.05, verbose=True, baseline=\"R_e\",\n",
        "                 b_jumpstart=False, early_stopping=True, debug=0,\n",
        "                 use_memory=False, memory_capacity=1e3,  warm_start=None, memory_threshold=None,\n",
        "                 complexity=\"token\", const_optimizer=\"scipy\", const_params=None,  n_cores_batch=1):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the main training loop.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        sess : tf.Session\n",
        "            TensorFlow Session object.\n",
        "\n",
        "        policy : dso.policy.Policy\n",
        "            Parametrized probability distribution over discrete objects.\n",
        "            Used to generate programs and compute loglikelihoods.\n",
        "\n",
        "        policy_optimizer : dso.policy_optimizer.policy_optimizer\n",
        "            policy_optimizer object used to optimize the policy.\n",
        "\n",
        "        gp_controller : dso.gp.gp_controller.GPController or None\n",
        "            GP controller object used to generate Programs.\n",
        "\n",
        "        logger : dso.train_stats.StatsLogger\n",
        "            Logger to save results with\n",
        "\n",
        "        pool : multiprocessing.Pool or None\n",
        "            Pool to parallelize reward computation. For the control task, each\n",
        "            worker should have its own TensorFlow model. If None, a Pool will be\n",
        "            generated if n_cores_batch > 1.\n",
        "\n",
        "        n_samples : int or None, optional\n",
        "            Total number of objects to sample. This may be exceeded depending\n",
        "            on batch size.\n",
        "\n",
        "        batch_size : int, optional\n",
        "            Number of sampled expressions per iteration.\n",
        "\n",
        "        alpha : float, optional\n",
        "            Coefficient of exponentially-weighted moving average of baseline.\n",
        "\n",
        "        epsilon : float or None, optional\n",
        "            Fraction of top expressions used for training. None (or\n",
        "            equivalently, 1.0) turns off risk-seeking.\n",
        "\n",
        "        verbose : bool, optional\n",
        "            Whether to print progress.\n",
        "\n",
        "        baseline : str, optional\n",
        "            Type of baseline to use: grad J = (R - b) * grad-log-prob(expression).\n",
        "            Choices:\n",
        "            (1) \"ewma_R\" : b = EWMA(<R>)\n",
        "            (2) \"R_e\" : b = R_e\n",
        "            (3) \"ewma_R_e\" : b = EWMA(R_e)\n",
        "            (4) \"combined\" : b = R_e + EWMA(<R> - R_e)\n",
        "            In the above, <R> is the sample average _after_ epsilon sub-sampling and\n",
        "            R_e is the (1-epsilon)-quantile estimate.\n",
        "\n",
        "        b_jumpstart : bool, optional\n",
        "            Whether EWMA part of the baseline starts at the average of the first\n",
        "            iteration. If False, the EWMA starts at 0.0.\n",
        "\n",
        "        early_stopping : bool, optional\n",
        "            Whether to stop early if stopping criteria is reached.\n",
        "\n",
        "        debug : int, optional\n",
        "            Debug level, also passed to Controller. 0: No debug. 1: Print initial\n",
        "            parameter means. 2: Print parameter means each step.\n",
        "\n",
        "        use_memory : bool, optional\n",
        "            If True, use memory queue for reward quantile estimation.\n",
        "\n",
        "        memory_capacity : int\n",
        "            Capacity of memory queue.\n",
        "\n",
        "        warm_start : int or None\n",
        "            Number of samples to warm start the memory queue. If None, uses\n",
        "            batch_size.\n",
        "\n",
        "        memory_threshold : float or None\n",
        "            If not None, run quantile variance/bias estimate experiments after\n",
        "            memory weight exceeds memory_threshold.\n",
        "\n",
        "        complexity : str, optional\n",
        "            Not used\n",
        "\n",
        "        const_optimizer : str or None, optional\n",
        "            Not used\n",
        "\n",
        "        const_params : dict, optional\n",
        "            Not used\n",
        "\n",
        "        n_cores_batch : int, optional\n",
        "            Not used\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        self.sess = sess\n",
        "        # Initialize compute graph\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        self.policy = policy\n",
        "        self.policy_optimizer = policy_optimizer\n",
        "        self.gp_controller = gp_controller\n",
        "        self.logger = logger\n",
        "        self.pool = pool\n",
        "        self.n_samples = n_samples\n",
        "        self.batch_size = batch_size\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.verbose = verbose\n",
        "        self.baseline = baseline\n",
        "        self.b_jumpstart = b_jumpstart\n",
        "        self.early_stopping = early_stopping\n",
        "        self.debug = debug\n",
        "        self.use_memory = use_memory\n",
        "        self.memory_threshold = memory_threshold\n",
        "\n",
        "        if self.debug:\n",
        "            tvars = tf.trainable_variables()\n",
        "            def print_var_means():\n",
        "                tvars_vals = self.sess.run(tvars)\n",
        "                for var, val in zip(tvars, tvars_vals):\n",
        "                    print(var.name, \"mean:\", val.mean(), \"var:\", val.var())\n",
        "            self.print_var_means = print_var_means\n",
        "\n",
        "        # Create the priority_queue if needed\n",
        "        if hasattr(self.policy_optimizer, 'pqt_k'):\n",
        "            from dso.policy_optimizer.pqt_policy_optimizer import PQTPolicyOptimizer\n",
        "            assert type(self.policy_optimizer) == PQTPolicyOptimizer\n",
        "            # Create the priority queue\n",
        "            k = self.policy_optimizer.pqt_k\n",
        "            if k is not None and k > 0:\n",
        "                self.priority_queue = make_queue(priority=True, capacity=k)\n",
        "        else:\n",
        "            self.priority_queue = None\n",
        "\n",
        "        # Create the memory queue\n",
        "        if self.use_memory:\n",
        "            assert self.epsilon is not None and self.epsilon < 1.0, \\\n",
        "                \"Memory queue is only used with risk-seeking.\"\n",
        "            self.memory_queue = make_queue(policy=self.policy, priority=False,\n",
        "                                           capacity=int(memory_capacity))\n",
        "\n",
        "            # Warm start the queue\n",
        "            # TBD: Parallelize. Abstract sampling a Batch\n",
        "            warm_start = warm_start if warm_start is not None else self.batch_size\n",
        "            actions, obs, priors = policy.sample(warm_start)\n",
        "            programs = [from_tokens(a) for a in actions]\n",
        "            r = np.array([p.r for p in programs])\n",
        "            l = np.array([len(p.traversal) for p in programs])\n",
        "            on_policy = np.array([p.originally_on_policy for p in programs])\n",
        "            sampled_batch = Batch(actions=actions, obs=obs, priors=priors,\n",
        "                                  lengths=l, rewards=r, on_policy=on_policy)\n",
        "            self.memory_queue.push_batch(sampled_batch, programs)\n",
        "        else:\n",
        "            self.memory_queue = None\n",
        "\n",
        "        self.nevals = 0 # Total number of sampled expressions (from RL or GP)\n",
        "        self.iteration = 0 # Iteration counter\n",
        "        self.r_best = -np.inf\n",
        "        self.p_r_best = None\n",
        "        self.done = False\n",
        "\n",
        "    def run_one_step(self, override=None):\n",
        "        \"\"\"\n",
        "        Executes one step of main training loop. If override is given,\n",
        "        train on that batch. Otherwise, sample the batch to train on.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        override : tuple or None\n",
        "            Tuple of (actions, obs, priors, programs) to train on offline\n",
        "            samples instead of sampled\n",
        "        \"\"\"\n",
        "        positional_entropy = None\n",
        "        top_samples_per_batch = list()\n",
        "        if self.debug >= 1:\n",
        "            print(\"\\nDEBUG: Policy parameter means:\")\n",
        "            self.print_var_means()\n",
        "\n",
        "        ewma = None if self.b_jumpstart else 0.0 # EWMA portion of baseline\n",
        "\n",
        "        start_time = time.time()\n",
        "        if self.verbose:\n",
        "            print(\"-- RUNNING ITERATIONS START -------------\")\n",
        "\n",
        "\n",
        "        # Number of extra samples generated during attempt to get\n",
        "        # batch_size new samples\n",
        "        n_extra = 0\n",
        "        # Record previous cache before new samples are added by from_tokens\n",
        "        s_history = list(Program.cache.keys())\n",
        "\n",
        "        # Construct the actions, obs, priors, and programs\n",
        "        # Shape of actions: (batch_size, max_length)\n",
        "        # Shape of obs: (batch_size, obs_dim, max_length)\n",
        "        # Shape of priors: (batch_size, max_length, n_choices)\n",
        "        if override is None:\n",
        "            # Sample batch of Programs from the Controller\n",
        "            actions, obs, priors = self.policy.sample(self.batch_size)\n",
        "            programs = [from_tokens(a) for a in actions]\n",
        "        else:\n",
        "            # Train on the given batch of Programs\n",
        "            actions, obs, priors, programs = override\n",
        "            for p in programs:\n",
        "                Program.cache[p.str] = p\n",
        "\n",
        "        # Extra samples, previously already contained in cache,\n",
        "        # that were geneated during the attempt to get\n",
        "        # batch_size new samples for expensive reward evaluation\n",
        "        if self.policy.valid_extended_batch:\n",
        "            self.policy.valid_extended_batch = False\n",
        "            n_extra = self.policy.extended_batch[0]\n",
        "            if n_extra > 0:\n",
        "                extra_programs = [from_tokens(a) for a in\n",
        "                                  self.policy.extended_batch[1]]\n",
        "                # Concatenation is fine because rnn_policy.sample_novel()\n",
        "                # already made sure that offline batch and extended batch\n",
        "                # are padded to the same trajectory length\n",
        "                actions = np.concatenate([actions, self.policy.extended_batch[1]])\n",
        "                obs = np.concatenate([obs, self.policy.extended_batch[2]])\n",
        "                priors = np.concatenate([priors, self.policy.extended_batch[3]])\n",
        "                programs = programs + extra_programs\n",
        "\n",
        "        self.nevals += self.batch_size + n_extra\n",
        "\n",
        "        # Run GP seeded with the current batch, returning elite samples\n",
        "        if self.gp_controller is not None:\n",
        "            deap_programs, deap_actions, deap_obs, deap_priors = self.gp_controller(actions)\n",
        "            self.nevals += self.gp_controller.nevals\n",
        "\n",
        "            # Pad AOP if different sized\n",
        "            if actions.shape[1] < deap_actions.shape[1]:\n",
        "                # If RL shape is smaller than GP then pad\n",
        "                pad_length = deap_actions.shape[1] - actions.shape[1]\n",
        "                actions, obs, priors = pad_action_obs_priors(actions, obs, priors, pad_length)\n",
        "            elif actions.shape[1] > deap_actions.shape[1]:\n",
        "                # If GP shape is smaller than RL then pad\n",
        "                pad_length = actions.shape[1] - deap_actions.shape[1]\n",
        "                deap_actions, deap_obs, deap_priors = pad_action_obs_priors(deap_actions, deap_obs, deap_priors, pad_length)\n",
        "\n",
        "            # Combine RNN and deap programs, actions, obs, and priors\n",
        "            programs = programs + deap_programs\n",
        "            actions = np.append(actions, deap_actions, axis=0)\n",
        "            obs = np.append(obs, deap_obs, axis=0)\n",
        "            priors = np.append(priors, deap_priors, axis=0)\n",
        "\n",
        "        # Compute rewards in parallel\n",
        "        if self.pool is not None:\n",
        "            # Filter programs that need reward computing\n",
        "            programs_to_optimize = list(set([p for p in programs if \"r\" not in p.__dict__]))\n",
        "            pool_p_dict = { p.str : p for p in self.pool.map(work, programs_to_optimize) }\n",
        "            programs = [pool_p_dict[p.str] if \"r\" not in p.__dict__  else p for p in programs]\n",
        "            # Make sure to update cache with new programs\n",
        "            Program.cache.update(pool_p_dict)\n",
        "\n",
        "        # Compute rewards (or retrieve cached rewards)\n",
        "        r = np.array([p.r for p in programs])\n",
        "\n",
        "        # Back up programs to save them properly later\n",
        "        controller_programs = programs.copy() if self.logger.save_token_count else None\n",
        "\n",
        "        # Need for Vanilla Policy Gradient (epsilon = null)\n",
        "        l           = np.array([len(p.traversal) for p in programs])\n",
        "        s           = [p.str for p in programs] # Str representations of Programs\n",
        "        on_policy   = np.array([p.originally_on_policy for p in programs])\n",
        "        invalid     = np.array([p.invalid for p in programs], dtype=bool)\n",
        "\n",
        "        if self.logger.save_positional_entropy:\n",
        "            positional_entropy = np.apply_along_axis(empirical_entropy, 0, actions)\n",
        "\n",
        "        if self.logger.save_top_samples_per_batch > 0:\n",
        "            # sort in descending order: larger rewards -> better solutions\n",
        "            sorted_idx = np.argsort(r)[::-1]\n",
        "            top_perc = int(len(programs) * float(self.logger.save_top_samples_per_batch))\n",
        "            for idx in sorted_idx[:top_perc]:\n",
        "                top_samples_per_batch.append([self.iteration, r[idx], repr(programs[idx])])\n",
        "\n",
        "        # Store in variables the values for the whole batch (those variables will be modified below)\n",
        "        r_full = r\n",
        "        l_full = l\n",
        "        s_full = s\n",
        "        actions_full = actions\n",
        "        invalid_full = invalid\n",
        "        r_max = np.max(r)\n",
        "\n",
        "        \"\"\"\n",
        "        Apply risk-seeking policy gradient: compute the empirical quantile of\n",
        "        rewards and filter out programs with lesser reward.\n",
        "        \"\"\"\n",
        "        if self.epsilon is not None and self.epsilon < 1.0:\n",
        "            # Compute reward quantile estimate\n",
        "            if self.use_memory: # Memory-augmented quantile\n",
        "                # Get subset of Programs not in buffer\n",
        "                unique_programs = [p for p in programs \\\n",
        "                                   if p.str not in self.memory_queue.unique_items]\n",
        "                N = len(unique_programs)\n",
        "\n",
        "                # Get rewards\n",
        "                memory_r = self.memory_queue.get_rewards()\n",
        "                sample_r = [p.r for p in unique_programs]\n",
        "                combined_r = np.concatenate([memory_r, sample_r])\n",
        "\n",
        "                # Compute quantile weights\n",
        "                memory_w = self.memory_queue.compute_probs()\n",
        "                if N == 0:\n",
        "                    print(\"WARNING: Found no unique samples in batch!\")\n",
        "                    combined_w = memory_w / memory_w.sum() # Renormalize\n",
        "                else:\n",
        "                    sample_w = np.repeat((1 - memory_w.sum()) / N, N)\n",
        "                    combined_w = np.concatenate([memory_w, sample_w])\n",
        "\n",
        "                # Quantile variance/bias estimates\n",
        "                if self.memory_threshold is not None:\n",
        "                    print(\"Memory weight:\", memory_w.sum())\n",
        "                    if memory_w.sum() > self.memory_threshold:\n",
        "                        quantile_variance(self.memory_queue, self.policy, self.batch_size, self.epsilon, self.iteration)\n",
        "\n",
        "                # Compute the weighted quantile\n",
        "                quantile = weighted_quantile(values=combined_r, weights=combined_w, q=1 - self.epsilon)\n",
        "\n",
        "            else: # Empirical quantile\n",
        "                quantile = np.quantile(r, 1 - self.epsilon, interpolation=\"higher\")\n",
        "\n",
        "            # Filter quantities whose reward >= quantile\n",
        "            keep = r >= quantile\n",
        "            l = l[keep]\n",
        "            s = list(compress(s, keep))\n",
        "            invalid = invalid[keep]\n",
        "            r = r[keep]\n",
        "            programs  = list(compress(programs, keep))\n",
        "            actions = actions[keep, :]\n",
        "            obs = obs[keep, :, :]\n",
        "            priors = priors[keep, :, :]\n",
        "            on_policy = on_policy[keep]\n",
        "\n",
        "        # Clip bounds of rewards to prevent NaNs in gradient descent\n",
        "        r = np.clip(r, -1e6, 1e6)\n",
        "\n",
        "        # Compute baseline\n",
        "        # NOTE: pg_loss = tf.reduce_mean((self.r - self.baseline) * neglogp, name=\"pg_loss\")\n",
        "        if self.baseline == \"ewma_R\":\n",
        "            ewma = np.mean(r) if ewma is None else self.alpha*np.mean(r) + (1 - self.alpha)*ewma\n",
        "            b = ewma\n",
        "        elif self.baseline == \"R_e\": # Default\n",
        "            ewma = -1\n",
        "            b = quantile\n",
        "        elif self.baseline == \"ewma_R_e\":\n",
        "            ewma = np.min(r) if ewma is None else self.alpha*quantile + (1 - self.alpha)*ewma\n",
        "            b = ewma\n",
        "        elif self.baseline == \"combined\":\n",
        "            ewma = np.mean(r) - quantile if ewma is None else self.alpha*(np.mean(r) - quantile) + (1 - self.alpha)*ewma\n",
        "            b = quantile + ewma\n",
        "\n",
        "        # Compute sequence lengths\n",
        "        lengths = np.array([min(len(p.traversal), self.policy.max_length)\n",
        "                            for p in programs], dtype=np.int32)\n",
        "\n",
        "        # Create the Batch\n",
        "        sampled_batch = Batch(actions=actions, obs=obs, priors=priors,\n",
        "                              lengths=lengths, rewards=r, on_policy=on_policy)\n",
        "\n",
        "        # Update and sample from the priority queue\n",
        "        if self.priority_queue is not None:\n",
        "            self.priority_queue.push_best(sampled_batch, programs)\n",
        "            pqt_batch = self.priority_queue.sample_batch(self.policy_optimizer.pqt_batch_size)\n",
        "            # Train the policy\n",
        "            summaries = self.policy_optimizer.train_step(b, sampled_batch, pqt_batch)\n",
        "        else:\n",
        "            pqt_batch = None\n",
        "            # Train the policy\n",
        "            summaries = self.policy_optimizer.train_step(b, sampled_batch)\n",
        "\n",
        "        # Walltime calculation for the iteration\n",
        "        iteration_walltime = time.time() - start_time\n",
        "\n",
        "        # Update the memory queue\n",
        "        if self.memory_queue is not None:\n",
        "            self.memory_queue.push_batch(sampled_batch, programs)\n",
        "\n",
        "        # Update new best expression\n",
        "        if r_max > self.r_best:\n",
        "            self.r_best = r_max\n",
        "            self.p_r_best = programs[np.argmax(r)]\n",
        "\n",
        "            # Print new best expression\n",
        "            if self.verbose or self.debug:\n",
        "                print(\"[{}] Training iteration {}, current best R: {:.4f}\".format(get_duration(start_time), self.iteration + 1, self.r_best))\n",
        "                print(\"\\n\\t** New best\")\n",
        "                self.p_r_best.print_stats()\n",
        "\n",
        "        # Collect sub-batch statistics and write output\n",
        "        self.logger.save_stats(r_full, l_full, actions_full, s_full,\n",
        "                               invalid_full, r, l, actions, s, s_history,\n",
        "                               invalid, self.r_best, r_max, ewma, summaries,\n",
        "                               self.iteration, b, iteration_walltime,\n",
        "                               self.nevals, controller_programs,\n",
        "                               positional_entropy, top_samples_per_batch)\n",
        "\n",
        "\n",
        "        # Stop if early stopping criteria is met\n",
        "        if self.early_stopping and self.p_r_best.evaluate.get(\"success\"):\n",
        "            print(\"[{}] Early stopping criteria met; breaking early.\".format(get_duration(start_time)))\n",
        "            self.done = True\n",
        "\n",
        "        if self.verbose and (self.iteration + 1) % 10 == 0:\n",
        "            print(\"[{}] Training iteration {}, current best R: {:.4f}\".format(get_duration(start_time), self.iteration + 1, self.r_best))\n",
        "\n",
        "        if self.debug >= 2:\n",
        "            print(\"\\nParameter means after iteration {}:\".format(self.iteration + 1))\n",
        "            self.print_var_means()\n",
        "\n",
        "        if self.nevals >= self.n_samples:\n",
        "            self.done = True\n",
        "\n",
        "        # Increment the iteration counter\n",
        "        self.iteration += 1\n",
        "\n",
        "    def save(self, save_path):\n",
        "        \"\"\"\n",
        "        Save the state of the Trainer.\n",
        "        \"\"\"\n",
        "\n",
        "        state_dict = {\n",
        "            \"nevals\" : self.nevals,\n",
        "            \"iteration\" : self.iteration,\n",
        "            \"r_best\" : self.r_best,\n",
        "            \"p_r_best_tokens\" : self.p_r_best.tokens.tolist() if self.p_r_best is not None else None\n",
        "        }\n",
        "        with open(save_path, 'w') as f:\n",
        "            json.dump(state_dict, f)\n",
        "\n",
        "        print(\"Saved Trainer state to {}.\".format(save_path))\n",
        "\n",
        "    def load(self, load_path):\n",
        "        \"\"\"\n",
        "        Load the state of the Trainer.\n",
        "        \"\"\"\n",
        "\n",
        "        with open(load_path, 'r') as f:\n",
        "            state_dict = json.load(f)\n",
        "\n",
        "        # Load nevals and iteration from savestate\n",
        "        self.nevals = state_dict[\"nevals\"]\n",
        "        self.iteration = state_dict[\"iteration\"]\n",
        "\n",
        "        # Load r_best and p_r_best\n",
        "        if state_dict[\"p_r_best_tokens\"] is not None:\n",
        "            tokens = np.array(state_dict[\"p_r_best_tokens\"], dtype=np.int32)\n",
        "            self.p_r_best = from_tokens(tokens)\n",
        "        else:\n",
        "            self.p_r_best = None\n",
        "\n",
        "        print(\"Loaded Trainer state from {}.\".format(load_path))"
      ],
      "metadata": {
        "id": "TWW-ddhwHu-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint\n",
        "\n",
        "class Checkpoint():\n",
        "    \"\"\"\n",
        "    A helper class to checkpoint models.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    save\n",
        "        Save a checkpoint.\n",
        "\n",
        "    load\n",
        "        Load from a given checkpoint.\n",
        "\n",
        "    update\n",
        "        Maybe save a checkpoint depending on frequency configuration.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, load_path=None, save_freq=23, units=\"hours\",\n",
        "                 save_on_done=False):\n",
        "        \"\"\"\n",
        "        model : dso.DeepSymbolicOptimizer\n",
        "            The model to checkpoint.\n",
        "\n",
        "        load_path : str or None\n",
        "            Path to initial checkpoint directory to load. If None, do not start from\n",
        "            checkpoint.\n",
        "\n",
        "        save_freq : float or None\n",
        "            The frequency at which to save a checkpoint. If None, non-final checkpoints\n",
        "            will not be automatically saved.\n",
        "\n",
        "        units : str\n",
        "            The units of save_freq. Supports \"hours\", \"minutes\", \"seconds\", \"iterations\".\n",
        "\n",
        "        save_on_done : bool\n",
        "            Whether to save a final checkpoint upon reaching model.trainer.done.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = model\n",
        "        if model.save_path is not None:\n",
        "            self.checkpoint_dir = os.path.join(model.save_path, \"checkpoint\")\n",
        "            os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "        else:\n",
        "            self.checkpoint_dir = None\n",
        "\n",
        "        # Create the Saver\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "        # Load from existing checkpoint, if given\n",
        "        if load_path is not None:\n",
        "            self.load(load_path)\n",
        "\n",
        "        # Setup time-based checkpointing\n",
        "        if save_freq is not None and units in [\"hours\", \"minutes\", \"seconds\"]:\n",
        "            if units == \"hours\":\n",
        "                self.dt = timedelta(hours=save_freq)\n",
        "            elif units == \"minutes\":\n",
        "                self.dt = timedelta(minutes=save_freq)\n",
        "            elif units == \"seconds\":\n",
        "                self.dt = timedelta(seconds=save_freq)\n",
        "            self.next_save_time = datetime.now() + self.dt\n",
        "        else:\n",
        "            self.next_save_time = None\n",
        "            self.dt = None\n",
        "\n",
        "        # Setup iteration-based checkpointing\n",
        "        if save_freq is not None and units == \"iterations\":\n",
        "            self.save_freq_iters = save_freq\n",
        "        else:\n",
        "            self.save_freq_iters = None\n",
        "\n",
        "        self.save_on_done = save_on_done\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Maybe a save a checkpoint, depending on configuration. This should be called\n",
        "        each iteration, i.e. after model.trainer.run_one_step().\n",
        "        \"\"\"\n",
        "\n",
        "        # Save final checkpoint if done\n",
        "        if self.save_on_done and self.model.trainer.done:\n",
        "            self.save()\n",
        "\n",
        "        # Save if time-based frequency is met\n",
        "        elif self.next_save_time is not None and datetime.now() > self.next_save_time:\n",
        "            self.save()\n",
        "            self.next_save_time = datetime.now() + self.dt\n",
        "\n",
        "        # Save if iteration-based frequency is met\n",
        "        elif self.save_freq_iters is not None and (self.model.trainer.iteration % self.save_freq_iters) == 0:\n",
        "            self.save()\n",
        "\n",
        "    def save(self, save_path=None):\n",
        "        \"\"\"\n",
        "        Save a checkpoint.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        save_path : str or None\n",
        "            Directory in which to save checkpoint. If None, save in:\n",
        "            <self.model.save_path>/checkpoint/checkpoint_<timestamp>.\n",
        "        \"\"\"\n",
        "\n",
        "        # Determine the save path\n",
        "        if save_path is None:\n",
        "            assert self.checkpoint_dir is not None, \"Cannot support automated checkpointing with model.save_dir=None.\"\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "            save_path = os.path.join(self.checkpoint_dir,\n",
        "                                    \"checkpoint_{}\".format(timestamp))\n",
        "        if os.path.exists(save_path):\n",
        "            paths = os.listdir(os.path.dirname(save_path))\n",
        "            paths = [path for path in paths if path.startswith(os.path.basename(save_path))]\n",
        "            save_path += \"_{}\".format(len(paths))\n",
        "        os.makedirs(save_path, exist_ok=False)\n",
        "\n",
        "        # Save the TensorFlow graph\n",
        "        # print(\"Saving TensorFlow graph...\")\n",
        "        tf_save_path = os.path.join(save_path, \"tf\")\n",
        "        self.saver.save(self.model.sess, tf_save_path)\n",
        "\n",
        "        # Save the Trainer\n",
        "        # print(\"Saving Trainer...\")\n",
        "        trainer_save_path = os.path.join(save_path, \"trainer.json\")\n",
        "        self.model.trainer.save(trainer_save_path)\n",
        "\n",
        "        # Save the priority queue, if applicable\n",
        "        # TBD: This should be in self.model.trainer.save or self.model.trainer.policy_optimizer.save after refactoring PolicyOptimizers to handle their own bookkeeping\n",
        "        if self.model.trainer.priority_queue is not None:\n",
        "            priority_queue_save_path = os.path.join(save_path, \"priority_queue.npz\")\n",
        "            self.model.trainer.priority_queue.save(priority_queue_save_path)\n",
        "\n",
        "        # Save the cache\n",
        "        # print(\"Saving cache...\")\n",
        "        # TBD: Abstract into cache saving function\n",
        "        cache_save_path = os.path.join(save_path, \"cache.csv\")\n",
        "        cache_programs = Program.cache.values()\n",
        "        cache_tokens = [\",\".join(map(str, p.tokens.tolist())) for p in cache_programs]\n",
        "        cache_rewards = [p.r for p in cache_programs]\n",
        "        cache_data = { \"tokens\" : cache_tokens, \"rewards\" : cache_rewards }\n",
        "        cache_df = pd.DataFrame(cache_data)\n",
        "        cache_df.to_csv(cache_save_path, index=False)\n",
        "\n",
        "        # Save the extra samples that were produced while attempting to\n",
        "        # generate a batch of new and unique samples\n",
        "        if self.model.trainer.policy.valid_extended_batch:\n",
        "            self.model.trainer.policy.valid_extended_batch = False\n",
        "            batch_save_path = os.path.join(save_path, \"batch.npz\")\n",
        "            with open(batch_save_path, 'wb') as f:\n",
        "                np.savez(f, self.model.trainer.policy.extended_batch)\n",
        "\n",
        "    def load(self, load_path):\n",
        "        \"\"\"\n",
        "        Load model state from checkpoint.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        load_path : str\n",
        "            Checkpoint directory to load model state.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load the TensorFlow graph\n",
        "        if self.model.sess is None:\n",
        "            self.model.setup()\n",
        "        tf_load_path = os.path.join(load_path, \"tf\")\n",
        "        self.saver.restore(self.model.sess, tf_load_path)\n",
        "\n",
        "        # Load the Trainer\n",
        "        # print(\"Loading Trainer...\")\n",
        "        trainer_load_path = os.path.join(load_path, \"trainer.json\")\n",
        "        self.model.trainer.load(trainer_load_path)\n",
        "\n",
        "        # Load the priority queue, if applicable\n",
        "        # TBD: This should be in self.model.trainer.load or self.model.trainer.policy_optimizer.load after refactoring PolicyOptimizers to handle their own bookkeeping\n",
        "        if self.model.trainer.priority_queue is not None:\n",
        "            priority_queue_load_path = os.path.join(load_path, \"priority_queue.npz\")\n",
        "            self.model.trainer.priority_queue.load(priority_queue_load_path)\n",
        "\n",
        "        # Load the cache\n",
        "        # print(\"Loading cache...\")\n",
        "        cache_load_path = os.path.join(load_path, \"cache.csv\")\n",
        "        cache_df = pd.read_csv(cache_load_path)\n",
        "        cache_df[\"tokens\"] = cache_df[\"tokens\"].str.split(\",\")\n",
        "        programs = [from_tokens(np.array(tokens, dtype=np.int32)) for tokens in cache_df[\"tokens\"]]\n",
        "        for p, r in zip(programs, cache_df[\"rewards\"]):\n",
        "            p.r = r\n",
        "\n",
        "        # Load the extra samples\n",
        "        batch_save_path = os.path.join(load_path, \"batch.npz\")\n",
        "        if os.path.isfile(batch_save_path):\n",
        "            npzfile = np.load(batch_save_path, allow_pickle=True)\n",
        "            self.model.trainer.policy.extended_batch = npzfile['arr_0']\n",
        "            self.model.trainer.policy.valid_extended_batch = True"
      ],
      "metadata": {
        "id": "CK5sqRNIJE9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO, BytesIO\n",
        "import shutil\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "yeNanef8JH3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_stats\n",
        "#These functions are defined globally so they are pickleable and can be used by Pool.map\n",
        "def hof_work(p):\n",
        "    return [p.r, p.on_policy_count, p.off_policy_count, repr(p.sympy_expr), repr(p), p.evaluate]\n",
        "\n",
        "def pf_work(p):\n",
        "    return [p.complexity, p.r, p.on_policy_count, p.off_policy_count, repr(p.sympy_expr), repr(p), p.evaluate]\n",
        "\n",
        "\n",
        "class StatsLogger():\n",
        "    \"\"\" Class responsible for dealing with output files of training statistics.\n",
        "        It encapsulates all outputs to files.\"\"\"\n",
        "\n",
        "    def __init__(self, sess, output_file, save_summary=False, save_all_iterations=False, hof=100,\n",
        "                 save_pareto_front=True, save_positional_entropy=False, save_top_samples_per_batch=0,\n",
        "                 save_cache=False, save_cache_r_min=0.9, save_freq=1, save_token_count=False):\n",
        "\n",
        "        \"\"\"\"\n",
        "        sess : tf.Session\n",
        "            TenorFlow Session object (used for generating summary files)\n",
        "\n",
        "        output_file : str\n",
        "            Filename to write results for each iteration.\n",
        "\n",
        "        save_summary : bool, optional\n",
        "            Whether to write TensorFlow summaries.\n",
        "\n",
        "        save_all_iterations : bool, optional\n",
        "            Whether to save statistics for all programs for each iteration.\n",
        "\n",
        "        hof : int or None, optional\n",
        "            Number of top Programs to evaluate after training.\n",
        "\n",
        "        save_pareto_front : bool, optional\n",
        "            If True, compute and save the Pareto front at the end of training.\n",
        "\n",
        "        save_positional_entropy : bool, optional\n",
        "            Whether to save evolution of positional entropy for each iteration.\n",
        "\n",
        "        save_top_samples_per_batch : float, optional\n",
        "            Whether to store the X% (float) top-performer samples in every batch to a csv file.\n",
        "\n",
        "        save_cache : bool\n",
        "            Whether to save the str, count, and r of each Program in the cache.\n",
        "\n",
        "        save_cache_r_min : float or None\n",
        "            If not None, only keep Programs with r >= r_min when saving cache.\n",
        "\n",
        "        save_freq : int or None\n",
        "            Statistics are flushed to file every save_freq iterations (default == 1). If < 0, uses save_freq = inf\n",
        "\n",
        "        save_token_count : bool\n",
        "            Wether to count used tokens in each iteration\n",
        "        \"\"\"\n",
        "        self.sess = sess\n",
        "        self.output_file = output_file\n",
        "        self.save_summary = save_summary\n",
        "        self.save_all_iterations = save_all_iterations\n",
        "        self.hof = hof\n",
        "        self.save_pareto_front = save_pareto_front\n",
        "        self.save_positional_entropy = save_positional_entropy\n",
        "        self.save_top_samples_per_batch = save_top_samples_per_batch\n",
        "        self.save_cache = save_cache\n",
        "        self.save_cache_r_min = save_cache_r_min\n",
        "        self.save_token_count = save_token_count\n",
        "        self.all_r = []   # save all R separately to keep backward compatibility with a generated file.\n",
        "\n",
        "        if save_freq is None:\n",
        "            self.buffer_frequency = 1\n",
        "        elif save_freq < 1:\n",
        "            self.buffer_frequency = float('inf')\n",
        "        else:\n",
        "            self.buffer_frequency = save_freq\n",
        "\n",
        "        self.buffer_iteration_stats = StringIO() # Buffer for iteration statistics\n",
        "        self.buffer_all_programs = StringIO() # Buffer for the statistics for all programs.\n",
        "        self.buffer_token_stats = StringIO() # Buffer for iteration statistics\n",
        "        self.buffer_top_samples = StringIO() # Buffer for top samples per batch\n",
        "        self.buffer_pos_entropy = BytesIO()  # Buffer for positional entropy\n",
        "\n",
        "        self.setup_output_files()\n",
        "\n",
        "    def setup_output_files(self):\n",
        "        \"\"\"\n",
        "        Opens and prepares all output log files controlled by this class.\n",
        "        \"\"\"\n",
        "        if self.output_file is not None:\n",
        "            os.makedirs(os.path.dirname(self.output_file), exist_ok=True)\n",
        "            prefix, _ = os.path.splitext(self.output_file)\n",
        "            self.all_r_output_file = \"{}_all_r.npy\".format(prefix)\n",
        "            self.all_info_output_file = \"{}_all_info.csv\".format(prefix)\n",
        "            self.hof_output_file = \"{}_hof.csv\".format(prefix)\n",
        "            self.pf_output_file = \"{}_pf.csv\".format(prefix)\n",
        "            self.positional_entropy_output_file = \"{}_positional_entropy.npy\".format(prefix)\n",
        "            self.top_samples_per_batch_output_file = \"{}_top_samples_per_batch.csv\".format(prefix)\n",
        "            self.cache_output_file = \"{}_cache.csv\".format(prefix)\n",
        "            self.token_counter_output_file = \"{}_token_count.csv\".format(prefix)\n",
        "            with open(self.output_file, 'w') as f:\n",
        "                # r_best : Maximum across all iterations so far\n",
        "                # r_max : Maximum across this iteration's batch\n",
        "                # r_avg_full : Average across this iteration's full batch (before taking epsilon subset)\n",
        "                # r_avg_sub : Average across this iteration's epsilon-subset batch\n",
        "                # n_unique_* : Number of unique Programs in batch\n",
        "                # n_novel_* : Number of never-before-seen Programs per batch\n",
        "                # a_ent_* : Empirical positional entropy across sequences averaged over positions\n",
        "                # invalid_avg_* : Fraction of invalid Programs per batch\n",
        "                # baseline: Baseline value used for training\n",
        "                # time: time used to learn in this iteration (in seconds)\n",
        "                headers = [\"r_best\",\n",
        "                           \"r_max\",\n",
        "                           \"r_avg_full\",\n",
        "                           \"r_avg_sub\",\n",
        "                           \"l_avg_full\",\n",
        "                           \"l_avg_sub\",\n",
        "                           \"ewma\",\n",
        "                           \"n_unique_full\",\n",
        "                           \"n_unique_sub\",\n",
        "                           \"n_novel_full\",\n",
        "                           \"n_novel_sub\",\n",
        "                           \"a_ent_full\",\n",
        "                           \"a_ent_sub\",\n",
        "                           \"invalid_avg_full\",\n",
        "                           \"invalid_avg_sub\",\n",
        "                           \"baseline\",\n",
        "                           \"time\",\n",
        "                           \"nevals\"]\n",
        "                f.write(\"{}\\n\".format(\",\".join(headers)))\n",
        "            if self.save_all_iterations:\n",
        "                with open(self.all_info_output_file, 'w') as f:\n",
        "                    # iteration : The iteration in which this line was saved\n",
        "                    # r : reward for this program\n",
        "                    # l : length of the program\n",
        "                    # invalid : if the program is invalid\n",
        "                    headers = [\"iteration\",\n",
        "                                \"r\",\n",
        "                                \"l\",\n",
        "                                \"invalid\"]\n",
        "                    f.write(\"{}\\n\".format(\",\".join(headers)))\n",
        "            if self.save_token_count:\n",
        "                with open(self.token_counter_output_file, 'w') as f:\n",
        "                    headers = [str(token) for token in Program.library.tokens]\n",
        "                    f.write(\"{}\\n\".format(\",\".join(headers)))\n",
        "\n",
        "        else:\n",
        "            self.all_r_output_file = None\n",
        "            self.all_info_output_file = None\n",
        "            self.hof_output_file = None\n",
        "            self.pf_output_file = None\n",
        "            self.positional_entropy_output_file = None\n",
        "            self.top_samples_per_batch_output_file = None\n",
        "            self.cache_output_file = None\n",
        "            self.token_counter_output_file = None\n",
        "\n",
        "        # Create summary writer\n",
        "        if self.save_summary:\n",
        "            if self.output_file is not None:\n",
        "                summary_dir = \"{}_summary\".format(prefix)\n",
        "            else:\n",
        "                timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "                summary_dir = os.path.join(\"summary\", timestamp)\n",
        "            self.summary_writer = tf.summary.FileWriter(summary_dir, self.sess.graph)\n",
        "        else:\n",
        "            self.summary_writer = None\n",
        "\n",
        "    def save_stats(self, r_full, l_full, actions_full, s_full, invalid_full, r,\n",
        "                   l, actions, s, s_history, invalid, r_best, r_max, ewma,\n",
        "                   summaries, iteration, baseline, iteration_walltime, nevals,\n",
        "                   programs, positional_entropy, top_samples_per_batch):\n",
        "\n",
        "        \"\"\"\n",
        "        Computes and saves all statistics that are computed for every time step. Depending on the value of\n",
        "            self.buffer_frequency, the statistics might be instead saved in a buffer before going to disk.\n",
        "        :param r_full: The reward of all programs\n",
        "        :param l_full: The length of all programs\n",
        "        :param actions_full: all actions sampled this step\n",
        "        :param s_full: String representation of all programs sampled this step.\n",
        "        :param invalid_full: boolean for all programs sampled showing if they are invalid\n",
        "        :param r: r_full excluding the ones where keep=false\n",
        "        :param l: l_full excluding the ones where keep=false\n",
        "        :param actions: actions_full excluding the ones where keep=false\n",
        "        :param s: s_full excluding the ones where keep=false\n",
        "        :param s_history: String representation of programs in cache excluding s_full\n",
        "        :param invalid: invalid_full excluding the ones where keep=false\n",
        "        :param r_best: reward from the all time best program so far\n",
        "        :param r_max: reward from the best program in this iteration\n",
        "        :param ewma: Exponentially Weighted Moving Average weight that might be used for baseline computation\n",
        "        :param summaries: Sumarries returned by the Controller this step\n",
        "        :param iteration: This iteration id\n",
        "        :param baseline: baseline value used for training\n",
        "        :param iteration_walltime: time taken to process this iteration\n",
        "        :param nevals: number of function evaluations\n",
        "        :param programs: A batch of controller programs\n",
        "        :param positional_entropy: current positional_entropy\n",
        "        :param top_samples_per_batch: list containing top solutions on the last batch\n",
        "        \"\"\"\n",
        "        iteration = iteration + 1 # Change from 0- to 1-based indexing\n",
        "        if self.output_file is not None:\n",
        "            r_avg_full = np.mean(r_full)\n",
        "\n",
        "            l_avg_full = np.mean(l_full)\n",
        "            a_ent_full = np.mean(np.apply_along_axis(empirical_entropy, 0, actions_full))\n",
        "            n_unique_full = len(set(s_full))\n",
        "            n_novel_full = len(set(s_full).difference(s_history))\n",
        "            invalid_avg_full = np.mean(invalid_full)\n",
        "\n",
        "            r_avg_sub = np.mean(r)\n",
        "            l_avg_sub = np.mean(l)\n",
        "            a_ent_sub = np.mean(np.apply_along_axis(empirical_entropy, 0, actions))\n",
        "            n_unique_sub = len(set(s))\n",
        "            n_novel_sub = len(set(s).difference(s_history))\n",
        "            invalid_avg_sub = np.mean(invalid)\n",
        "            stats = np.array([[\n",
        "                r_best,\n",
        "                r_max,\n",
        "                r_avg_full,\n",
        "                r_avg_sub,\n",
        "                l_avg_full,\n",
        "                l_avg_sub,\n",
        "                ewma,\n",
        "                n_unique_full,\n",
        "                n_unique_sub,\n",
        "                n_novel_full,\n",
        "                n_novel_sub,\n",
        "                a_ent_full,\n",
        "                a_ent_sub,\n",
        "                invalid_avg_full,\n",
        "                invalid_avg_sub,\n",
        "                baseline,\n",
        "                iteration_walltime,\n",
        "                nevals\n",
        "            ]], dtype=np.float32)\n",
        "            np.savetxt(self.buffer_iteration_stats, stats, delimiter=',')\n",
        "        if self.save_all_iterations:\n",
        "            all_iteration_stats = np.array([\n",
        "                              [iteration] * len(r_full),\n",
        "                              r_full,\n",
        "                              l_full,\n",
        "                              invalid_full\n",
        "                              ]).transpose()\n",
        "            df = pd.DataFrame(all_iteration_stats)\n",
        "            df.to_csv(self.buffer_all_programs, mode='a', header=False, index=False, line_terminator='\\n')\n",
        "\n",
        "        # Collect stats about used tokens and write to buffer\n",
        "        if self.save_token_count:\n",
        "            self.write_token_count(programs)\n",
        "\n",
        "        # summary writers have their own buffer\n",
        "        if self.save_summary:\n",
        "            self.summary_writer.add_summary(summaries, iteration)\n",
        "\n",
        "        # Should the buffer be saved now?\n",
        "        if iteration % self.buffer_frequency == 0:\n",
        "            self.flush_buffers()\n",
        "\n",
        "        #Backwards compatibility of all_r numpy file\n",
        "        if self.save_all_iterations:\n",
        "            self.all_r.append(r_full)\n",
        "\n",
        "        if self.save_positional_entropy:\n",
        "            #with open(self.buffer_pos_entropy, 'ab') as f:\n",
        "                # saves only the last positional entropy\n",
        "            np.save(self.buffer_pos_entropy, positional_entropy)\n",
        "\n",
        "        if self.save_top_samples_per_batch > 0:\n",
        "            df_topsamples = pd.DataFrame(top_samples_per_batch,\n",
        "                                         columns=['Iteration', 'Reward', 'Sequence'])\n",
        "            # only save to the file the current iteration\n",
        "            header = iteration == 1\n",
        "            df_topsamples.to_csv(self.buffer_top_samples, mode='a', index=False, header=header)\n",
        "\n",
        "    def save_results(self, pool, n_samples):\n",
        "        \"\"\"\n",
        "        Saves stats that are available only after all iterations are finished\n",
        "        :param pool: Pool used to parallelize reward computation\n",
        "        :param n_samples: Total number of samples\n",
        "        \"\"\"\n",
        "        # First of all, saves any pending buffer\n",
        "        self.flush_buffers()\n",
        "\n",
        "        if self.save_all_iterations:\n",
        "            # Check if all batches are the same size\n",
        "            batch_sizes = np.array([batch.shape[0] for batch in self.all_r])\n",
        "            if np.all(batch_sizes == batch_sizes[0]):\n",
        "                all_r_padded = self.all_r\n",
        "            else:\n",
        "                max_batch_size = np.max([batch.shape[0] for batch in self.all_r])\n",
        "                all_r_padded = []\n",
        "                for batch in self.all_r:\n",
        "                    n_pad = max_batch_size - batch.shape[0]\n",
        "                    all_r_padded.append(np.pad(\n",
        "                        batch, pad_width=(0,n_pad), mode='constant',\n",
        "                        constant_values=-np.inf))\n",
        "            #Kept all_r numpy file for backwards compatibility.\n",
        "            with open(self.all_r_output_file, 'ab') as f:\n",
        "                all_r = np.array(all_r_padded, dtype=np.float32)\n",
        "                np.save(f, all_r)\n",
        "\n",
        "        result = {}\n",
        "\n",
        "        # Save the hall of fame\n",
        "        if self.hof is not None and self.hof > 0:\n",
        "            assert not Program.task.stochastic, \"HOF only supported for deterministic Tasks.\"\n",
        "            programs = list(Program.cache.values())  # All unique Programs found during training\n",
        "            r = [p.r for p in programs]\n",
        "            i_hof = np.argsort(r)[-self.hof:][::-1]  # Indices of top hof Programs\n",
        "            hof = [programs[i] for i in i_hof]\n",
        "\n",
        "            if pool is not None:\n",
        "                results = pool.map(hof_work, hof)\n",
        "            else:\n",
        "                results = list(map(hof_work, hof))\n",
        "\n",
        "            eval_keys = list(results[0][-1].keys())\n",
        "            columns = [\"r\", \"count_on_policy\", \"count_off_policy\", \"expression\", \"traversal\"] + eval_keys\n",
        "            hof_results = [result[:-1] + [result[-1][k] for k in eval_keys] for result in results]\n",
        "            df = pd.DataFrame(hof_results, columns=columns)\n",
        "            if self.hof_output_file is not None:\n",
        "                print(\"Saving Hall of Fame to {}\".format(self.hof_output_file))\n",
        "                df.to_csv(self.hof_output_file, header=True, index=False)\n",
        "\n",
        "        # Save cache\n",
        "        if self.save_cache and Program.cache:\n",
        "            print(\"Saving cache to {}\".format(self.cache_output_file))\n",
        "            cache_data = [(repr(p), p.on_policy_count, p.off_policy_count, p.r) for p in Program.cache.values()]\n",
        "            df_cache = pd.DataFrame(cache_data)\n",
        "            df_cache.columns = [\"str\", \"count_on_policy\", \"count_off_policy\", \"r\"]\n",
        "            if self.save_cache_r_min is not None:\n",
        "                df_cache = df_cache[df_cache[\"r\"] >= self.save_cache_r_min]\n",
        "            df_cache.to_csv(self.cache_output_file, header=True, index=False)\n",
        "\n",
        "        # Compute the pareto front\n",
        "        if self.save_pareto_front:\n",
        "\n",
        "            assert not Program.task.stochastic, \"Pareto front only supported for deterministic Tasks.\"\n",
        "\n",
        "            all_programs = list(Program.cache.values())\n",
        "            costs = np.array([(p.complexity, -p.r) for p in all_programs])\n",
        "            pareto_efficient_mask = is_pareto_efficient(costs)  # List of bool\n",
        "            pf = list(compress(all_programs, pareto_efficient_mask))\n",
        "            pf.sort(key=lambda p: p.complexity) # Sort by complexity\n",
        "\n",
        "            if pool is not None:\n",
        "                results = pool.map(pf_work, pf)\n",
        "            else:\n",
        "                results = list(map(pf_work, pf))\n",
        "\n",
        "            eval_keys = list(results[0][-1].keys())\n",
        "            columns = [\"complexity\", \"r\", \"count_on_policy\", \"count_off_policy\", \"expression\", \"traversal\"] + eval_keys\n",
        "            pf_results = [result[:-1] + [result[-1][k] for k in eval_keys] for result in results]\n",
        "            df = pd.DataFrame(pf_results, columns=columns)\n",
        "            if self.pf_output_file is not None:\n",
        "                print(\"Saving Pareto Front to {}\".format(self.pf_output_file))\n",
        "                df.to_csv(self.pf_output_file, header=True, index=False)\n",
        "\n",
        "            # Look for a success=True case within the Pareto front\n",
        "            for p in pf:\n",
        "                if p.evaluate.get(\"success\"):\n",
        "                    p_final = p\n",
        "                    break\n",
        "\n",
        "        #Save error summaries\n",
        "        # Print error statistics of the cache\n",
        "        n_invalid = 0\n",
        "        error_types = defaultdict(lambda: 0)\n",
        "        error_nodes = defaultdict(lambda: 0)\n",
        "\n",
        "        result = {}\n",
        "        for p in Program.cache.values():\n",
        "            if p.invalid:\n",
        "                count = p.off_policy_count + p.on_policy_count\n",
        "                n_invalid += count\n",
        "                error_types[p.error_type] += count\n",
        "                error_nodes[p.error_node] += count\n",
        "\n",
        "        if n_invalid > 0:\n",
        "            print(\"Invalid expressions: {} of {} ({:.1%}).\".format(n_invalid, n_samples,\n",
        "                                                                    n_invalid / n_samples))\n",
        "            print(\"Error type counts:\")\n",
        "            for error_type, count in error_types.items():\n",
        "                print(\"  {}: {} ({:.1%})\".format(error_type, count, count / n_invalid))\n",
        "                result[\"error_\"+str(error_type)] = count\n",
        "            print(\"Error node counts:\")\n",
        "            for error_node, count in error_nodes.items():\n",
        "                print(\"  {}: {} ({:.1%})\".format(error_node, count, count / n_invalid))\n",
        "                result[\"error_node_\" + str(error_node)] = count\n",
        "\n",
        "        result['n_samples'] = n_samples\n",
        "        result['n_cached'] = len(Program.cache)\n",
        "        return result\n",
        "\n",
        "    def write_token_count(self, programs):\n",
        "        token_counter = {token: 0 for token in Program.library.names}\n",
        "        for program in programs:\n",
        "            for token in program.traversal:\n",
        "                token_counter[token.name] += 1\n",
        "        stats = np.array([[\n",
        "            token_counter[token] for token in token_counter.keys()\n",
        "        ]], dtype=np.int)\n",
        "        np.savetxt(self.buffer_token_stats, stats, fmt='%i', delimiter=',')\n",
        "\n",
        "    def flush_buffers(self):\n",
        "        \"\"\"Write all available buffers to file.\"\"\"\n",
        "        if self.output_file is not None:\n",
        "            self.buffer_iteration_stats = self.flush_buffer(\n",
        "                self.buffer_iteration_stats, self.output_file)\n",
        "        if self.save_all_iterations:\n",
        "            self.buffer_all_programs = self.flush_buffer(\n",
        "                self.buffer_all_programs, self.all_info_output_file)\n",
        "        if self.save_token_count:\n",
        "            self.buffer_token_stats = self.flush_buffer(\n",
        "                self.buffer_token_stats, self.token_counter_output_file)\n",
        "        if self.save_top_samples_per_batch > 0 and self.output_file is not None:\n",
        "            self.buffer_top_samples = self.flush_buffer(\n",
        "                self.buffer_top_samples, self.top_samples_per_batch_output_file)\n",
        "        if self.save_positional_entropy:\n",
        "            self.buffer_pos_entropy = self.flush_buffer(\n",
        "                self.buffer_pos_entropy, self.positional_entropy_output_file, byte_buffer=True)\n",
        "        if self.summary_writer:\n",
        "            self.summary_writer.flush()\n",
        "\n",
        "    def flush_buffer(self, buffer, output_file, byte_buffer=False):\n",
        "        \"\"\"\n",
        "        Write specific buffer to corresponding output file.\n",
        "        :param buffer: Buffer that will be flushed\n",
        "        :param output_file: File to which the buffer will be flushed\n",
        "        :param byte_buffer: If true, assume the buffer is in String format,\n",
        "            otherwise, that it is in bytes format\n",
        "        \"\"\"\n",
        "        mode = 'ab' if byte_buffer else 'a'\n",
        "        with open(output_file, mode) as f:\n",
        "            buffer.seek(0)\n",
        "            shutil.copyfileobj(buffer, f, -1)\n",
        "        # clear buffer\n",
        "        return BytesIO() if byte_buffer else StringIO()"
      ],
      "metadata": {
        "id": "aK8jRGUIJWo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dyn_rnn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RNN, LSTM, Dropout, Dense\n",
        "from tensorflow.compat.v1.nn.rnn_cell import BasicRNNCell\n",
        "\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "class LanguageModel(object):\n",
        "    def __init__(self, vocabulary_size, embedding_size, num_layers, num_hidden, mode='train'):\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.x = tf.compat.v1.placeholder(tf.int32, [None, None], name=\"x\") # whole seq + seq len\n",
        "        self.keep_prob = tf.compat.v1.placeholder(tf.float32, [], name=\"keep_prob\")\n",
        "        self.batch_size = tf.compat.v1.shape(self.x)[0]\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.lm_input = self.x[:, :-2]\n",
        "            self.seq_len = self.x[:, -1]\n",
        "        elif mode == 'predict':\n",
        "            self.lm_input = self.x[:,:]\n",
        "            self.seq_len = tf.reduce_sum(tf.sign(self.lm_input), 1)\n",
        "\n",
        "        # Embedding (optional)\n",
        "        with tf.name_scope(\"embedding\"):\n",
        "            init_embeddings = tf.random.uniform([vocabulary_size, self.embedding_size])\n",
        "            embeddings = tf.compat.v1.get_variable(\"embeddings\", initializer=init_embeddings)\n",
        "            lm_input_emb = tf.nn.embedding_lookup(embeddings, self.lm_input)\n",
        "\n",
        "        with tf.compat.v1.variable_scope(\"rnn\"):\n",
        "            def make_cell():\n",
        "                cell = BasicRNNCell(self.num_hidden)  # Or use LSTM(...) for better performance\n",
        "                cell = Dropout(1 - self.keep_prob)(cell)\n",
        "                return cell\n",
        "\n",
        "            cell = RNN([make_cell() for _ in range(self.num_layers)])\n",
        "\n",
        "            self.initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
        "            rnn_outputs, self.last_state = tf.nn.dynamic_rnn(\n",
        "                cell=cell,\n",
        "                initial_state=self.initial_state,\n",
        "                inputs=lm_input_emb,  # Assuming you're using embeddings\n",
        "                sequence_length=self.seq_len,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        with tf.name_scope(\"output\"):\n",
        "            self.logits = Dense(vocabulary_size)(rnn_outputs)  # Use tf.layers.dense for TF < 2.0\n",
        "\n",
        "        with tf.name_scope(\"loss\"):\n",
        "            if mode == \"train\":\n",
        "                target = self.x[:, 1:-1]\n",
        "            elif mode == \"predict\":\n",
        "                target = self.x[:, :]\n",
        "\n",
        "            self.loss = SparseCategoricalCrossentropy(from_logits=True)(target, self.logits)\n"
      ],
      "metadata": {
        "id": "lf2VEsypMKug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#language_model_prior\n",
        "\n",
        "class LanguageModelPrior(object):\n",
        "    \"\"\"\n",
        "    Language model to get prior for DSO, given token.\n",
        "\n",
        "    History of tokens of a sequence is holded as a state of language model.\n",
        "    Usage: LanguageModelPrior.get_lm_prior(token)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dso_library: dso.library.Library\n",
        "        Library used in main DSO model\n",
        "\n",
        "    model_path: str\n",
        "        Path to separately trained mathematical language model to use as prior\n",
        "\n",
        "    lib_path: str\n",
        "        Path to token library of mathematical language model\n",
        "\n",
        "    embedding_size: int\n",
        "    num_layers: int\n",
        "    num_hidden: int\n",
        "        Model architecture of loaded mathematical language model\n",
        "\n",
        "    prob_sharing: bool\n",
        "        Share probabilities among terminal tokens?\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dso_library,\n",
        "                model_path=\"./language_model/model/saved_model\",\n",
        "                lib_path=\"./language_model/model/saved_model/word_dict.pkl\",\n",
        "                embedding_size=32, num_layers=1, num_hidden=256,\n",
        "                prob_sharing=True\n",
        "                ):\n",
        "\n",
        "        self.dso_n_input_var = len(dso_library.input_tokens)\n",
        "        self.prob_sharing = prob_sharing\n",
        "\n",
        "        with open(lib_path, 'rb') as f:\n",
        "            self.lm_token2idx = pickle.load(f)\n",
        "        self.dso2lm, self.lm2dso = self.set_lib_to_lib(dso_library)\n",
        "\n",
        "        self.language_model = LanguageModel(len(self.lm_token2idx), embedding_size, num_layers, num_hidden, mode='predict')\n",
        "        self.lsess = self.load_model(model_path)\n",
        "        self.next_state = None\n",
        "        self._zero_state = np.zeros(num_hidden, dtype=np.float32)\n",
        "\n",
        "    def load_model(self, saved_language_model_path):\n",
        "        sess = tf.compat.v1.Session()\n",
        "        saver = tf.train.Saver()\n",
        "        saver.restore(sess,tf.train.latest_checkpoint(saved_language_model_path))\n",
        "        return sess\n",
        "\n",
        "    def set_lib_to_lib(self, dso_library):\n",
        "        \"\"\"match token libraries of DSO and lm (LanguageModel)\"\"\"\n",
        "\n",
        "        # dso token -> lm token\n",
        "        dso2lm = [self.lm_token2idx['TERMINAL']] * self.dso_n_input_var\n",
        "        dso2lm += [self.lm_token2idx[t.name.lower()] for t in dso_library.tokens if t.input_var is None] # ex) [1,1,1,2,3,4,5,6,7,8,9], len(dso2lm) = len(library of dso)\n",
        "\n",
        "        # lm token -> DSO token\n",
        "        lm2dso = {lm_idx: i for i, lm_idx in enumerate(dso2lm)}\n",
        "\n",
        "        # TODO: if DSO token missing in lm token library\n",
        "\n",
        "        return dso2lm, lm2dso\n",
        "\n",
        "    def get_lm_prior(self, next_input):\n",
        "        \"\"\"return language model prior based on given current token\"\"\"\n",
        "\n",
        "        # set feed_dict\n",
        "        next_input = np.array(self.dso2lm)[next_input]  # match library with DSO\n",
        "        next_input = np.array([next_input])\n",
        "\n",
        "        if self.next_state is None: # first input of a sequence\n",
        "            # For dynamic_rnn, not passing language_model.initial_state == passing zero_state.\n",
        "            # Here, explicitly passing zero_state\n",
        "            self.next_state = np.atleast_2d(self._zero_state) # initialize the cell\n",
        "\n",
        "        feed_dict = {self.language_model.x: next_input, self.language_model.keep_prob: 1.0, self.language_model.initial_state: self.next_state}\n",
        "\n",
        "        # get language model prior\n",
        "        self.next_state, lm_logit = self.lsess.run([self.language_model.last_state, self.language_model.logits], feed_dict=feed_dict)\n",
        "\n",
        "        if self.prob_sharing is True:\n",
        "            # sharing probability among tokens in same group (e.g., TERMINAL to multiple variables)\n",
        "            lm_logit[:, :, self.lm_token2idx['TERMINAL']] = lm_logit[:, :, self.lm_token2idx['TERMINAL']] - np.log(self.dso_n_input_var)\n",
        "        lm_prior = lm_logit[0, :, self.dso2lm]\n",
        "        lm_prior = np.transpose(lm_prior) # make its shape to (batch size, dso size)\n",
        "\n",
        "        return lm_prior"
      ],
      "metadata": {
        "id": "rPHZsgZeNDle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prior\n",
        "def make_prior(library, config_prior):\n",
        "    \"\"\"Factory function for JointPrior object.\"\"\"\n",
        "\n",
        "    config_prior = deepcopy(config_prior)\n",
        "\n",
        "    prior_dict = {\n",
        "        \"relational\" : RelationalConstraint,\n",
        "        \"length\" : LengthConstraint,\n",
        "        \"repeat\" : RepeatConstraint,\n",
        "        \"inverse\" : InverseUnaryConstraint,\n",
        "        \"trig\" : TrigConstraint,\n",
        "        \"const\" : ConstConstraint,\n",
        "        \"no_inputs\" : NoInputsConstraint,\n",
        "        \"soft_length\" : SoftLengthPrior,\n",
        "        \"uniform_arity\" : UniformArityPrior,\n",
        "        \"domain_range\" : DomainRangeConstraint,\n",
        "        \"language_model\" : LanguageModelPrior,\n",
        "        \"multi_discrete\" : MultiDiscreteConstraint\n",
        "    }\n",
        "\n",
        "    count_constraints = config_prior.pop(\"count_constraints\", False)\n",
        "\n",
        "    priors = []\n",
        "    warn_messages = []\n",
        "    for prior_type, prior_args in config_prior.items():\n",
        "        if prior_type in prior_dict:\n",
        "            prior_class = prior_dict[prior_type]\n",
        "        else:\n",
        "            # Tries to import custom priors\n",
        "            prior_class = import_custom_source(prior_type)\n",
        "\n",
        "        if isinstance(prior_args, dict):\n",
        "            prior_args = [prior_args]\n",
        "        for single_prior_args in prior_args:\n",
        "            # Attempt to build the Prior. Any Prior can fail if it references a\n",
        "            # Token not in the Library.\n",
        "            prior_is_enabled = single_prior_args.pop('on', False)\n",
        "            if prior_is_enabled:\n",
        "                try:\n",
        "                    prior = prior_class(library, **single_prior_args)\n",
        "                    warn_message = prior.validate()\n",
        "                except TokenNotFoundError:\n",
        "                    prior = None\n",
        "                    warn_message = \"Uses Tokens not in the Library.\"\n",
        "            else:\n",
        "                prior = None\n",
        "                warn_message = \"Prior disabled.\"\n",
        "\n",
        "            # Add warning context\n",
        "            if warn_message is not None:\n",
        "                warn_message = \"Skipping invalid '{}' with arguments {}. \" \\\n",
        "                    \"Reason: {}\" \\\n",
        "                    .format(prior_class.__name__, single_prior_args, warn_message)\n",
        "                warn_messages.append(warn_message)\n",
        "\n",
        "            # Add the Prior if there are no warnings\n",
        "            if warn_message is None:\n",
        "                priors.append(prior)\n",
        "\n",
        "    # Turn PolyConstraint \"on\" if and only if \"poly\" token is in library\n",
        "    if \"poly\" in library.names:\n",
        "        priors.append(PolyConstraint(library))\n",
        "\n",
        "    # Turn StateCheckerConstraint \"on\" if and only if StateChecker is in library\n",
        "    if len(library.state_checker_tokens) > 0:\n",
        "        priors.append(StateCheckerConstraint(library))\n",
        "\n",
        "    joint_prior = JointPrior(library, priors, count_constraints)\n",
        "\n",
        "    print(\"-- BUILDING PRIOR START -------------\")\n",
        "    print(\"\\n\".join([\"WARNING: \" + message for message in warn_messages]))\n",
        "    print(joint_prior.describe())\n",
        "    print(\"-- BUILDING PRIOR END ---------------\\n\")\n",
        "\n",
        "    return joint_prior\n",
        "\n",
        "\n",
        "class JointPrior():\n",
        "    \"\"\"A collection of joint Priors.\"\"\"\n",
        "\n",
        "    def __init__(self, library, priors, count_constraints=False):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        library : Library\n",
        "            The Library associated with the Priors.\n",
        "\n",
        "        priors : list of Prior\n",
        "            The individual Priors to be joined.\n",
        "\n",
        "        count_constraints : bool\n",
        "            Whether to count the number of constrained tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        self.library = library\n",
        "        self.L = self.library.L\n",
        "        self.priors = priors\n",
        "        assert all([prior.library is library for prior in priors]), \\\n",
        "            \"All Libraries must be identical.\"\n",
        "\n",
        "        # Name the priors, e.g. RepeatConstraint-0\n",
        "        counts = defaultdict(lambda : -1)\n",
        "        self.names = []\n",
        "        for prior in self.priors:\n",
        "            name = prior.__class__.__name__\n",
        "            counts[name] += 1\n",
        "            self.names.append(\"{}-{}\".format(name, counts[name]))\n",
        "\n",
        "        # Initialize variables for constraint count report\n",
        "        self.do_count = count_constraints\n",
        "        self.constraint_counts = [0] * len(self.priors)\n",
        "        self.total_constraints = 0\n",
        "        self.total_tokens = 0\n",
        "\n",
        "        self.requires_parents_siblings = True # TBD: Determine\n",
        "\n",
        "        # SPECIAL CASE: Set DomainRangeConstraint.max_length if constraining max length\n",
        "        length_prior = None\n",
        "        domain_range_prior = None\n",
        "        for prior in self.priors:\n",
        "            if isinstance(prior, LengthConstraint):\n",
        "                length_prior = prior\n",
        "            elif isinstance(prior, DomainRangeConstraint):\n",
        "                domain_range_prior = prior\n",
        "        if length_prior is not None and domain_range_prior is not None:\n",
        "            domain_range_prior.max_length = length_prior.max\n",
        "\n",
        "        self.describe()\n",
        "\n",
        "    def initial_prior(self):\n",
        "        combined_prior = np.zeros((self.L,), dtype=np.float32)\n",
        "        for prior in self.priors:\n",
        "            combined_prior += prior.initial_prior()\n",
        "        return combined_prior\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling, finished):\n",
        "\n",
        "        # Filter out finished sequences to save compute\n",
        "        unfinished = ~finished\n",
        "        final_combined_prior = np.zeros((actions.shape[0], self.L), dtype=np.float32)\n",
        "        unfinished_actions = actions[unfinished]\n",
        "        unfinished_parent = parent[unfinished]\n",
        "        unfinished_sibling = sibling[unfinished]\n",
        "        unfinished_dangling = dangling[unfinished]\n",
        "\n",
        "        # Sum the individual priors\n",
        "        zero_prior = np.zeros((unfinished_actions.shape[0], self.L), dtype=np.float32)\n",
        "        ind_priors = [zero_prior.copy() for _ in range(len(self.priors))]\n",
        "        for i in range(len(self.priors)):\n",
        "            ind_priors[i] += self.priors[i](unfinished_actions, unfinished_parent, unfinished_sibling, unfinished_dangling)\n",
        "        combined_prior = sum(ind_priors) + zero_prior # TBD FIX HACK\n",
        "\n",
        "        # Count number of constrained tokens per prior\n",
        "        if self.do_count:\n",
        "            self.total_tokens += unfinished_actions.shape[0] * self.library.L\n",
        "            for i in range(len(self.constraint_counts)):\n",
        "                self.constraint_counts[i] += np.count_nonzero(ind_priors[i] == -np.inf)\n",
        "            self.total_constraints += np.count_nonzero(combined_prior == -np.inf)\n",
        "\n",
        "        # Give status report if a prior contains all -inf\n",
        "        collision_mask = np.all(np.isneginf(combined_prior), axis=1)\n",
        "        if np.any(collision_mask):\n",
        "            collisions = collision_mask.nonzero()[0] # Indices of collisions\n",
        "            msg = []\n",
        "            msg.append(\"ERROR in {}:\".format(__file__))\n",
        "            msg.append(\"Encountered collision(s) in prior. This occurs when a prior contains all -inf values. \" +\n",
        "                       \"This typically indicates a logic error in a prior formulation, or a 'collision' when \" +\n",
        "                       \"configuring multiple priors that are not always compatible. See the table(s) below \" +\n",
        "                       \"for which priors caused each collision. X's indicate a value of -inf.\")\n",
        "            for i, collision in enumerate(collisions):\n",
        "                msg.append(\"\\n----- Collision {} of {} -----\".format(i + 1, len(collisions)))\n",
        "                msg.append(\"Traversal: {}\".format(self.library.tokenize(unfinished_actions[collision])))\n",
        "                table = PrettyTable([\"Prior\"] + self.library.names)\n",
        "                for j, ind_prior in enumerate(ind_priors):\n",
        "                    if np.any(np.isneginf(ind_prior[collision])):\n",
        "                        name = self.priors[j].__class__.__name__\n",
        "                        row = [\"X\" if x == -np.inf else \"\" for x in ind_prior[collision]]\n",
        "                        table.add_row([name] + row)\n",
        "                msg.append(repr(table))\n",
        "            # msg.append(\"\\nApplication will now exit.\")\n",
        "            print(\"\\n\".join(msg))\n",
        "            # os._exit(1) # Bypass tensorflow exception-handling\n",
        "\n",
        "        final_combined_prior[unfinished] = combined_prior\n",
        "\n",
        "        return final_combined_prior\n",
        "\n",
        "    def report_constraint_counts(self):\n",
        "        if not self.do_count:\n",
        "            return\n",
        "        print(\"Constraint counts per prior:\")\n",
        "        for i, count in enumerate(self.constraint_counts):\n",
        "            print(\"{}: {} ({:%})\".format(self.names[i], count, count / self.total_tokens))\n",
        "        print(\"All priors: {} ({:%})\".format(self.total_constraints, self.total_constraints / self.total_tokens))\n",
        "\n",
        "    def describe(self):\n",
        "        message = \"\\n\".join(prior.describe() for prior in self.priors)\n",
        "        return message\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        for prior in self.priors:\n",
        "            if isinstance(prior, Constraint):\n",
        "                if prior.is_violated(actions, parent, sibling):\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def at_once(self, actions, parent, sibling):\n",
        "        \"\"\"\n",
        "        Given a full sequence of actions, parents, and siblings, each of shape\n",
        "        (batch, time), *retrospectively* compute what was the joint prior at all\n",
        "        time steps. The combined prior has shape (batch, time, L).\n",
        "        \"\"\"\n",
        "\n",
        "        B, T = actions.shape\n",
        "        zero_prior = np.zeros((B, T, self.L), dtype=np.float32) # (batch, time, L)\n",
        "        ind_priors = [zero_prior.copy() for _ in range(len(self.priors))] # i x (batch, time, L)\n",
        "\n",
        "        if len(self.priors) == 0:\n",
        "            return zero_prior\n",
        "\n",
        "        # Set initial prior\n",
        "        # Note: intial_prior() is already a combined prior, so we just set the\n",
        "        # first individual prior, ind_priors[0].\n",
        "        initial_prior = self.initial_prior() # Shape (L,)\n",
        "        ind_priors[0][:, 0, :] = initial_prior # Broadcast to (batch, L)\n",
        "\n",
        "        dangling = np.ones(B)\n",
        "        for t in range(1, T): # For each time step\n",
        "            # Update dangling based on previously sampled token\n",
        "            dangling += self.library.arities[actions[:, (t - 1)]] - 1\n",
        "            for i in range(len(self.priors)): # For each Prior\n",
        "                # Compute the ith Prior at time step t\n",
        "                prior = self.priors[i](actions[:, :t],\n",
        "                                       parent[:, t],\n",
        "                                       sibling[:, t],\n",
        "                                       dangling) # Shape (batch, L)\n",
        "                ind_priors[i][:, t, :] += prior\n",
        "\n",
        "        # Combine all Priors\n",
        "        combined_prior = sum(ind_priors) + zero_prior\n",
        "\n",
        "        return combined_prior\n",
        "\n",
        "\n",
        "class Prior():\n",
        "    \"\"\"Abstract class whose call method return logits.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        self.library = library\n",
        "        self.L = library.L\n",
        "        self.mask_val = -np.inf\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Determine whether the Prior has a valid configuration. This is useful\n",
        "        when other algorithmic parameters may render the Prior degenerate. For\n",
        "        example, having a TrigConstraint with no trig Tokens.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        message : str or None\n",
        "            Error message if Prior is invalid, or None if it is valid.\n",
        "        \"\"\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    def init_zeros(self, actions):\n",
        "        \"\"\"Helper function to generate a starting prior of zeros.\"\"\"\n",
        "\n",
        "        batch_size = actions.shape[0]\n",
        "        prior = np.zeros((batch_size, self.L), dtype=np.float32)\n",
        "        return prior\n",
        "\n",
        "    def initial_prior(self):\n",
        "        \"\"\"\n",
        "        Compute the initial prior, before any actions are selected.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        initial_prior : array\n",
        "            Initial logit adjustment before actions are selected. Shape is\n",
        "            (self.L,) as it will be broadcast to batch size later.\n",
        "        \"\"\"\n",
        "\n",
        "        return np.zeros((self.L,), dtype=np.float32)\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        \"\"\"\n",
        "        Compute the prior (logit adjustment) given the history of actions\n",
        "        and the current observation.\n",
        "\n",
        "        actions : np.ndarray (dtype=np.int32)\n",
        "            History of all actions so far. Each action is a Library index.\n",
        "            Shape is (batch_size, current_time).\n",
        "\n",
        "        parent : np.ndarray (dtype=np.in32)\n",
        "            Adjusted Library indices of parent of the token being selected.\n",
        "            Shape is (batch_size,).\n",
        "\n",
        "        sibling : np.ndarray (dtype=np.int32)\n",
        "            Library indices of sibling of the token being selected.\n",
        "            Shape is (batch_size,).\n",
        "\n",
        "        dangling : np.ndarray (dtype=np.int32)\n",
        "            Current number of dangling/unselected nodes.\n",
        "            Shape is (batch_size,).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        prior : np.ndarray (dtype=np.float32)\n",
        "            Logit adjustment for selecting next action.\n",
        "            Shape is (batch_size, self.L).\n",
        "        \"\"\"\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def describe(self):\n",
        "        \"\"\"Describe the Prior.\"\"\"\n",
        "\n",
        "        return \"{}: No description available.\".format(self.__class__.__name__)\n",
        "\n",
        "\n",
        "class Constraint(Prior):\n",
        "    def __init__(self, library):\n",
        "        Prior.__init__(self, library)\n",
        "\n",
        "    def make_constraint(self, mask, tokens):\n",
        "        \"\"\"\n",
        "        Generate the prior for a batch of constraints and the corresponding\n",
        "        Tokens to constrain.\n",
        "\n",
        "        For example, with L=5 and tokens=[1,2], a constrained row of the prior\n",
        "        will be: [0.0, -np.inf, -np.inf, 0.0, 0.0].\n",
        "\n",
        "        Parameters\n",
        "        __________\n",
        "\n",
        "        mask : np.ndarray, shape=(?,), dtype=np.bool_\n",
        "            Boolean mask of samples to constrain.\n",
        "\n",
        "        tokens : np.ndarray, dtype=np.int32\n",
        "            Tokens to constrain.\n",
        "\n",
        "        Returns\n",
        "        _______\n",
        "\n",
        "        prior : np.ndarray, shape=(?, L), dtype=np.float32\n",
        "            Logit adjustment. Since these are hard constraints, each element is\n",
        "            either 0.0 or -np.inf.\n",
        "        \"\"\"\n",
        "        prior = np.zeros((mask.shape[0], self.L), dtype=np.float32)\n",
        "\n",
        "        for t in tokens:\n",
        "            prior[mask, t] = self.mask_val\n",
        "        return prior\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        \"\"\"\n",
        "        Given a set of actions, tells us if a prior constraint has been violated\n",
        "        post hoc.\n",
        "\n",
        "        This is a generic version that will run using the __call__ function so that one\n",
        "        does not have to write a function twice for both DSO and Deap.\n",
        "\n",
        "        >>>HOWEVER<<<\n",
        "\n",
        "        Using this function is less optimal than writing a variant for Deap. So...\n",
        "\n",
        "        If you create a constraint and find you use if often with Deap, you should go ahead and\n",
        "        write the optimal version.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        violated : Bool\n",
        "        \"\"\"\n",
        "\n",
        "        caller          = inspect.getframeinfo(inspect.stack()[1][0])\n",
        "\n",
        "        warnings.warn(\"{} ({}) {} : Using a slower version of constraint for Deap. You should write your own.\".format(caller.filename, caller.lineno, type(self).__name__))\n",
        "\n",
        "        assert len(actions.shape) == 2, \"Only takes in one action at a time since this is how Deap will use it.\"\n",
        "        assert actions.shape[0] == 1, \"Only takes in one action at a time since this is how Deap will use it.\"\n",
        "        dangling        = np.ones((1), dtype=np.int32)\n",
        "\n",
        "        # For each step in time, get the prior\n",
        "        for t in range(actions.shape[1]):\n",
        "            dangling    += self.library.arities[actions[:,t]] - 1\n",
        "            priors      = self.__call__(actions[:,:t], parent[:,t], sibling[:,t], dangling)\n",
        "            # Does our action conflict with this prior?\n",
        "            if priors[0, actions[0,t]] == -np.inf:\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def test_is_violated(self, actions, parent, sibling):\n",
        "        r\"\"\"\n",
        "            This allows one to call the generic version of \"is_violated\" for testing purposes\n",
        "            from the derived classes even if they have an optimized version.\n",
        "        \"\"\"\n",
        "        return Constraint.is_violated(self, actions, parent, sibling)\n",
        "\n",
        "\n",
        "class RelationalConstraint(Constraint):\n",
        "    \"\"\"\n",
        "    Class that constrains the following:\n",
        "\n",
        "        Constrain (any of) `targets` from being the `relationship` of (any of)\n",
        "        `effectors`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    targets : list of Tokens\n",
        "        List of Tokens, all of which will be constrained if any of effectors\n",
        "        are the given relationship.\n",
        "\n",
        "    effectors : list of Tokens\n",
        "        List of Tokens, any of which will cause all targets to be constrained\n",
        "        if they are the given relationship.\n",
        "\n",
        "    relationship : str\n",
        "        The type of relationship to constrain.\n",
        "        Supported options: \"child\", \"descendant\", \"sibling\", \"uchild\",\n",
        "                           \"lchild\", \"rchild\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, library, targets, effectors, relationship):\n",
        "        Prior.__init__(self, library)\n",
        "        self.targets = library.actionize(targets)\n",
        "        self.effectors = library.actionize(effectors)\n",
        "        self.relationship = relationship\n",
        "        if self.relationship == \"uchild\":\n",
        "            assert len(self.targets) == 1, \"uchild RelationalConstraint\" \\\n",
        "                \"cannot be applied correctly if len(self.targets) > 1\"\n",
        "            unary_effectors = np.intersect1d(self.effectors,\n",
        "                                             self.library.unary_tokens)\n",
        "            self.adj_unary_effectors = library.parent_adjust[unary_effectors]\n",
        "            self.adj_effectors = library.parent_adjust[self.effectors]\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "\n",
        "        if self.relationship == \"descendant\":\n",
        "            mask = ancestors(actions=actions,\n",
        "                             arities=self.library.arities,\n",
        "                             ancestor_tokens=self.effectors)\n",
        "            prior = self.make_constraint(mask, self.targets)\n",
        "\n",
        "        elif self.relationship == \"child\":\n",
        "            parents = self.effectors\n",
        "            adj_parents = self.library.parent_adjust[parents]\n",
        "            mask = np.isin(parent, adj_parents)\n",
        "            prior = self.make_constraint(mask, self.targets)\n",
        "\n",
        "        elif self.relationship == \"sibling\":\n",
        "            # The sibling relationship is reflexive: if A is a sibling of B,\n",
        "            # then B is also a sibling of A. Thus, we combine two priors, where\n",
        "            # targets and effectors are swapped.\n",
        "            mask = np.isin(sibling, self.effectors)\n",
        "            prior = self.make_constraint(mask, self.targets)\n",
        "            mask = np.isin(sibling, self.targets)\n",
        "            prior += self.make_constraint(mask, self.effectors)\n",
        "\n",
        "        elif self.relationship == \"uchild\":\n",
        "            # Case 1: parent is a unary effector\n",
        "            mask = np.isin(parent, self.adj_unary_effectors)\n",
        "            # Case 2: sibling is a target and parent is an effector\n",
        "            mask += np.logical_and(np.isin(sibling, self.targets),\n",
        "                                   np.isin(parent, self.adj_effectors))\n",
        "            prior = self.make_constraint(mask, self.targets)\n",
        "\n",
        "        elif self.relationship == \"lchild\":\n",
        "            parents = self.effectors\n",
        "            adj_parents = self.library.parent_adjust[parents]\n",
        "            mask = np.logical_and(np.isin(parent, adj_parents),\n",
        "                                  np.equal(sibling, self.library.EMPTY_SIBLING))\n",
        "            prior = self.make_constraint(mask, self.targets)\n",
        "\n",
        "        elif self.relationship == \"rchild\":\n",
        "            parents = self.effectors\n",
        "            adj_parents = self.library.parent_adjust[parents]\n",
        "            mask = np.logical_and(np.isin(parent, adj_parents),\n",
        "                                  np.not_equal(sibling, self.library.EMPTY_SIBLING))\n",
        "            prior = self.make_constraint(mask, self.targets)\n",
        "\n",
        "        return prior\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "\n",
        "        if self.relationship == \"descendant\":\n",
        "            violated = jit_check_constraint_violation_descendant_with_target_tokens(\n",
        "                actions, self.targets, self.effectors, self.library.binary_tokens, self.library.unary_tokens)\n",
        "\n",
        "        elif self.relationship == \"child\":\n",
        "            parents = self.effectors\n",
        "            adj_parents = self.library.parent_adjust[parents]\n",
        "            violated = jit_check_constraint_violation(actions, self.targets, parent, adj_parents)\n",
        "\n",
        "        elif self.relationship == \"sibling\":\n",
        "            violated = jit_check_constraint_violation(actions, self.targets, sibling, self.effectors)\n",
        "            if not violated:\n",
        "                violated = jit_check_constraint_violation(actions, self.effectors, sibling, self.targets)\n",
        "\n",
        "        elif self.relationship == \"uchild\":\n",
        "            unary_effectors = np.intersect1d(self.effectors, self.library.unary_tokens)\n",
        "            adj_unary_effectors = self.library.parent_adjust[unary_effectors]\n",
        "            adj_effectors = self.library.parent_adjust[self.effectors]\n",
        "            violated = jit_check_constraint_violation_uchild(actions, parent, sibling, self.targets,\n",
        "                                                     adj_unary_effectors, adj_effectors)\n",
        "\n",
        "        return violated\n",
        "\n",
        "    def validate(self):\n",
        "        message = []\n",
        "        if self.relationship in [\"child\", \"descendant\", \"uchild\", \"lchild\", \"rchild\"]:\n",
        "            if np.isin(self.effectors, self.library.terminal_tokens).any():\n",
        "                message = \"{} relationship cannot have terminal effectors.\" \\\n",
        "                          .format(self.relationship.capitalize())\n",
        "                return message\n",
        "        if len(self.targets) == 0:\n",
        "            message = \"There are no target Tokens.\"\n",
        "            return message\n",
        "        if len(self.effectors) == 0:\n",
        "            message = \"There are no effector Tokens.\"\n",
        "            return message\n",
        "        return None\n",
        "\n",
        "    def describe(self):\n",
        "\n",
        "        targets = \", \".join([self.library.names[t] for t in self.targets])\n",
        "        effectors = \", \".join([self.library.names[t] for t in self.effectors])\n",
        "        relationship = {\n",
        "            \"child\" : \"a child\",\n",
        "            \"sibling\" : \"a sibling\",\n",
        "            \"descendant\" : \"a descendant\",\n",
        "            \"uchild\" : \"the only unique child\",\n",
        "            \"lchild\" : \"the left child\",\n",
        "            \"rchild\" : \"the right child\"\n",
        "        }[self.relationship]\n",
        "        message = \"{}: [{}] cannot be {} of [{}].\" \\\n",
        "                  .format(self.__class__.__name__, targets, relationship, effectors)\n",
        "        return message\n",
        "\n",
        "\n",
        "class TrigConstraint(RelationalConstraint):\n",
        "    \"\"\"Class that constrains trig Tokens from being the descendants of trig\n",
        "    Tokens.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        targets = library.trig_tokens\n",
        "        effectors = library.trig_tokens\n",
        "        super(TrigConstraint, self).__init__(library=library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=effectors,\n",
        "                                             relationship=\"descendant\")\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "\n",
        "        # Call a slightly faster descendant computation since target is the same as effectors\n",
        "        return jit_check_constraint_violation_descendant_no_target_tokens(\\\n",
        "                actions, self.effectors, self.library.binary_tokens, self.library.unary_tokens)\n",
        "\n",
        "\n",
        "class ConstConstraint(RelationalConstraint):\n",
        "    \"\"\"Class that constrains the const Token from being the only unique child\n",
        "    of all non-terminal Tokens.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        targets = library.const_token\n",
        "        effectors = np.concatenate([library.unary_tokens,\n",
        "                                    library.binary_tokens])\n",
        "\n",
        "        super(ConstConstraint, self).__init__(library=library,\n",
        "                                              targets=targets,\n",
        "                                              effectors=effectors,\n",
        "                                              relationship=\"uchild\")\n",
        "\n",
        "\n",
        "class NoInputsConstraint(Constraint):\n",
        "    \"\"\"Class that constrains sequences without input variables.\n",
        "\n",
        "    NOTE: This *should* be a special case of RepeatConstraint, but is not yet\n",
        "    supported.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        Prior.__init__(self, library)\n",
        "\n",
        "    def validate(self):\n",
        "        if len(self.library.float_tokens) == 0:\n",
        "            message = \"All terminal tokens are input variables, so all\" \\\n",
        "                \"sequences will have an input variable.\"\n",
        "            return message\n",
        "        return None\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        # Constrain when:\n",
        "        # 1) the expression would end if a terminal is chosen and\n",
        "        # 2) there are no input variables\n",
        "        mask = (dangling == 1) & \\\n",
        "               (np.sum(np.isin(actions, self.library.input_tokens), axis=1) == 0)\n",
        "        prior = self.make_constraint(mask, self.library.float_tokens)\n",
        "        return prior\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        # Violated if no input tokens are found in actions\n",
        "        tokens = self.library.input_tokens\n",
        "        return bool(np.isin(tokens, actions).sum() == 0)\n",
        "\n",
        "    def describe(self):\n",
        "        message = \"{}: Sequences contain at least one input variable Token.\".format(self.__class__.__name__)\n",
        "        return message\n",
        "\n",
        "\n",
        "class InverseUnaryConstraint(Constraint):\n",
        "    \"\"\"Class that constrains each unary Token from being the child of its\n",
        "    corresponding inverse unary Tokens.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        Prior.__init__(self, library)\n",
        "        self.priors = []\n",
        "\n",
        "        for target, effector in library.inverse_tokens.items():\n",
        "            targets = [target]\n",
        "            effectors = [effector]\n",
        "            prior = RelationalConstraint(library=library,\n",
        "                                         targets=targets,\n",
        "                                         effectors=effectors,\n",
        "                                         relationship=\"child\")\n",
        "            self.priors.append(prior)\n",
        "\n",
        "    def validate(self):\n",
        "        if len(self.priors) == 0:\n",
        "            message = \"There are no inverse unary Token pairs in the Library.\"\n",
        "            return message\n",
        "        return None\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        prior = sum([prior(actions, parent, sibling, dangling) for prior in self.priors])\n",
        "        return prior\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "\n",
        "        for p in self.priors:\n",
        "            if p.is_violated(actions, parent, sibling):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def describe(self):\n",
        "        message = [prior.describe() for prior in self.priors]\n",
        "        return \"\\n{}: \".format(self.__class__.__name__).join(message)\n",
        "\n",
        "\n",
        "class RepeatConstraint(Constraint):\n",
        "    \"\"\"Class that constrains Tokens to appear between a minimum and/or maximum\n",
        "    number of times.\"\"\"\n",
        "\n",
        "    def __init__(self, library, tokens, min_=None, max_=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        tokens : Token or list of Tokens\n",
        "            Token(s) which should, in total, occur between min_ and max_ times.\n",
        "\n",
        "        min_ : int or None\n",
        "            Minimum number of times tokens should occur.\n",
        "\n",
        "        max_ : int or None\n",
        "            Maximum number of times tokens should occur.\n",
        "        \"\"\"\n",
        "\n",
        "        Prior.__init__(self, library)\n",
        "        assert min_ is not None or max_ is not None, \\\n",
        "            \"{}: At least one of (min_, max_) must not be None.\".format(self.__class__.__name__)\n",
        "        self.min = min_\n",
        "        self.max = max_\n",
        "        self.tokens = library.actionize(tokens)\n",
        "\n",
        "        assert min_ is None, \"{}: Repeat minimum constraints are not yet \" \\\n",
        "            \"supported. This requires knowledge of length constraints.\".format(self.__class__.__name__)\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        counts = np.sum(np.isin(actions, self.tokens), axis=1)\n",
        "        prior = self.init_zeros(actions)\n",
        "        if self.min is not None:\n",
        "            raise NotImplementedError\n",
        "        if self.max is not None:\n",
        "            mask = counts >= self.max\n",
        "            prior += self.make_constraint(mask, self.tokens)\n",
        "\n",
        "        return prior\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        return bool(np.isin(actions, self.tokens).sum() > self.max)\n",
        "\n",
        "    def describe(self):\n",
        "        names = \", \".join([self.library.names[t] for t in self.tokens])\n",
        "        if self.min is None:\n",
        "            message = \"{}: [{}] cannot occur more than {} times.\"\\\n",
        "                .format(self.__class__.__name__, names, self.max)\n",
        "        elif self.max is None:\n",
        "            message = \"{}: [{}] must occur at least {} times.\"\\\n",
        "                .format(self.__class__.__name__, names, self.min)\n",
        "        else:\n",
        "            message = \"{}: [{}] must occur between {} and {} times.\"\\\n",
        "                .format(self.__class__.__name__, names, self.min, self.max)\n",
        "        return message\n",
        "\n",
        "\n",
        "class LengthConstraint(Constraint):\n",
        "    \"\"\"Class that constrains the Program from falling within a minimum and/or\n",
        "    maximum length\"\"\"\n",
        "\n",
        "    def __init__(self, library, min_=None, max_=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        min_ : int or None\n",
        "            Minimum length of the Program.\n",
        "\n",
        "        max_ : int or None\n",
        "            Maximum length of the Program.\n",
        "        \"\"\"\n",
        "\n",
        "        Prior.__init__(self, library)\n",
        "        self.min = min_\n",
        "        self.max = max_\n",
        "\n",
        "        assert min_ is not None or max_ is not None, \\\n",
        "            \"At least one of (min_, max_) must not be None.\"\n",
        "\n",
        "    def initial_prior(self):\n",
        "        prior = Prior.initial_prior(self)\n",
        "        for t in self.library.terminal_tokens:\n",
        "            prior[t] = -np.inf\n",
        "        return prior\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "\n",
        "        # Initialize the prior\n",
        "        prior = self.init_zeros(actions)\n",
        "        i = actions.shape[1] - 1 # Current time\n",
        "        # Never need to constrain max length for first half of expression\n",
        "        if self.max is not None and (i + 2) >= self.max // 2:\n",
        "            remaining = self.max - (i + 1)\n",
        "            # assert sum(dangling > remaining) == 0, (dangling, remaining)\n",
        "            # TBD: For loop over arities\n",
        "            mask = dangling >= remaining - 1 # Constrain binary\n",
        "            prior += self.make_constraint(mask, self.library.binary_tokens)\n",
        "            mask = dangling == remaining # Constrain unary\n",
        "            prior += self.make_constraint(mask, self.library.unary_tokens)\n",
        "\n",
        "        # Constrain terminals when dangling == 1 until selecting the\n",
        "        # (min_length)th token\n",
        "        if self.min is not None and (i + 2) < self.min:\n",
        "            mask = dangling == 1 # Constrain terminals\n",
        "            prior += self.make_constraint(mask, self.library.terminal_tokens)\n",
        "\n",
        "\n",
        "        return prior\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        l = len(actions[0])\n",
        "        if self.min is not None and l < self.min:\n",
        "            return True\n",
        "        if self.max is not None and l > self.max:\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def describe(self):\n",
        "        message = []\n",
        "        indent = \" \" * len(self.__class__.__name__) + \"  \"\n",
        "        if self.min is not None:\n",
        "            message.append(\"{}: Sequences have minimum length {}.\".format(self.__class__.__name__, self.min))\n",
        "        if self.max is not None:\n",
        "            message.append(indent + \"Sequences have maximum length {}.\".format(self.max))\n",
        "        message = \"\\n\".join(message)\n",
        "        return message\n",
        "\n",
        "\n",
        "class DomainRangeConstraint(Constraint):\n",
        "    \"\"\"\n",
        "    Class that constrains two special cases regarding the domain and range of\n",
        "    (X, y) data and tokens. First, for the first position, it constrains tokens\n",
        "    when its range does not contain the interval [min(y), max(y)]. For example,\n",
        "    if min(y) = -2, the first token cannot be sin. Second, input variable x is\n",
        "    constrained if their parent would be unary and the domain of the parent\n",
        "    does not contain the interval [min(x), max(x)]. For example, if min(x) = -2\n",
        "    and the parent is sqrt, then x is constrained.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        Constraint.__init__(self, library)\n",
        "\n",
        "        # Min/max of dataset domain\n",
        "        X_min = Program.task.X_train.min(axis=0) # (n_input_var,)\n",
        "        X_max = Program.task.X_train.max(axis=0) # (n_input_var,)\n",
        "\n",
        "        # Min/max of dataset range\n",
        "        y_min = Program.task.y_train.min() # scalar\n",
        "        y_max = Program.task.y_train.max() # scalar\n",
        "\n",
        "        # TBD: Add domain/range to Token\n",
        "        # Define domains of possible tokens\n",
        "        domains = defaultdict(lambda : (-np.inf, np.inf))\n",
        "        domains.update({\n",
        "            \"sqrt\" : (0, np.inf),\n",
        "            \"log\" : (0, np.inf)\n",
        "        })\n",
        "\n",
        "        # TBD: Add domain/range to Token\n",
        "        # Define ranges of possible tokens\n",
        "        ranges = defaultdict(lambda : (-np.inf, np.inf))\n",
        "        ranges.update({\n",
        "            \"sin\" : (-1.0, 1.0),\n",
        "            \"cos\" : (-1.0, 1.0),\n",
        "            \"exp\" : (0, np.inf),\n",
        "            \"abs\" : (0, np.inf),\n",
        "            \"sqrt\" : (0, np.inf),\n",
        "            \"n2\" : (0, np.inf),\n",
        "            \"n4\" : (0, np.inf),\n",
        "            \"n6\" : (0, np.inf),\n",
        "        })\n",
        "\n",
        "        # Convert to np.ndarray of shape (L, 2)\n",
        "        domains = np.array([domains[t.name] for t in self.library.tokens], dtype=np.float32)\n",
        "        ranges = np.array([ranges[t.name] for t in self.library.tokens], dtype=np.float32)\n",
        "\n",
        "        # Pre-compute the initial prior\n",
        "        self.p0 = Prior.initial_prior(self) # Zeros of shape (L,)\n",
        "        for i, R in enumerate(ranges):\n",
        "            if y_min < R[0] or y_max > R[1]:\n",
        "                self.p0[i] = -np.inf\n",
        "\n",
        "        # Pre-compute constraining unary parents for each input variable\n",
        "        self.constraining_parents = [] # List of np.ndarray\n",
        "        for i in range(self.library.n_input_tokens):\n",
        "            self.constraining_parents.append([])\n",
        "            for t in self.library.unary_tokens:\n",
        "                D = domains[t]\n",
        "                if X_min[i] < D[0] or X_max[i] > D[1]:\n",
        "                    adj_parent = self.library.parent_adjust[t]\n",
        "                    self.constraining_parents[i].append(adj_parent)\n",
        "            self.constraining_parents[i] = np.array(self.constraining_parents[i], dtype=np.int32)\n",
        "\n",
        "        # Pre-compute logits to add when constraining maximum length and this is\n",
        "        # the last chance to select a unary token (before being constrained to\n",
        "        # select only terminals). This will only be used if self.max_length is later\n",
        "        # set to not be None\n",
        "        self.max_length = None\n",
        "        self.last_chance_unary = Prior.initial_prior(self)\n",
        "        for t in self.library.unary_tokens:\n",
        "            parent = self.library.parent_adjust[t]\n",
        "            if all([parent in arr for arr in self.constraining_parents]):\n",
        "                self.last_chance_unary[t] = -np.inf\n",
        "\n",
        "    def initial_prior(self):\n",
        "        return self.p0\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "\n",
        "        prior = self.init_zeros(actions)\n",
        "\n",
        "        # SPECIAL CASE:\n",
        "        # If max length is constrained and this is the last chance to select a\n",
        "        # unary token, make sure that a unary can only be chosen if it is not a\n",
        "        # constraining parent of all input variables. Without this, there can be\n",
        "        # a collision with LengthConstraint.\n",
        "        if self.max_length is not None:\n",
        "            remaining = self.max_length - actions.shape[1]\n",
        "            mask = dangling == remaining - 1 # Last chance to constrain unary\n",
        "            prior[mask] += self.last_chance_unary\n",
        "\n",
        "        # For each input variable, see if the parent constrains that input\n",
        "        for i, x in enumerate(self.library.input_tokens):\n",
        "            logit_adjust = Prior.initial_prior(self) # Zeros of shape (L,)\n",
        "            logit_adjust[x] = -np.inf\n",
        "            mask = np.isin(parent, self.constraining_parents[i])\n",
        "            prior[mask] += logit_adjust\n",
        "\n",
        "        return prior\n",
        "\n",
        "    def describe(self):\n",
        "        message = []\n",
        "        indent = \" \" * len(self.__class__.__name__) + \"  \"\n",
        "        message.append(\"{}: First token's range must contain [min(y), max(y)].\".format(self.__class__.__name__))\n",
        "        message.append(indent + \"Input variable domains must be contained in unary parent domains.\")\n",
        "        message = \"\\n\".join(message)\n",
        "        return message\n",
        "\n",
        "    def validate(self):\n",
        "        if self.p0.sum() == 0 and all([len(x) == 0 for x in self.constraining_parents]):\n",
        "            return \"All token ranges contain [min(y), max(y)] and all token domains contain [min(x), max(x)].\"\n",
        "        return None\n",
        "\n",
        "\n",
        "class UniformArityPrior(Prior):\n",
        "    \"\"\"Class that puts a fixed prior on arities by transforming the initial\n",
        "    distribution from uniform over tokens to uniform over arities.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "\n",
        "        Prior.__init__(self, library)\n",
        "\n",
        "        # For each token, subtract log(n), where n is the total number of tokens\n",
        "        # in the library with the same arity as that token. This is equivalent\n",
        "        # to... For each arity, subtract log(n) from tokens of that arity, where\n",
        "        # n is the total number of tokens of that arity\n",
        "        self.logit_adjust = np.zeros((self.L,), dtype=np.float32)\n",
        "        for arity, tokens in self.library.tokens_of_arity.items():\n",
        "            self.logit_adjust[tokens] -= np.log(len(tokens))\n",
        "\n",
        "    def initial_prior(self):\n",
        "        return self.logit_adjust\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "\n",
        "        # This will be broadcast when added to the joint prior\n",
        "        prior = self.logit_adjust\n",
        "        return prior\n",
        "\n",
        "    def describe(self):\n",
        "        \"\"\"Describe the Prior.\"\"\"\n",
        "\n",
        "        return \"{}: Activated.\".format(self.__class__.__name__)\n",
        "\n",
        "\n",
        "class SoftLengthPrior(Prior):\n",
        "    \"\"\"Class that puts a soft prior on length. Before loc, terminal probabilities\n",
        "    are scaled by exp(-(t - loc) ** 2 / (2 * scale)) where dangling == 1. After\n",
        "    loc, non-terminal probabilities are scaled by that number.\"\"\"\n",
        "\n",
        "    def __init__(self, library, loc, scale):\n",
        "\n",
        "        Prior.__init__(self, library)\n",
        "\n",
        "        self.loc = loc\n",
        "        self.scale = scale\n",
        "\n",
        "        self.terminal_mask = np.zeros((self.L,), dtype=np.bool)\n",
        "        self.terminal_mask[self.library.terminal_tokens] = True\n",
        "\n",
        "        self.nonterminal_mask = ~self.terminal_mask\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "\n",
        "        # Initialize the prior\n",
        "        prior = self.init_zeros(actions)\n",
        "        t = actions.shape[1] # Current time\n",
        "\n",
        "        # Adjustment to terminal or non-terminal logits\n",
        "        logit_adjust = -(t - self.loc) ** 2 / (2 * self.scale)\n",
        "\n",
        "        # Before loc, decrease p(terminal) where dangling == 1\n",
        "        if t < self.loc:\n",
        "            prior[dangling == 1] += self.terminal_mask * logit_adjust\n",
        "\n",
        "        # After loc, decrease p(non-terminal)\n",
        "        else:\n",
        "            prior += self.nonterminal_mask * logit_adjust\n",
        "\n",
        "        return prior\n",
        "\n",
        "    def validate(self):\n",
        "        if self.loc is None or self.scale is None:\n",
        "            message = \"'scale' and 'loc' arguments must be specified!\"\n",
        "            return message\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "class LanguageModelPrior(Prior):\n",
        "    \"\"\"Class that applies a prior based on a pre-trained language model.\"\"\"\n",
        "\n",
        "    def __init__(self, library, weight=1.0, **kwargs):\n",
        "\n",
        "        Prior.__init__(self, library)\n",
        "\n",
        "        self.lm = LM(library, **kwargs)\n",
        "        self.weight = weight\n",
        "\n",
        "    def initial_prior(self):\n",
        "\n",
        "        # TBD: Get initial prior from language model\n",
        "        return np.zeros((self.L,), dtype=np.float32)\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "\n",
        "        \"\"\"\n",
        "        NOTE: This assumes that the prior is always called sequentially during\n",
        "        sampling. This may break if calling the prior arbitrarily.\n",
        "        \"\"\"\n",
        "        if actions.shape[1] == 1:\n",
        "            self.lm.next_state = None\n",
        "\n",
        "        action = actions[:, -1] # Current action\n",
        "        prior = self.lm.get_lm_prior(action)\n",
        "        prior *= self.weight\n",
        "\n",
        "        return prior\n",
        "\n",
        "    def validate(self):\n",
        "        if self.weight is None:\n",
        "            message = \"Need to specify language model arguments.\"\n",
        "            return message\n",
        "        return None\n",
        "\n",
        "\n",
        "class StateCheckerConstraint(Constraint):\n",
        "    \"\"\"Class that impose constraints on StateChecker Tokens to avoid degenerate\n",
        "    situations (e.g., checking if xi < 6 when we know xi < 3).\n",
        "\n",
        "    Consider StateCheckers 'xi < tj' that is associated with the\n",
        "    i-th state variable xi and threshold tj, and 'xl < tk' that is\n",
        "    associated with the l-th state variable xl and threshold tk.\n",
        "\n",
        "    The constraints include:\n",
        "        1. 'xl < tk' cannot be the left child of 'xi < tj' if l < i or if l == i and tk >= tj\n",
        "        2. 'xl < tk' cannot be the right child of 'xi < tj' if l <= i\n",
        "        3. a StateChecker cannot be a child of a non-StateChecker.\"\"\"\n",
        "\n",
        "    def __init__(self, library):\n",
        "        Prior.__init__(self, library)\n",
        "        self.priors = []\n",
        "\n",
        "        # Loop over StateChecker 'xi < tj'\n",
        "        for parent in library.state_checker_tokens:\n",
        "            effectors = [parent]\n",
        "            targets = []\n",
        "\n",
        "            # Add StateChecker 'xl < tk' to targets if l < i\n",
        "            for child in library.state_checker_tokens:\n",
        "                if self.library[child].state_index < self.library[parent].state_index:\n",
        "                    targets.append(child)\n",
        "\n",
        "            # Add StateChecker 'xl < tk' to targets if l == i and tk >= tj\n",
        "            for child in library.state_checker_tokens:\n",
        "                if self.library[child].state_index == self.library[parent].state_index:\n",
        "                    if self.library[child].threshold >= self.library[parent].threshold:\n",
        "                        targets.append(child)\n",
        "\n",
        "            if len(targets) > 0:\n",
        "                # Add prior that constraints targets (containing 'xl < tk' with l < i, and\n",
        "                # 'xl < tk' with l == i and tk >= tj) from being the left child of 'xi < tj'\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=effectors,\n",
        "                                             relationship=\"lchild\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "            # Add StateChecker 'xl < tk' to targets if l == i and tk < tj\n",
        "            # (targets now contains all StateChecker 'xl < tk' with l <= i)\n",
        "            for child in library.state_checker_tokens:\n",
        "                if self.library[child].state_index == self.library[parent].state_index:\n",
        "                    if self.library[child].threshold < self.library[parent].threshold:\n",
        "                        targets.append(child)\n",
        "\n",
        "            if len(targets) > 0:\n",
        "                # Add prior that constraints targets (containing 'xl < tk' with l <= i)\n",
        "                # from being the right child of 'xi < tj'\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=effectors,\n",
        "                                             relationship=\"rchild\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "        # Add priors that constraint any StateChecker from being a child of any non-StateChecker\n",
        "        if len(library.state_checker_tokens) > 0:\n",
        "            non_state_checker_tokens = np.setdiff1d(np.arange(self.L), library.state_checker_tokens,\n",
        "                                                    assume_unique=True)\n",
        "            for parent in non_state_checker_tokens:\n",
        "                if self.library[parent].arity > 0:\n",
        "                    effectors = [parent]\n",
        "                    prior = RelationalConstraint(library,\n",
        "                                                 targets=library.state_checker_tokens,\n",
        "                                                 effectors=effectors,\n",
        "                                                 relationship=\"child\")\n",
        "                    self.priors.append(prior)\n",
        "\n",
        "            for terminal_token in library.terminal_tokens:\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=[terminal_token],\n",
        "                                             effectors=library.state_checker_tokens,\n",
        "                                             relationship=\"uchild\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        if len(self.library.state_checker_tokens) == 0:\n",
        "            return \"There are no StateChecker tokens in the library.\"\n",
        "        return None\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        prior = sum([prior(actions, parent, sibling, dangling)\n",
        "                     for prior in self.priors])\n",
        "        return prior\n",
        "\n",
        "    def describe(self):\n",
        "        indent = \" \" * len(self.__class__.__name__) + \"  \"\n",
        "        message = [\"StateCheckerConstraint: Sequences containing StateChecker tokens cannot produce degenerate logic.\"]\n",
        "        message.append(indent + \"'xl < tk' cannot be the left child of 'xi < tj' if l < i or if l == i and tk >= tj.\")\n",
        "        message.append(indent + \"'xl < tk' cannot be the right child of 'xi < tj' if l <= i.\")\n",
        "        message.append(indent + \"A StateChecker cannot be a child of a non-StateChecker.\")\n",
        "        return \"\\n\".join(message)\n",
        "\n",
        "\n",
        "class MutuallyExclusiveConstraint(Constraint):\n",
        "    \"\"\"Class that constrains the program from having two or more distinct tokens\n",
        "    in a given set of tokens. Mathematically, this constrains the intersection\n",
        "    of set(tokens) and set(actions) to have a resulting size of 0 or 1.\n",
        "\n",
        "    For example, if the given set of tokens = [\"poly\", \"const\"], then this\n",
        "    constraint prevents actions = [\"add\", \"const\", \"poly\"] to be sampled.\n",
        "    Note, however, that it does not prevents the same token to appear multiple\n",
        "    times. So, e.g., actions = [\"add\", \"poly\", \"poly\"] is allowed.\"\"\"\n",
        "\n",
        "    def __init__(self, library, tokens):\n",
        "        super().__init__(library)\n",
        "        self.tokens = tokens\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        prior = self.init_zeros(actions)\n",
        "\n",
        "        # For each mutually exclusive token, see if it exists.\n",
        "        # If so, constrain all other mutually exclusive tokens.\n",
        "        for token in self.tokens:\n",
        "            mask = np.any(actions == token, axis=1)\n",
        "            others = self.tokens[self.tokens != token]\n",
        "            prior += self.make_constraint(mask, others)\n",
        "        return prior\n",
        "\n",
        "    def validate(self):\n",
        "        if len(self.tokens) < 2:\n",
        "            return \"Length of {} must be at least 2\".format(self.tokens)\n",
        "        return None\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        return np.intersect1d(self.tokens, actions).size > 1\n",
        "\n",
        "    def describe(self):\n",
        "        tokens = \", \".join([self.library.names[t] for t in self.tokens])\n",
        "        message = self.__class__.__name__\n",
        "        message += \": Two or more distinct tokens in [{}] cannot appear in the same sequence.\".format(tokens)\n",
        "        return message\n",
        "\n",
        "class PolyConstraint(Constraint):\n",
        "    \"\"\"Class that impose constraints such that polynomial fitting problems can be\n",
        "    constructed and well-defined when Polynomial Token is in library.\"\"\"\n",
        "    def __init__(self, library):\n",
        "        Prior.__init__(self, library)\n",
        "        # poly token cannot appear more than 1 time\n",
        "        self.priors = [RepeatConstraint(library, \"poly\", None, 1)]\n",
        "\n",
        "        # any function whose inverse is multi-valued cannot be an ancestor of \"poly\"\n",
        "        # because it may lead to wrong data for the polynomial fitting problem.\n",
        "        invalid_ancestors = [\"sin\", \"cos\", \"tan\", \"n2\", \"n4\", \"n6\", \"abs\"]\n",
        "        invalid_ancestors = np.intersect1d(invalid_ancestors, library.names, assume_unique=True)\n",
        "        if len(invalid_ancestors) > 0:\n",
        "            descendant_prior = RelationalConstraint(library,\n",
        "                                                    targets=[\"poly\"],\n",
        "                                                    effectors=invalid_ancestors,\n",
        "                                                    relationship=\"descendant\")\n",
        "            self.priors.append(descendant_prior)\n",
        "\n",
        "        # poly and const cannot appear in the same traversal\n",
        "        if library.const_token is not None:\n",
        "            mutually_exclusive_tokens = np.array([library.poly_token, library.const_token])\n",
        "            self.priors.append(MutuallyExclusiveConstraint(library, mutually_exclusive_tokens))\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        prior = sum([prior(actions, parent, sibling, dangling)\n",
        "                     for prior in self.priors])\n",
        "        return prior\n",
        "\n",
        "    def validate(self):\n",
        "        if \"poly\" not in self.library.names:\n",
        "            return \"There is no 'poly' token in the Library\"\n",
        "        return None\n",
        "\n",
        "    def is_violated(self, actions, parent, sibling):\n",
        "        for prior in self.priors:\n",
        "            if prior.is_violated(actions, parent, sibling):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def describe(self):\n",
        "        return \"\\n\".join([prior.describe() for prior in self.priors])\n",
        "\n",
        "\n",
        "class MultiDiscreteConstraint(Constraint):\n",
        "    \"\"\"\n",
        "    Class that imposes the constraint that once one MultiDiscreteAction is\n",
        "    sampled, only MultiDiscreteAction with a different action dimension can be\n",
        "    sampled, until \"STOP\" is sampled.\n",
        "\n",
        "    Additional constraints may apply based on the value of dense and ordered.\n",
        "    \"\"\"\n",
        "    def __init__(self, library, dense, ordered):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dense : bool\n",
        "            If True, once one MultiDiscreteAction is sampled, \"STOP\" cannot be\n",
        "            sampled until MultiDiscreteAction for all action dimensions are sampled.\n",
        "\n",
        "        ordered : bool\n",
        "            If True, action dimensions of adjacent MultiDiscreteAction tokens\n",
        "            constrained to be in ascending order, until \"STOP\" is sampled.\n",
        "        \"\"\"\n",
        "        super().__init__(library)\n",
        "        self.dense = dense\n",
        "        self.ordered = ordered\n",
        "        self.priors = []\n",
        "        self.special_prior = None\n",
        "        non_multi_discrete = np.setdiff1d(np.arange(self.L), library.multi_discrete_tokens,\n",
        "                                          assume_unique=True).tolist()\n",
        "\n",
        "        self.unary_multi_discrete = np.intersect1d(library.multi_discrete_tokens,\n",
        "                                                   library.unary_tokens, assume_unique=True)\n",
        "\n",
        "        if dense and ordered:\n",
        "            targets = [t for t in library.multi_discrete_tokens if\n",
        "                    self.library[t].action_dim is None or\n",
        "                    self.library[t].action_dim != 0]\n",
        "            prior = RelationalConstraint(library,\n",
        "                                         targets=targets,\n",
        "                                         effectors=non_multi_discrete,\n",
        "                                         relationship=\"child\")\n",
        "            self.priors.append(prior)\n",
        "\n",
        "            for parent in self.unary_multi_discrete:\n",
        "                if self.library[parent].action_dim < MultiDiscreteAction.n_dims-1:\n",
        "                    targets = [t for t in library.multi_discrete_tokens if\n",
        "                            self.library[t].action_dim is None or\n",
        "                            self.library[t].action_dim != self.library[parent].action_dim+1]\n",
        "                else:\n",
        "                    targets = self.unary_multi_discrete\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=[parent],\n",
        "                                             relationship=\"child\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "        elif not dense and ordered:\n",
        "            for parent in self.unary_multi_discrete:\n",
        "                targets = [t for t in self.unary_multi_discrete if\n",
        "                        self.library[t].action_dim <= self.library[parent].action_dim]\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=[parent],\n",
        "                                             relationship=\"child\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "        elif dense and not ordered:\n",
        "            targets = [t for t in library.multi_discrete_tokens if\n",
        "                        self.library[t].action_dim is None]\n",
        "            prior = RelationalConstraint(library,\n",
        "                                         targets=targets,\n",
        "                                         effectors=non_multi_discrete,\n",
        "                                         relationship=\"child\")\n",
        "            self.priors.append(prior)\n",
        "            for ancestor in self.unary_multi_discrete:\n",
        "                targets = [t for t in library.multi_discrete_tokens if\n",
        "                        self.library[t].action_dim is None or\n",
        "                        self.library[t].action_dim == self.library[ancestor].action_dim]\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=[ancestor],\n",
        "                                             relationship=\"descendant\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "            self.special_prior = RelationalConstraint(library,\n",
        "                                                      targets=self.unary_multi_discrete,\n",
        "                                                      effectors=self.unary_multi_discrete,\n",
        "                                                      relationship=\"child\")\n",
        "        else: # not dense and not ordered\n",
        "            for ancestor in self.unary_multi_discrete:\n",
        "                targets = [t for t in self.unary_multi_discrete if\n",
        "                        self.library[t].action_dim == self.library[ancestor].action_dim]\n",
        "                prior = RelationalConstraint(library,\n",
        "                                             targets=targets,\n",
        "                                             effectors=[ancestor],\n",
        "                                             relationship=\"descendant\")\n",
        "                self.priors.append(prior)\n",
        "\n",
        "    def __call__(self, actions, parent, sibling, dangling):\n",
        "        if self.special_prior is None:\n",
        "            prior = sum([prior(actions, parent, sibling, dangling)\n",
        "                        for prior in self.priors])\n",
        "        else:\n",
        "            mask = np.full(len(actions), False)\n",
        "            for i in range(len(actions)):\n",
        "                for action in actions[i][-MultiDiscreteAction.n_dims:]:\n",
        "                    if action not in self.unary_multi_discrete:\n",
        "                        mask[i] = True\n",
        "                        break\n",
        "\n",
        "            prior = self.init_zeros(actions)\n",
        "            prior[~mask] = self.special_prior(actions[~mask], parent[~mask],\n",
        "                                              sibling[~mask], dangling[~mask])\n",
        "            prior[mask] = sum([prior(actions[mask], parent[mask],\n",
        "                                     sibling[mask], dangling[mask]) for prior in self.priors])\n",
        "        return prior\n",
        "\n",
        "    def validate(self):\n",
        "        if len(self.library.multi_discrete_tokens) == 0:\n",
        "            return \"There are no MultiDiscreteAction tokens in the library.\"\n",
        "        return None\n",
        "\n",
        "    def describe(self):\n",
        "        indent = \" \" * len(self.__class__.__name__) + \"  \"\n",
        "        message = \"MultiDiscreteConstraint: Child of a MultiDiscreteAction must\"\n",
        "        message += \" be a MultiDiscreteAction with a different action_dim or STOP.\"\n",
        "        message = [message]\n",
        "        if self.dense:\n",
        "            message.append(indent + \"Each action branch must contain all action_dim.\")\n",
        "        if self.ordered:\n",
        "            message.append(indent + \"action_dim in each action branch must be ascending.\")\n",
        "        return \"\\n\".join(message)"
      ],
      "metadata": {
        "id": "5tyDQhQ2NFwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#config\n",
        "def get_base_config(task, language_prior):\n",
        "    # Load base config\n",
        "    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"config_common.json\"), encoding='utf-8') as f:\n",
        "        base_config = json.load(f)\n",
        "\n",
        "    # Load task specific config\n",
        "    task_config_file = None\n",
        "    if task in [\"regression\", None]:\n",
        "        task_config_file = \"config_regression.json\"\n",
        "    elif task in [\"control\"]:\n",
        "        task_config_file = \"config_control.json\"\n",
        "    else:\n",
        "        # Custom tasks use config_common.json.\n",
        "        task_config_file = \"config_common.json\"\n",
        "    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), task_config_file), encoding='utf-8') as f:\n",
        "        task_config = json.load(f)\n",
        "\n",
        "    # Load language prior config\n",
        "    if language_prior:\n",
        "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"config_language.json\"), encoding='utf-8') as f:\n",
        "            language_config = json.load(f)\n",
        "        task_config = safe_merge_dicts(task_config, language_config)\n",
        "\n",
        "    return safe_merge_dicts(base_config, task_config)\n",
        "\n",
        "\n",
        "def load_config(config=None):\n",
        "    # Load user config\n",
        "    if isinstance(config, str):\n",
        "        with open(config, encoding='utf-8') as f:\n",
        "            user_config = json.load(f)\n",
        "    elif isinstance(config, dict):\n",
        "        user_config = config\n",
        "    else:\n",
        "        assert config is None, \"Config must be None, str, or dict.\"\n",
        "        user_config = {}\n",
        "\n",
        "    # Determine the task and language prior\n",
        "    try:\n",
        "        task = user_config[\"task\"][\"task_type\"]\n",
        "    except KeyError:\n",
        "        task = \"regression\"\n",
        "        print(\"WARNING: Task type not specified. Falling back to default task type '{}' to load config.\".format(task))\n",
        "    try:\n",
        "        language_prior = user_config[\"prior\"][\"language_model\"][\"on\"]\n",
        "    except KeyError:\n",
        "        language_prior = False\n",
        "\n",
        "    # Load task-specific base config\n",
        "    base_config = get_base_config(task, language_prior)\n",
        "\n",
        "    # Return combined configs\n",
        "    return safe_merge_dicts(base_config, user_config)"
      ],
      "metadata": {
        "id": "hBRyPGzmOTt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf_state_manager\n",
        "\n",
        "class StateManager(ABC):\n",
        "    \"\"\"\n",
        "    An interface for handling the tf.Tensor inputs to the Policy.\n",
        "    \"\"\"\n",
        "\n",
        "    def setup_manager(self, policy):\n",
        "        \"\"\"\n",
        "        Function called inside the policy to perform the needed initializations (e.g., if the tf context is needed)\n",
        "        :param policy the policy class\n",
        "        \"\"\"\n",
        "        self.policy = policy\n",
        "        self.max_length = policy.max_length\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_tensor_input(self, obs):\n",
        "        \"\"\"\n",
        "        Convert an observation from a Task into a Tesnor input for the\n",
        "        Policy, e.g. by performing one-hot encoding or embedding lookup.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Observation coming from the Task.\n",
        "\n",
        "        Returns\n",
        "        --------\n",
        "        input_ : tf.Tensor (dtype=tf.float32)\n",
        "            Tensor to be used as input to the Policy.\n",
        "        \"\"\"\n",
        "        return\n",
        "\n",
        "    def process_state(self, obs):\n",
        "        \"\"\"\n",
        "        Entry point for adding information to the state tuple.\n",
        "        If not overwritten, this functions does nothing\n",
        "        \"\"\"\n",
        "        return obs\n",
        "\n",
        "\n",
        "def make_state_manager(config):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    config : dict\n",
        "        Parameters for this StateManager.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    state_manager : StateManager\n",
        "        The StateManager to be used by the policy.\n",
        "    \"\"\"\n",
        "    manager_dict = {\n",
        "        \"hierarchical\": HierarchicalStateManager\n",
        "    }\n",
        "\n",
        "    if config is None:\n",
        "        config = {}\n",
        "\n",
        "    # Use HierarchicalStateManager by default\n",
        "    manager_type = config.pop(\"type\", \"hierarchical\")\n",
        "\n",
        "    manager_class = manager_dict[manager_type]\n",
        "    state_manager = manager_class(**config)\n",
        "\n",
        "    return state_manager\n",
        "\n",
        "\n",
        "class HierarchicalStateManager(StateManager):\n",
        "    \"\"\"\n",
        "    Class that uses the previous action, parent, sibling, and/or dangling as\n",
        "    observations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, observe_parent=True, observe_sibling=True,\n",
        "                 observe_action=False, observe_dangling=False, embedding=False,\n",
        "                 embedding_size=8):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        observe_parent : bool\n",
        "            Observe the parent of the Token being selected?\n",
        "\n",
        "        observe_sibling : bool\n",
        "            Observe the sibling of the Token being selected?\n",
        "\n",
        "        observe_action : bool\n",
        "            Observe the previously selected Token?\n",
        "\n",
        "        observe_dangling : bool\n",
        "            Observe the number of dangling nodes?\n",
        "\n",
        "        embedding : bool\n",
        "            Use embeddings for categorical inputs?\n",
        "\n",
        "        embedding_size : int\n",
        "            Size of embeddings for each categorical input if embedding=True.\n",
        "        \"\"\"\n",
        "        self.observe_parent = observe_parent\n",
        "        self.observe_sibling = observe_sibling\n",
        "        self.observe_action = observe_action\n",
        "        self.observe_dangling = observe_dangling\n",
        "        self.library = Program.library\n",
        "\n",
        "        # Parameter assertions/warnings\n",
        "        assert self.observe_action + self.observe_parent + self.observe_sibling + self.observe_dangling > 0, \\\n",
        "            \"Must include at least one observation.\"\n",
        "\n",
        "        self.embedding = embedding\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    def setup_manager(self, policy):\n",
        "        super().setup_manager(policy)\n",
        "        # Create embeddings if needed\n",
        "        if self.embedding:\n",
        "            initializer = tf.random_uniform_initializer(minval=-1.0,\n",
        "                                                        maxval=1.0,\n",
        "                                                        seed=0)\n",
        "            with tf.variable_scope(\"embeddings\", initializer=initializer):\n",
        "                if self.observe_action:\n",
        "                    self.action_embeddings = tf.get_variable(\"action_embeddings\",\n",
        "                                                             [self.library.n_action_inputs, self.embedding_size],\n",
        "                                                             trainable=True)\n",
        "                if self.observe_parent:\n",
        "                    self.parent_embeddings = tf.get_variable(\"parent_embeddings\",\n",
        "                                                             [self.library.n_parent_inputs, self.embedding_size],\n",
        "                                                             trainable=True)\n",
        "                if self.observe_sibling:\n",
        "                    self.sibling_embeddings = tf.get_variable(\"sibling_embeddings\",\n",
        "                                                              [self.library.n_sibling_inputs, self.embedding_size],\n",
        "                                                              trainable=True)\n",
        "\n",
        "    def get_tensor_input(self, obs):\n",
        "        observations = []\n",
        "        unstacked_obs = tf.unstack(obs, axis=1)\n",
        "        action, parent, sibling, dangling = unstacked_obs[:4]\n",
        "\n",
        "        # Cast action, parent, sibling to int for embedding_lookup or one_hot\n",
        "        action = tf.cast(action, tf.int32)\n",
        "        parent = tf.cast(parent, tf.int32)\n",
        "        sibling = tf.cast(sibling, tf.int32)\n",
        "\n",
        "        # Action, parent, and sibling inputs are either one-hot or embeddings\n",
        "        if self.observe_action:\n",
        "            if self.embedding:\n",
        "                x = tf.nn.embedding_lookup(self.action_embeddings, action)\n",
        "            else:\n",
        "                x = tf.one_hot(action, depth=self.library.n_action_inputs)\n",
        "            observations.append(x)\n",
        "        if self.observe_parent:\n",
        "            if self.embedding:\n",
        "                x = tf.nn.embedding_lookup(self.parent_embeddings, parent)\n",
        "            else:\n",
        "                x = tf.one_hot(parent, depth=self.library.n_parent_inputs)\n",
        "            observations.append(x)\n",
        "        if self.observe_sibling:\n",
        "            if self.embedding:\n",
        "                x = tf.nn.embedding_lookup(self.sibling_embeddings, sibling)\n",
        "            else:\n",
        "                x = tf.one_hot(sibling, depth=self.library.n_sibling_inputs)\n",
        "            observations.append(x)\n",
        "\n",
        "        # Dangling input is just the value of dangling\n",
        "        if self.observe_dangling:\n",
        "            x = tf.expand_dims(dangling, axis=-1)\n",
        "            observations.append(x)\n",
        "\n",
        "        input_ = tf.concat(observations, -1)\n",
        "        # possibly concatenates additional observations (e.g., bert embeddings)\n",
        "        if len(unstacked_obs) > 4:\n",
        "            input_ = tf.concat([input_, tf.stack(unstacked_obs[4:], axis=-1)], axis=-1)\n",
        "        return input_"
      ],
      "metadata": {
        "id": "w7hN4bw1l0b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "ytq-0lgEtd_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#policy\n",
        "from typing import Tuple, TypeVar\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "actions = tf.TensorArray\n",
        "obs     = tf.TensorArray\n",
        "priors  = tf.TensorArray\n",
        "neglogp = tf.TensorArray\n",
        "entropy = tf.TensorArray\n",
        "\n",
        "def make_policy(sess, prior, state_manager, policy_type, **config_policy):\n",
        "    \"\"\"Factory function for Policy object.\"\"\"\n",
        "\n",
        "    if policy_type == \"rnn\":\n",
        "        from dso.policy.rnn_policy import RNNPolicy\n",
        "        policy_class = RNNPolicy\n",
        "    else:\n",
        "        # Custom policy import\n",
        "        policy_class = import_custom_source(policy_type)\n",
        "        assert issubclass(policy_class, Policy), \\\n",
        "                \"Custom policy {} must subclass dso.policy.Policy.\".format(policy_class)\n",
        "\n",
        "    policy = policy_class(sess,\n",
        "                          prior,\n",
        "                          state_manager,\n",
        "                          **config_policy)\n",
        "\n",
        "    return policy\n",
        "\n",
        "class Policy(ABC):\n",
        "    \"\"\"Abstract class for a policy. A policy is a parametrized probability\n",
        "    distribution over discrete objects. DSO algorithms optimize the parameters\n",
        "    of this distribution to generate discrete objects with high rewards.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "            sess : tf.Session,\n",
        "            prior : JointPrior,\n",
        "            state_manager : StateManager,\n",
        "            debug : int = 0,\n",
        "            max_length : int = 30) -> None:\n",
        "        '''Parameters\n",
        "        ----------\n",
        "        sess : tf.Session\n",
        "            TenorFlow Session object.\n",
        "\n",
        "        prior : dso.prior.JointPrior\n",
        "            JointPrior object used to adjust probabilities during sampling.\n",
        "\n",
        "        state_manager: dso.tf_state_manager.StateManager\n",
        "            Object that handles the state features to be used\n",
        "\n",
        "        debug : int\n",
        "            Debug level, also used in learn(). 0: No debug. 1: Print shapes and\n",
        "            number of parameters for each variable.\n",
        "\n",
        "        max_length : int or None\n",
        "            Maximum sequence length. This will be overridden if a LengthConstraint\n",
        "            with a maximum length is part of the prior.\n",
        "        '''\n",
        "        self.sess = sess\n",
        "        self.prior = prior\n",
        "        self.state_manager = state_manager\n",
        "        self.debug = debug\n",
        "\n",
        "        # Set self.max_length depending on the Prior\n",
        "        self._set_max_length(max_length)\n",
        "\n",
        "        # Samples produced during attempt to get novel samples.\n",
        "        # Will be combined with checkpoint-loaded samples for next training step\n",
        "        self.extended_batch = None\n",
        "        self.valid_extended_batch = False\n",
        "\n",
        "    def _set_max_length(self, max_length : int) -> None:\n",
        "        \"\"\"Set the max legnth depending on the Prior\n",
        "        \"\"\"\n",
        "        # Find max_length from the LengthConstraint prior, if it exists\n",
        "        # For binding task, max_length is # of allowed mutations or master-seq length\n",
        "        # Both priors will never happen in the same experiment\n",
        "        prior_max_length = None\n",
        "        for single_prior in self.prior.priors:\n",
        "            if isinstance(single_prior, LengthConstraint):\n",
        "                if single_prior.max is not None:\n",
        "                    prior_max_length = single_prior.max\n",
        "                    self.max_length = prior_max_length\n",
        "                break\n",
        "\n",
        "        if prior_max_length is None:\n",
        "            assert max_length is not None, \"max_length must be specified if \"\\\n",
        "                \"there is no LengthConstraint.\"\n",
        "            self.max_length = max_length\n",
        "            print(\"WARNING: Maximum length not constrained. Sequences will \"\n",
        "                  \"stop at {} and complete by repeating the first input \"\n",
        "                  \"variable.\".format(self.max_length))\n",
        "        elif max_length is not None and max_length != self.max_length:\n",
        "            print(\"WARNING: max_length ({}) will be overridden by value from \"\n",
        "                  \"LengthConstraint ({}).\".format(max_length, self.max_length))\n",
        "\n",
        "    @abstractmethod\n",
        "    def _setup_tf_model(self, **kwargs) -> None:\n",
        "        \"\"\"\"Setup the TensorFlow graph(s).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            None\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def make_neglogp_and_entropy(self,\n",
        "            B : Batch,\n",
        "            entropy_gamma : float\n",
        "            ) -> Tuple[neglogp, entropy]:\n",
        "        \"\"\"Computes the negative log-probabilities for a given\n",
        "        batch of actions, observations and priors\n",
        "        under the current policy.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        neglogp, entropy :\n",
        "            Tensorflow tensors\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def sample(self, n : int) -> Tuple[actions, obs, priors]:\n",
        "        \"\"\"Sample batch of n expressions.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        actions, obs, priors :\n",
        "            Or a batch\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_probs(self, memory_batch, log=False):\n",
        "        \"\"\"Compute the probabilities of a Batch.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        probs :\n",
        "            Or a batch\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "PrknnBIunc0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf"
      ],
      "metadata": {
        "id": "bySENsUF1qO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "2UVtAoG6vOpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Used for function annotations using the type system\n",
        "summaries = tf.TensorArray\n",
        "\n",
        "def make_policy_optimizer(sess, policy, policy_optimizer_type, **config_policy_optimizer):\n",
        "    \"\"\"Factory function for policy optimizer object.\"\"\"\n",
        "\n",
        "    if policy_optimizer_type == \"pg\":\n",
        "        from dso.policy_optimizer.pg_policy_optimizer import PGPolicyOptimizer\n",
        "        policy_optimizer_class = PGPolicyOptimizer\n",
        "    elif policy_optimizer_type == \"pqt\":\n",
        "        from dso.policy_optimizer.pqt_policy_optimizer import PQTPolicyOptimizer\n",
        "        policy_optimizer_class = PQTPolicyOptimizer\n",
        "    elif policy_optimizer_type == \"ppo\":\n",
        "        from dso.policy_optimizer.ppo_policy_optimizer import PPOPolicyOptimizer\n",
        "        policy_optimizer_class = PPOPolicyOptimizer\n",
        "    else:\n",
        "        # Custom policy import\n",
        "        policy_optimizer_class = import_custom_source(policy_optimizer_type)\n",
        "        assert issubclass(policy_optimizer_class, Policy), \\\n",
        "                \"Custom policy {} must subclass dso.policy.Policy.\".format(policy_optimizer_class)\n",
        "\n",
        "    policy_optimizer = policy_optimizer_class(sess,\n",
        "                                              policy,\n",
        "                                              **config_policy_optimizer)\n",
        "\n",
        "    return policy_optimizer\n",
        "\n",
        "class PolicyOptimizer(ABC):\n",
        "    \"\"\"Abstract class for a policy optimizer. A policy optimizer is an\n",
        "    algorithm for optimizing the parameters of a parametrized policy.\n",
        "\n",
        "    To define a new optimizer, inherit from this class and add the following\n",
        "    methods (look in _setup_policy_optimizer below):\n",
        "\n",
        "        _set_loss() : Define the \\propto \\log(p(\\tau|\\theta)) loss for the method\n",
        "        _preppend_to_summary() : Add additional fields for the tensorflow summary\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def _init(self,\n",
        "            sess : tf.compat.v1.Session(),\n",
        "            policy : Policy,\n",
        "            debug : int = 0,\n",
        "            summary : bool = False,\n",
        "            # Optimizer hyperparameters\n",
        "            optimizer : str = 'adam',\n",
        "            learning_rate : float = 0.001,\n",
        "            # Loss hyperparameters\n",
        "            entropy_weight : float = 0.005,\n",
        "            entropy_gamma : float = 1.0) -> None:\n",
        "        '''Parameters\n",
        "        ----------\n",
        "        sess : tf.Session\n",
        "            TensorFlow Session object.\n",
        "\n",
        "        policy : dso.policy.Policy\n",
        "            Parametrized probability distribution over discrete objects\n",
        "\n",
        "        debug : int\n",
        "            Debug level, also used in learn(). 0: No debug. 1: Print shapes and\n",
        "            number of parameters for each variable.\n",
        "\n",
        "        summary : bool\n",
        "            Write tensorboard summaries?\n",
        "\n",
        "        optimizer : str\n",
        "            Optimizer to use. Supports 'adam', 'rmsprop', and 'sgd'.\n",
        "\n",
        "        learning_rate : float\n",
        "            Learning rate for optimizer.\n",
        "\n",
        "        entropy_weight : float\n",
        "            Coefficient for entropy bonus.\n",
        "\n",
        "        entropy_gamma : float or None\n",
        "            Gamma in entropy decay. None (or\n",
        "            equivalently, 1.0) turns off entropy decay.\n",
        "        '''\n",
        "        self.sess = sess\n",
        "        self.policy = policy\n",
        "\n",
        "        # Needed in _setup_optimizer\n",
        "        self.debug = debug\n",
        "        self.optimizer = optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Need in self.summary\n",
        "        self.summary = summary\n",
        "\n",
        "        # Needed for make_batch_ph calls\n",
        "        self.n_choices = Program.library.L\n",
        "\n",
        "        # Placeholders, computed after instantiating expressions\n",
        "        self.batch_size = tf.placeholder(dtype=tf.int32, shape=(), name=\"batch_size\")\n",
        "        self.baseline = tf.placeholder(dtype=tf.float32, shape=(), name=\"baseline\")\n",
        "\n",
        "        # On policy batch\n",
        "        self.sampled_batch_ph = make_batch_ph(\"sampled_batch\", self.n_choices)\n",
        "\n",
        "        # Need in _init_loss_with_entropy\n",
        "        self.entropy_weight = entropy_weight\n",
        "        self.entropy_gamma = entropy_gamma\n",
        "\n",
        "\n",
        "    def _init_loss_with_entropy(self) -> None:\n",
        "        # Add entropy contribution to loss. The entropy regularizer does not\n",
        "        # depend on the particular policy optimizer\n",
        "        with tf.name_scope(\"losses\"):\n",
        "\n",
        "            self.neglogp, entropy = self.policy.make_neglogp_and_entropy(self.sampled_batch_ph, self.entropy_gamma)\n",
        "\n",
        "            # Entropy loss\n",
        "            self.entropy_loss = -self.entropy_weight * tf.reduce_mean(entropy, name=\"entropy_loss\")\n",
        "            loss = self.entropy_loss\n",
        "\n",
        "            # self.loss is modified in the child object\n",
        "            self.loss = loss\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _set_loss(self) -> None:\n",
        "        \"\"\"Define the \\propto \\log(p(\\tau|\\theta)) loss for the method\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            None\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def _setup_optimizer(self):\n",
        "        \"\"\" Setup the optimizer\n",
        "        \"\"\"\n",
        "        def make_optimizer(name, learning_rate):\n",
        "            if name == \"adam\":\n",
        "                return tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "            if name == \"rmsprop\":\n",
        "                return tf.train.RMSPropOptimizer(learning_rate=learning_rate, decay=0.99)\n",
        "            if name == \"sgd\":\n",
        "                return tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "            raise ValueError(\"Did not recognize optimizer '{}'\".format(name))\n",
        "\n",
        "        # Create training op\n",
        "        optimizer = make_optimizer(name=self.optimizer, learning_rate=self.learning_rate)\n",
        "        with tf.name_scope(\"train\"):\n",
        "            self.grads_and_vars = optimizer.compute_gradients(self.loss)\n",
        "            self.train_op = optimizer.apply_gradients(self.grads_and_vars)\n",
        "            # The two lines above are equivalent to:\n",
        "            # self.train_op = optimizer.minimize(self.loss)\n",
        "        with tf.name_scope(\"grad_norm\"):\n",
        "            self.grads, _ = list(zip(*self.grads_and_vars))\n",
        "            self.norms = tf.global_norm(self.grads)\n",
        "\n",
        "        if self.debug >= 1:\n",
        "            total_parameters = 0\n",
        "            print(\"\")\n",
        "            for variable in tf.trainable_variables():\n",
        "                shape = variable.get_shape()\n",
        "                n_parameters = np.product(shape)\n",
        "                total_parameters += n_parameters\n",
        "                print(\"Variable:    \", variable.name)\n",
        "                print(\"  Shape:     \", shape)\n",
        "                print(\"  Parameters:\", n_parameters)\n",
        "            print(\"Total parameters:\", total_parameters)\n",
        "\n",
        "\n",
        "    # abstractmethod (override if needed)\n",
        "    def _preppend_to_summary(self) -> None:\n",
        "        \"\"\"Add particular fields to the summary log.\n",
        "        Override if needed.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def _setup_summary(self) -> None:\n",
        "        \"\"\" Setup tensor flow summary\n",
        "        \"\"\"\n",
        "        with tf.name_scope(\"summary\"):\n",
        "            tf.summary.scalar(\"entropy_loss\", self.entropy_loss)\n",
        "            tf.summary.scalar(\"total_loss\", self.loss)\n",
        "            tf.summary.scalar(\"reward\", tf.reduce_mean(self.sampled_batch_ph.rewards))\n",
        "            tf.summary.scalar(\"baseline\", self.baseline)\n",
        "            tf.summary.histogram(\"reward\", self.sampled_batch_ph.rewards)\n",
        "            tf.summary.histogram(\"length\", self.sampled_batch_ph.lengths)\n",
        "            for g, v in self.grads_and_vars:\n",
        "                tf.summary.histogram(v.name, v)\n",
        "                tf.summary.scalar(v.name + '_norm', tf.norm(v))\n",
        "                tf.summary.histogram(v.name + '_grad', g)\n",
        "                tf.summary.scalar(v.name + '_grad_norm', tf.norm(g))\n",
        "            tf.summary.scalar('gradient norm', self.norms)\n",
        "            self.summaries = tf.summary.merge_all()\n",
        "\n",
        "\n",
        "    def _setup_policy_optimizer(self,\n",
        "            sess : tf.compat.v1.Session(),\n",
        "            policy : Policy,\n",
        "            debug : int = 0,\n",
        "            summary : bool = False,\n",
        "            # Optimizer hyperparameters\n",
        "            optimizer : str = 'adam',\n",
        "            learning_rate : float = 0.001,\n",
        "            # Loss hyperparameters\n",
        "            entropy_weight : float = 0.005,\n",
        "            entropy_gamma : float = 1.0) -> None:\n",
        "        \"\"\"Setup of the policy optimizer.\n",
        "        \"\"\"\n",
        "        self._init(sess, policy, debug, summary, optimizer, learning_rate, entropy_weight, entropy_gamma)\n",
        "        self._init_loss_with_entropy()\n",
        "        self._set_loss() # Abstract method defined in derived class\n",
        "        self._setup_optimizer()\n",
        "        if self.summary:\n",
        "            self._preppend_to_summary() # Abstract method defined in derived class\n",
        "            self._setup_summary()\n",
        "        else:\n",
        "            self.summaries = tf.no_op()\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def train_step(self,\n",
        "            baseline : np.ndarray,\n",
        "            sampled_batch : Batch) -> summaries:\n",
        "        \"\"\"Computes loss, trains model, and returns summaries.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            None\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yR3iitZiwZMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#core.py\n",
        "#DSO\n",
        "\n",
        "\n",
        "class DeepSymbolicOptimizer():\n",
        "    \"\"\"\n",
        "    Deep symbolic optimization model. Includes model hyperparameters and\n",
        "    training configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    config : dict or str\n",
        "        Config dictionary or path to JSON.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    config : dict\n",
        "        Configuration parameters for training.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    train\n",
        "        Builds and trains the model according to config.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.set_config(config)\n",
        "        self.sess = None\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        # Clear the cache and reset the compute graph\n",
        "        Program.clear_cache()\n",
        "        tf.reset_default_graph()\n",
        "\n",
        "        # Generate objects needed for training and set seeds\n",
        "        self.pool = self.make_pool_and_set_task()\n",
        "        self.set_seeds() # Must be called _after_ resetting graph and _after_ setting task\n",
        "\n",
        "        # Limit TF to single thread to prevent \"resource not available\" errors in parallelized runs\n",
        "        session_config = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "        self.sess = tf.Session(config=session_config)\n",
        "\n",
        "        # Setup logdirs and output files\n",
        "        self.output_file = self.make_output_file()\n",
        "        self.save_config()\n",
        "\n",
        "        # Prepare training parameters\n",
        "        self.prior = self.make_prior()\n",
        "        self.state_manager = self.make_state_manager()\n",
        "        self.policy = self.make_policy()\n",
        "        self.policy_optimizer = self.make_policy_optimizer()\n",
        "        self.gp_controller = self.make_gp_controller()\n",
        "        self.logger = self.make_logger()\n",
        "        self.trainer = self.make_trainer()\n",
        "        self.checkpoint = self.make_checkpoint()\n",
        "\n",
        "    def train_one_step(self, override=None):\n",
        "        \"\"\"\n",
        "        Train one iteration.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup the model\n",
        "        if self.sess is None:\n",
        "            self.setup()\n",
        "\n",
        "        # Run one step\n",
        "        assert not self.trainer.done, \"Training has already completed!\"\n",
        "        self.trainer.run_one_step(override)\n",
        "\n",
        "        # Maybe save next checkpoint\n",
        "        self.checkpoint.update()\n",
        "\n",
        "        # If complete, return summary\n",
        "        if self.trainer.done:\n",
        "            return self.finish()\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train the model until completion.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup the model\n",
        "        self.setup()\n",
        "\n",
        "        # Train the model until done\n",
        "        while not self.trainer.done:\n",
        "            result = self.train_one_step()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def finish(self):\n",
        "        \"\"\"\n",
        "        After training completes, finish up and return summary dict.\n",
        "        \"\"\"\n",
        "\n",
        "        # Return statistics of best Program\n",
        "        p = self.trainer.p_r_best\n",
        "        result = {\"seed\" : self.config_experiment[\"seed\"]} # Seed listed first\n",
        "        result.update({\"r\" : p.r})\n",
        "        result.update(p.evaluate)\n",
        "        result.update({\n",
        "            \"expression\" : repr(p.sympy_expr),\n",
        "            \"traversal\" : repr(p),\n",
        "            \"program\" : p\n",
        "        })\n",
        "\n",
        "        # Save all results available only after all iterations are finished. Also return metrics to be added to the summary file\n",
        "        results_add = self.logger.save_results(self.pool, self.trainer.nevals)\n",
        "        result.update(results_add)\n",
        "\n",
        "        # Close the pool\n",
        "        if self.pool is not None:\n",
        "            self.pool.close()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def set_config(self, config):\n",
        "        config = load_config(config)\n",
        "\n",
        "        self.config = defaultdict(dict, config)\n",
        "        self.config_task = self.config[\"task\"]\n",
        "        self.config_prior = self.config[\"prior\"]\n",
        "        self.config_logger = self.config[\"logging\"]\n",
        "        self.config_training = self.config[\"training\"]\n",
        "        self.config_state_manager = self.config[\"state_manager\"]\n",
        "        self.config_policy = self.config[\"policy\"]\n",
        "        self.config_policy_optimizer = self.config[\"policy_optimizer\"]\n",
        "        self.config_gp_meld = self.config[\"gp_meld\"]\n",
        "        self.config_experiment = self.config[\"experiment\"]\n",
        "        self.config_checkpoint = self.config[\"checkpoint\"]\n",
        "\n",
        "    def save_config(self):\n",
        "        # Save the config file\n",
        "        if self.output_file is not None:\n",
        "            path = os.path.join(self.config_experiment[\"save_path\"],\n",
        "                                \"config.json\")\n",
        "            # With run.py, config.json may already exist. To avoid race\n",
        "            # conditions, only record the starting seed. Use a backup seed\n",
        "            # in case this worker's seed differs.\n",
        "            backup_seed = self.config_experiment[\"seed\"]\n",
        "            if not os.path.exists(path):\n",
        "                if \"starting_seed\" in self.config_experiment:\n",
        "                    self.config_experiment[\"seed\"] = self.config_experiment[\"starting_seed\"]\n",
        "                    del self.config_experiment[\"starting_seed\"]\n",
        "                with open(path, 'w') as f:\n",
        "                    json.dump(self.config, f, indent=3)\n",
        "            self.config_experiment[\"seed\"] = backup_seed\n",
        "\n",
        "    def set_seeds(self):\n",
        "        \"\"\"\n",
        "        Set the tensorflow, numpy, and random module seeds based on the seed\n",
        "        specified in config. If there is no seed or it is None, a time-based\n",
        "        seed is used instead and is written to config.\n",
        "        \"\"\"\n",
        "\n",
        "        seed = self.config_experiment.get(\"seed\")\n",
        "\n",
        "        # Default uses current time in milliseconds, modulo 1e9\n",
        "        if seed is None:\n",
        "            seed = round(time() * 1000) % int(1e9)\n",
        "            self.config_experiment[\"seed\"] = seed\n",
        "\n",
        "        # Shift the seed based on task name\n",
        "        # This ensures a specified seed doesn't have similarities across different task names\n",
        "        task_name = Program.task.name\n",
        "        shifted_seed = seed + zlib.adler32(task_name.encode(\"utf-8\"))\n",
        "\n",
        "        # Set the seeds using the shifted seed\n",
        "        tf.set_random_seed(shifted_seed)\n",
        "        np.random.seed(shifted_seed)\n",
        "        random.seed(shifted_seed)\n",
        "\n",
        "    def make_prior(self):\n",
        "        prior = make_prior(Program.library, self.config_prior)\n",
        "        return prior\n",
        "\n",
        "    def make_state_manager(self):\n",
        "        state_manager = make_state_manager(self.config_state_manager)\n",
        "        return state_manager\n",
        "\n",
        "    def make_trainer(self):\n",
        "        trainer = Trainer(self.sess,\n",
        "                          self.policy,\n",
        "                          self.policy_optimizer,\n",
        "                          self.gp_controller,\n",
        "                          self.logger,\n",
        "                          self.pool,\n",
        "                          **self.config_training)\n",
        "        return trainer\n",
        "\n",
        "    def make_logger(self):\n",
        "        logger = StatsLogger(self.sess,\n",
        "                             self.output_file,\n",
        "                             **self.config_logger)\n",
        "        return logger\n",
        "\n",
        "    def make_checkpoint(self):\n",
        "        checkpoint = Checkpoint(self,\n",
        "                                **self.config_checkpoint)\n",
        "        return checkpoint\n",
        "\n",
        "    def make_policy_optimizer(self):\n",
        "        policy_optimizer = make_policy_optimizer(self.sess,\n",
        "                                                 self.policy,\n",
        "                                                 **self.config_policy_optimizer)\n",
        "        return policy_optimizer\n",
        "\n",
        "    def make_policy(self):\n",
        "        policy = make_policy(self.sess,\n",
        "                             self.prior,\n",
        "                             self.state_manager,\n",
        "                             **self.config_policy)\n",
        "        return policy\n",
        "\n",
        "    def make_gp_controller(self):\n",
        "        if self.config_gp_meld.pop(\"run_gp_meld\", False):\n",
        "            from dso.gp.gp_controller import GPController\n",
        "            gp_controller = GPController(self.prior,\n",
        "                                         self.config_prior,\n",
        "                                         **self.config_gp_meld)\n",
        "        else:\n",
        "            gp_controller = None\n",
        "        return gp_controller\n",
        "\n",
        "    def make_pool_and_set_task(self):\n",
        "        # Create the pool and set the Task for each worker\n",
        "\n",
        "        # Set complexity and const optimizer here so pool can access them\n",
        "        # Set the complexity function\n",
        "        complexity = self.config_training[\"complexity\"]\n",
        "        Program.set_complexity(complexity)\n",
        "\n",
        "        # Set the constant optimizer\n",
        "        const_optimizer = self.config_training[\"const_optimizer\"]\n",
        "        const_params = self.config_training[\"const_params\"]\n",
        "        const_params = const_params if const_params is not None else {}\n",
        "        Program.set_const_optimizer(const_optimizer, **const_params)\n",
        "\n",
        "        pool = None\n",
        "        n_cores_batch = self.config_training.get(\"n_cores_batch\")\n",
        "        if n_cores_batch is not None:\n",
        "            if n_cores_batch == -1:\n",
        "                n_cores_batch = cpu_count()\n",
        "            if n_cores_batch > 1:\n",
        "                pool = Pool(n_cores_batch,\n",
        "                            initializer=set_task,\n",
        "                            initargs=(self.config_task,))\n",
        "\n",
        "        # Set the Task for the parent process\n",
        "        set_task(self.config_task)\n",
        "\n",
        "        return pool\n",
        "\n",
        "    def make_output_file(self):\n",
        "        \"\"\"Generates an output filename\"\"\"\n",
        "\n",
        "        # If logdir is not provided (e.g. for pytest), results are not saved\n",
        "        if self.config_experiment.get(\"logdir\") is None:\n",
        "            self.save_path = None\n",
        "            print(\"WARNING: logdir not provided. Results will not be saved to file.\")\n",
        "            return None\n",
        "\n",
        "        # When using run.py, timestamp is already generated\n",
        "        timestamp = self.config_experiment.get(\"timestamp\")\n",
        "        if timestamp is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "            self.config_experiment[\"timestamp\"] = timestamp\n",
        "\n",
        "        # Generate save path\n",
        "        task_name = Program.task.name\n",
        "        if self.config_experiment[\"exp_name\"] is None:\n",
        "            save_path = os.path.join(\n",
        "                self.config_experiment[\"logdir\"],\n",
        "                '_'.join([task_name, timestamp]))\n",
        "        else:\n",
        "            save_path = os.path.join(\n",
        "                self.config_experiment[\"logdir\"],\n",
        "                self.config_experiment[\"exp_name\"])\n",
        "\n",
        "        self.config_experiment[\"task_name\"] = task_name\n",
        "        self.config_experiment[\"save_path\"] = save_path\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        seed = self.config_experiment[\"seed\"]\n",
        "        output_file = os.path.join(save_path,\n",
        "                                   \"dso_{}_{}.csv\".format(task_name, seed))\n",
        "\n",
        "        self.save_path = save_path\n",
        "\n",
        "        return output_file\n",
        "\n",
        "    def save(self, save_path=None):\n",
        "        self.checkpoint.save(save_path)\n",
        "\n",
        "    def load(self, load_path):\n",
        "        self.checkpoint.load(load_path)"
      ],
      "metadata": {
        "id": "nw0WCT0jrFqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load_config\n",
        "\n",
        "import os\n",
        "\n",
        "import commentjson as json\n",
        "\n",
        "def get_base_config(task, language_prior):\n",
        "    # Load base config\n",
        "    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"config_common.json\"), encoding='utf-8') as f:\n",
        "        base_config = json.load(f)\n",
        "\n",
        "    # Load task specific config\n",
        "    task_config_file = None\n",
        "    if task in [\"regression\", None]:\n",
        "        task_config_file = \"config_regression.json\"\n",
        "    elif task in [\"control\"]:\n",
        "        task_config_file = \"config_control.json\"\n",
        "    else:\n",
        "        # Custom tasks use config_common.json.\n",
        "        task_config_file = \"config_common.json\"\n",
        "    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), task_config_file), encoding='utf-8') as f:\n",
        "        task_config = json.load(f)\n",
        "\n",
        "    # Load language prior config\n",
        "    if language_prior:\n",
        "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"config_language.json\"), encoding='utf-8') as f:\n",
        "            language_config = json.load(f)\n",
        "        task_config = safe_merge_dicts(task_config, language_config)\n",
        "\n",
        "    return safe_merge_dicts(base_config, task_config)\n",
        "\n",
        "\n",
        "def load_config(config=None):\n",
        "    # Load user config\n",
        "    if isinstance(config, str):\n",
        "        with open(config, encoding='utf-8') as f:\n",
        "            user_config = json.load(f)\n",
        "    elif isinstance(config, dict):\n",
        "        user_config = config\n",
        "    else:\n",
        "        assert config is None, \"Config must be None, str, or dict.\"\n",
        "        user_config = {}\n",
        "\n",
        "    # Determine the task and language prior\n",
        "    try:\n",
        "        task = user_config[\"task\"][\"task_type\"]\n",
        "    except KeyError:\n",
        "        task = \"regression\"\n",
        "        print(\"WARNING: Task type not specified. Falling back to default task type '{}' to load config.\".format(task))\n",
        "    try:\n",
        "        language_prior = user_config[\"prior\"][\"language_model\"][\"on\"]\n",
        "    except KeyError:\n",
        "        language_prior = False\n",
        "\n",
        "    # Load task-specific base config\n",
        "    base_config = get_base_config(task, language_prior)\n",
        "\n",
        "    # Return combined configs\n",
        "    return safe_merge_dicts(base_config, user_config)"
      ],
      "metadata": {
        "id": "XGdiN6UCxOu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gYFXom-DykYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#int_it\n",
        "import os\n",
        "\n",
        "import commentjson as json\n",
        "\n",
        "def get_base_config(task, language_prior):\n",
        "    # Load base config\n",
        "    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"config_common.json\"), encoding='utf-8') as f:\n",
        "        base_config = json.load(f)\n",
        "\n",
        "    # Load task specific config\n",
        "    task_config_file = None\n",
        "    if task in [\"regression\", None]:\n",
        "        task_config_file = \"config_regression.json\"\n",
        "    elif task in [\"control\"]:\n",
        "        task_config_file = \"config_control.json\"\n",
        "    else:\n",
        "        # Custom tasks use config_common.json.\n",
        "        task_config_file = \"config_common.json\"\n",
        "    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), task_config_file), encoding='utf-8') as f:\n",
        "        task_config = json.load(f)\n",
        "\n",
        "    # Load language prior config\n",
        "    if language_prior:\n",
        "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"config_language.json\"), encoding='utf-8') as f:\n",
        "            language_config = json.load(f)\n",
        "        task_config = safe_merge_dicts(task_config, language_config)\n",
        "\n",
        "    return safe_merge_dicts(base_config, task_config)\n",
        "\n",
        "\n",
        "def load_config(config=None):\n",
        "    # Load user config\n",
        "    if isinstance(config, str):\n",
        "        with open(config, encoding='utf-8') as f:\n",
        "            user_config = json.load(f)\n",
        "    elif isinstance(config, dict):\n",
        "        user_config = config\n",
        "    else:\n",
        "        assert config is None, \"Config must be None, str, or dict.\"\n",
        "        user_config = {}\n",
        "\n",
        "    # Determine the task and language prior\n",
        "    try:\n",
        "        task = user_config[\"task\"][\"task_type\"]\n",
        "    except KeyError:\n",
        "        task = \"regression\"\n",
        "        print(\"WARNING: Task type not specified. Falling back to default task type '{}' to load config.\".format(task))\n",
        "    try:\n",
        "        language_prior = user_config[\"prior\"][\"language_model\"][\"on\"]\n",
        "    except KeyError:\n",
        "        language_prior = False\n",
        "\n",
        "    # Load task-specific base config\n",
        "    base_config = get_base_config(task, language_prior)\n",
        "\n",
        "    # Return combined configs\n",
        "    return safe_merge_dicts(base_config, user_config)\n"
      ],
      "metadata": {
        "id": "Qwp2z6L8BKni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQa-Ez5nD2S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to the directory you want to create\n",
        "save_path = \"/content/output\"\n",
        "\n",
        "# Create the directory\n",
        "os.makedirs(save_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "lF9EMo3G95Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Hardcoded parameters\n",
        "    runs = 5\n",
        "    n_cores_task = 4\n",
        "    seed = 42\n",
        "    exp_name = \"DSO_Example\"\n",
        "\n",
        "    # Define the configuration directly within the script\n",
        "    config = {\n",
        "        \"experiment\": {\n",
        "            \"seed\": seed,\n",
        "            \"save_path\": \"/path/to/your/save/directory\",\n",
        "            \"exp_name\": exp_name,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "        },\n",
        "        \"task\": {\n",
        "            \"task_type\": \"regression\",\n",
        "            \"dataset\": \"path/to/your/dataset.csv\",\n",
        "            \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "            \"metric\": \"inv_nrmse\",\n",
        "            \"metric_params\": [1.0],\n",
        "            \"threshold\": 1e-12,\n",
        "            \"protected\": False,\n",
        "            \"reward_noise\": 0.0,\n",
        "            \"reward_noise_type\": \"r\",\n",
        "            \"normalize_variance\": False\n",
        "        },\n",
        "        \"training\": {\n",
        "            \"n_samples\": 2000000,\n",
        "            \"batch_size\": 1000,\n",
        "            \"epsilon\": 0.05,\n",
        "            \"n_cores_batch\": 1\n",
        "        },\n",
        "        \"policy_optimizer\": {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"entropy_weight\": 0.03,\n",
        "            \"entropy_gamma\": 0.7\n",
        "        },\n",
        "        \"prior\": {\n",
        "            \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "            \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "            \"inverse\": {\"on\": True},\n",
        "            \"trig\": {\"on\": True},\n",
        "            \"const\": {\"on\": True},\n",
        "            \"no_inputs\": {\"on\": True},\n",
        "            \"uniform_arity\": {\"on\": True},\n",
        "            \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "            \"domain_range\": {\"on\": False}\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "4vBD6E-sAHt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "JoRnWovIG0Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dso(config):\n",
        "    \"\"\"Trains DSO and returns dict of reward, expression, and traversal\"\"\"\n",
        "\n",
        "    print(\"\\n== TRAINING SEED {} START ============\".format(config[\"experiment\"][\"seed\"]))\n",
        "\n",
        "    # For some reason, for the control task, the environment needs to be instantiated\n",
        "    # before creating the pool. Otherwise, gym.make() hangs during the pool initializer\n",
        "    if config[\"task\"][\"task_type\"] == \"control\" and config[\"training\"][\"n_cores_batch\"] > 1:\n",
        "        import gym\n",
        "        import dso.task.control # Registers custom and third-party environments\n",
        "        gym.make(config[\"task\"][\"env\"])\n",
        "\n",
        "    # Train the model\n",
        "    model = DeepSymbolicOptimizer(deepcopy(config))\n",
        "    start = time.time()\n",
        "    result = model.train()\n",
        "    result[\"t\"] = time.time() - start\n",
        "    result.pop(\"program\")\n",
        "\n",
        "    save_path = model.config_experiment[\"save_path\"]\n",
        "    summary_path = os.path.join(save_path, \"summary.csv\")\n",
        "    print(\"== TRAINING SEED {} END ==============\".format(config[\"experiment\"][\"seed\"]))\n",
        "\n",
        "    return result, summary_path"
      ],
      "metadata": {
        "id": "R3i01qJhG1ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_summary(config, runs, messages):\n",
        "    text = '\\n== EXPERIMENT SETUP START ===========\\n'\n",
        "    text += 'Task type            : {}\\n'.format(config[\"task\"][\"task_type\"])\n",
        "    if config[\"task\"][\"task_type\"] == \"regression\":\n",
        "        text += 'Dataset              : {}\\n'.format(config[\"task\"][\"dataset\"])\n",
        "    elif config[\"task\"][\"task_type\"] == \"control\":\n",
        "        text += 'Environment          : {}\\n'.format(config[\"task\"][\"env\"])\n",
        "    text += 'Starting seed        : {}\\n'.format(config[\"experiment\"][\"seed\"])\n",
        "    text += 'Runs                 : {}\\n'.format(runs)\n",
        "    if len(messages) > 0:\n",
        "        text += 'Additional context   :\\n'\n",
        "        for message in messages:\n",
        "            text += \"      {}\\n\".format(message)\n",
        "    text += '== EXPERIMENT SETUP END ============='\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "8JRipWvpIeOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Hardcoded parameters\n",
        "    runs = 5\n",
        "    n_cores_task = 4\n",
        "    seed = 42\n",
        "    exp_name = \"DSO_Example\"\n",
        "\n",
        "    # Define the configuration directly within the script\n",
        "    config = {\n",
        "        \"experiment\": {\n",
        "            \"seed\": seed,\n",
        "            \"save_path\": \"/path/to/your/save/directory\",\n",
        "            \"exp_name\": exp_name,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "        },\n",
        "        \"task\": {\n",
        "            \"task_type\": \"regression\",\n",
        "            \"dataset\": \"/content/train_feature.csv\",\n",
        "            \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "            \"metric\": \"inv_nrmse\",\n",
        "            \"metric_params\": [1.0],\n",
        "            \"threshold\": 1e-12,\n",
        "            \"protected\": False,\n",
        "            \"reward_noise\": 0.0,\n",
        "            \"reward_noise_type\": \"r\",\n",
        "            \"normalize_variance\": False\n",
        "        },\n",
        "        \"training\": {\n",
        "            \"n_samples\": 2000000,\n",
        "            \"batch_size\": 1000,\n",
        "            \"epsilon\": 0.05,\n",
        "            \"n_cores_batch\": 1\n",
        "        },\n",
        "        \"policy_optimizer\": {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"entropy_weight\": 0.03,\n",
        "            \"entropy_gamma\": 0.7\n",
        "        },\n",
        "        \"prior\": {\n",
        "            \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "            \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "            \"inverse\": {\"on\": True},\n",
        "            \"trig\": {\"on\": True},\n",
        "            \"const\": {\"on\": True},\n",
        "            \"no_inputs\": {\"on\": True},\n",
        "            \"uniform_arity\": {\"on\": True},\n",
        "            \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "            \"domain_range\": {\"on\": False}\n",
        "        }\n",
        "    }\n",
        "    print(\"\\n== TRAINING START ============\")  # Optional starting message\n",
        "    results = []\n",
        "    for i in range(runs):\n",
        "        config[\"experiment\"][\"seed\"] = seed + i  # Increment seed\n",
        "\n",
        "        result = train_dso(deepcopy(config))  # Deepcopy avoids overwriting\n",
        "\n",
        "        # Assuming 'result' already includes a performance metric (e.g., 'reward')\n",
        "        best_reward = result.get(\"reward\", -1)  # Or your relevant metric's key\n",
        "\n",
        "        results.append(result)\n",
        "        print(f\"Run {i} Best Reward: {best_reward}\")\n",
        "\n",
        "    print(\"== TRAINING END ==============\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def train_dso(config):\n",
        "  model = DeepSymbolicOptimizer(config)\n",
        "  start = time.time()\n",
        "  result = model.train()\n",
        "  result[\"t\"] = time.time() - start\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "yxnoE0uKKiXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Script started.\")\n",
        "    # Hardcoded parameters\n",
        "    runs = 5\n",
        "    n_cores_task = 4\n",
        "    seed = 42\n",
        "    exp_name = \"DSO_Example\"\n",
        "\n",
        "    # Define the configuration directly within the script\n",
        "    config = {\n",
        "        \"experiment\": {\n",
        "            \"seed\": seed,\n",
        "            \"save_path\": \"/path/to/your/save/directory\",\n",
        "            \"exp_name\": exp_name,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "        },\n",
        "        \"task\": {\n",
        "            \"task_type\": \"regression\",  # Ensure task type matches your problem\n",
        "            \"dataset\": \"/content/train_feature.csv\",  # Updated dataset path\n",
        "            \"validation_dataset\": \"/content/train_feature.csv\",  # Added validation dataset path\n",
        "            \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "            \"metric\": \"inv_nrmse\",  # Confirm the evaluation metric\n",
        "            \"metric_params\": [1.0],\n",
        "            \"threshold\": 1e-12,\n",
        "            \"protected\": False,\n",
        "            \"reward_noise\": 0.0,\n",
        "            \"reward_noise_type\": \"r\",\n",
        "            \"normalize_variance\": False\n",
        "        },\n",
        "        \"training\": {\n",
        "            \"n_samples\": 2000000,\n",
        "            \"batch_size\": 1000,\n",
        "            \"epsilon\": 0.05,\n",
        "            \"n_cores_batch\": 1\n",
        "        },\n",
        "        \"policy_optimizer\": {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"entropy_weight\": 0.03,\n",
        "            \"entropy_gamma\": 0.7\n",
        "        },\n",
        "        \"prior\": {\n",
        "            \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "            \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "            \"inverse\": {\"on\": True},\n",
        "            \"trig\": {\"on\": True},\n",
        "            \"const\": {\"on\": True},\n",
        "            \"no_inputs\": {\"on\": True},\n",
        "            \"uniform_arity\": {\"on\": True},\n",
        "            \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "            \"domain_range\": {\"on\": False}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"\\n== TRAINING START ============\")\n",
        "    results = []\n",
        "    for i in range(runs):\n",
        "        config[\"experiment\"][\"seed\"] = seed + i  # Increment seed\n",
        "\n",
        "        result = train_dso(deepcopy(config))  # Deepcopy avoids overwriting\n",
        "\n",
        "        # Assuming 'result' includes a performance metric\n",
        "        best_reward = result.get(\"reward\", -1)\n",
        "\n",
        "        results.append(result)\n",
        "        print(f\"Run {i} Best Reward: {best_reward}\")\n",
        "\n",
        "    print(\"== TRAINING END ==============\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def train_dso(config):\n",
        "    model = DeepSymbolicOptimizer(config)\n",
        "    start = time.time()\n",
        "    result = model.train()\n",
        "    result[\"t\"] = time.time() - start\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "8isPTELpmIeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "# Ensure you have imported the DeepSymbolicOptimizer class from its respective module\n",
        "\n",
        "class DeepSymbolicOptimizer:\n",
        "    # Dummy class definition - Replace with actual implementation\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def train(self):\n",
        "        # Dummy train method - Replace with actual implementation\n",
        "        print(\"Training model...\")\n",
        "        # Simulate training process\n",
        "        time.sleep(5)\n",
        "        print(\"Training complete.\")\n",
        "        return {\"reward\": 20 }  # Replace with actual reward\n",
        "\n",
        "def main():\n",
        "    print(\"Script started.\")\n",
        "    # Hardcoded parameters\n",
        "    runs = 5\n",
        "    n_cores_task = 4\n",
        "    seed = 42\n",
        "    exp_name = \"DSO_Example\"\n",
        "\n",
        "    # Define the configuration directly within the script\n",
        "    config = {\n",
        "        \"experiment\": {\n",
        "            \"seed\": seed,\n",
        "            \"save_path\": \"/mnt/data/your_save_directory\",  # Update to your actual save path\n",
        "            \"exp_name\": exp_name,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "        },\n",
        "        \"task\": {\n",
        "            \"task_type\": \"regression\",\n",
        "            \"dataset\": \"/content/train_feature.csv\",  # Updated dataset path\n",
        "            \"validation_dataset\": \"/content/validation_feature.csv\",  # Updated validation dataset path\n",
        "            \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "            \"metric\": \"inv_nrmse\",\n",
        "            \"metric_params\": [1.0],\n",
        "            \"threshold\": 1e-12,\n",
        "            \"protected\": False,\n",
        "            \"reward_noise\": 0.0,\n",
        "            \"reward_noise_type\": \"r\",\n",
        "            \"normalize_variance\": False\n",
        "        },\n",
        "        \"training\": {\n",
        "            \"n_samples\": 2000000,\n",
        "            \"batch_size\": 1000,\n",
        "            \"epsilon\": 0.05,\n",
        "            \"n_cores_batch\": 1\n",
        "        },\n",
        "        \"policy_optimizer\": {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"entropy_weight\": 0.03,\n",
        "            \"entropy_gamma\": 0.7\n",
        "        },\n",
        "        \"prior\": {\n",
        "            \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "            \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "            \"inverse\": {\"on\": True},\n",
        "            \"trig\": {\"on\": True},\n",
        "            \"const\": {\"on\": True},\n",
        "            \"no_inputs\": {\"on\": True},\n",
        "            \"uniform_arity\": {\"on\": True},\n",
        "            \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "            \"domain_range\": {\"on\": False}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"\\n== TRAINING START ============\")\n",
        "    results = []\n",
        "    for i in range(runs):\n",
        "        print(f\"Starting run {i}...\")  # Indicates which run is starting.\n",
        "        config[\"experiment\"][\"seed\"] = seed + i  # Increment seed\n",
        "\n",
        "        result = train_dso(deepcopy(config))  # Deepcopy avoids overwriting\n",
        "\n",
        "        # Assuming 'result' includes a performance metric\n",
        "        best_reward = result.get(\"reward\", -1)\n",
        "        results.append(result)\n",
        "        print(f\"Run {i} Best Reward: {best_reward}\")\n",
        "\n",
        "    print(\"== TRAINING END ==============\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def train_dso(config):\n",
        "    print(\"Training DSO...\")  # Indicates the start of the training process.\n",
        "    model = DeepSymbolicOptimizer(config)\n",
        "    start = time.time()\n",
        "    result = model.train()\n",
        "    result[\"t\"] = time.time() - start\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf8_AHIwn8tW",
        "outputId": "19e57cce-8c02-43d6-d5ad-5134b1c9c3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script started.\n",
            "\n",
            "== TRAINING START ============\n",
            "Starting run 0...\n",
            "Training DSO...\n",
            "Training model...\n",
            "Training complete.\n",
            "Run 0 Best Reward: 20\n",
            "Starting run 1...\n",
            "Training DSO...\n",
            "Training model...\n",
            "Training complete.\n",
            "Run 1 Best Reward: 20\n",
            "Starting run 2...\n",
            "Training DSO...\n",
            "Training model...\n",
            "Training complete.\n",
            "Run 2 Best Reward: 20\n",
            "Starting run 3...\n",
            "Training DSO...\n",
            "Training model...\n",
            "Training complete.\n",
            "Run 3 Best Reward: 20\n",
            "Starting run 4...\n",
            "Training DSO...\n",
            "Training model...\n",
            "Training complete.\n",
            "Run 4 Best Reward: 20\n",
            "== TRAINING END ==============\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "class DeepSymbolicOptimizer:\n",
        "  def __init__(self, config):\n",
        "        self.config = config\n",
        "  def train(self):\n",
        "        print(\"Training model...\")\n",
        "        self.optimizer.fit()\n",
        "        print(\"Training complete.\")\n",
        "        return {\"reward\": 42}  # Placeholder for the reward\n",
        "\n",
        "  def get_equation(self):\n",
        "        return self.optimizer.best_expression\n",
        "\n",
        "   # Get the best expression from DSO\n",
        "\n",
        "def train_dso(config):\n",
        "    print(\"Training DSO...\")\n",
        "    model = DeepSymbolicOptimizer(config)\n",
        "    start = time.time()\n",
        "    result = model.train()\n",
        "    equation = model.get_equation()  # Extract the equation\n",
        "    result[\"equation\"] = equation  # Store the equation in the result dictionary\n",
        "    result[\"t\"] = time.time() - start\n",
        "    return result\n",
        "def get_equation(self):\n",
        "        return self.optimizer.best_expression\n",
        "def main():\n",
        "    print(\"Script started.\")\n",
        "    # Hardcoded parameters\n",
        "    runs = 5\n",
        "    n_cores_task = 4\n",
        "    seed = 42\n",
        "    exp_name = \"DSO_Example\"\n",
        "\n",
        "    # Define the configuration directly within the script\n",
        "    config = {\n",
        "        \"experiment\": {\n",
        "            \"seed\": seed,\n",
        "            \"save_path\": \"/mnt/data/your_save_directory\",  # Update to your actual save path\n",
        "            \"exp_name\": exp_name,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "        },\n",
        "        \"task\": {\n",
        "            \"task_type\": \"regression\",\n",
        "            \"dataset\": \"/content/train_feature.csv\",  # Updated dataset path\n",
        "            \"validation_dataset\": \"/content/validation_feature.csv\",  # Updated validation dataset path\n",
        "            \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "            \"metric\": \"inv_nrmse\",\n",
        "            \"metric_params\": [1.0],\n",
        "            \"threshold\": 1e-12,\n",
        "            \"protected\": False,\n",
        "            \"reward_noise\": 0.0,\n",
        "            \"reward_noise_type\": \"r\",\n",
        "            \"normalize_variance\": False\n",
        "        },\n",
        "        \"training\": {\n",
        "            \"n_samples\": 2000000,\n",
        "            \"batch_size\": 1000,\n",
        "            \"epsilon\": 0.05,\n",
        "            \"n_cores_batch\": 1\n",
        "        },\n",
        "        \"policy_optimizer\": {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"entropy_weight\": 0.03,\n",
        "            \"entropy_gamma\": 0.7\n",
        "        },\n",
        "        \"prior\": {\n",
        "            \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "            \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "            \"inverse\": {\"on\": True},\n",
        "            \"trig\": {\"on\": True},\n",
        "            \"const\": {\"on\": True},\n",
        "            \"no_inputs\": {\"on\": True},\n",
        "            \"uniform_arity\": {\"on\": True},\n",
        "            \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "            \"domain_range\": {\"on\": False}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"\\n== TRAINING START ============\")\n",
        "    print(\"Script started.\")\n",
        "    # Configuration and other setup\n",
        "    results = []\n",
        "    for i in range(runs):\n",
        "        print(f\"Starting run {i}...\")\n",
        "        config[\"experiment\"][\"seed\"] = seed + i\n",
        "        result = train_dso(deepcopy(config))\n",
        "        best_reward = result.get(\"reward\", -1)\n",
        "        equation = result.get(\"equation\", \"No equation found\")\n",
        "        print(f\"Run {i} Best Reward: {best_reward}, Equation: {equation}\")\n",
        "        results.append(result)\n",
        "    print(\"== TRAINING END ==============\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "eVfnmrkGrUcW",
        "outputId": "95b04d50-a321-494a-a3ad-ba439e6bbbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script started.\n",
            "\n",
            "== TRAINING START ============\n",
            "Script started.\n",
            "Starting run 0...\n",
            "Training DSO...\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DeepSymbolicOptimizer' object has no attribute 'optimizer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-2244c35926aa>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-2244c35926aa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting run {i}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mbest_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mequation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"equation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No equation found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-2244c35926aa>\u001b[0m in \u001b[0;36mtrain_dso\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepSymbolicOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mequation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_equation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Extract the equation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"equation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mequation\u001b[0m  \u001b[0;31m# Store the equation in the result dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-2244c35926aa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# Placeholder for the reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DeepSymbolicOptimizer' object has no attribute 'optimizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Script started.\")\n",
        "    # Hardcoded parameters\n",
        "    runs = 5\n",
        "    n_cores_task = 4\n",
        "    seed = 42\n",
        "    exp_name = \"DSO_Example\"\n",
        "\n",
        "    # Define the configuration directly within the script\n",
        "    config = {\n",
        "        \"experiment\": {\n",
        "            \"seed\": seed,\n",
        "            \"save_path\": \"/mnt/data/your_save_directory\",  # Update to your actual save path\n",
        "            \"exp_name\": exp_name,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "        },\n",
        "        \"task\": {\n",
        "            \"task_type\": \"regression\",\n",
        "            \"dataset\": \"/content/train_feature.csv\",  # Updated dataset path\n",
        "            \"validation_dataset\": \"/content/validation_feature.csv\",  # Updated validation dataset path\n",
        "            \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "            \"metric\": \"inv_nrmse\",\n",
        "            \"metric_params\": [1.0],\n",
        "            \"threshold\": 1e-12,\n",
        "            \"protected\": False,\n",
        "            \"reward_noise\": 0.0,\n",
        "            \"reward_noise_type\": \"r\",\n",
        "            \"normalize_variance\": False\n",
        "        },\n",
        "        \"training\": {\n",
        "            \"n_samples\": 2000000,\n",
        "            \"batch_size\": 1000,\n",
        "            \"epsilon\": 0.05,\n",
        "            \"n_cores_batch\": 1\n",
        "        },\n",
        "        \"policy_optimizer\": {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"entropy_weight\": 0.03,\n",
        "            \"entropy_gamma\": 0.7\n",
        "        },\n",
        "        \"prior\": {\n",
        "            \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "            \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "            \"inverse\": {\"on\": True},\n",
        "            \"trig\": {\"on\": True},\n",
        "            \"const\": {\"on\": True},\n",
        "            \"no_inputs\": {\"on\": True},\n",
        "            \"uniform_arity\": {\"on\": True},\n",
        "            \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "            \"domain_range\": {\"on\": False}\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "vkO8gCA4wjR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "\n",
        "# Dummy classes for illustration - replace with actual imports from DSO or your implementation\n",
        "class Task(ABC):\n",
        "    \"\"\"\n",
        "    Object specifying a symbolic search task.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    library : Library\n",
        "        Library of Tokens.\n",
        "\n",
        "    stochastic : bool\n",
        "        Whether the reward function of the task is stochastic.\n",
        "\n",
        "    task_type : str\n",
        "        Task type: regression, control, or binding.\n",
        "\n",
        "    name : str\n",
        "        Unique name for instance of this task.\n",
        "    \"\"\"\n",
        "\n",
        "    task_type = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def reward_function(self, program, optimizing=False):\n",
        "        \"\"\"\n",
        "        The reward function for this task.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        program : dso.program.Program\n",
        "\n",
        "            The Program to compute reward of.\n",
        "\n",
        "        optimizing : bool\n",
        "\n",
        "            Whether the reward is computed for PlaceholderConstant optimization.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        reward : float\n",
        "\n",
        "            Fitness/reward of the program.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, program):\n",
        "        \"\"\"\n",
        "        The evaluation metric for this task.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        program : dso.program.Program\n",
        "\n",
        "            The Program to evaluate.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        info : dict\n",
        "\n",
        "            Dictionary of evaluation metrics. Special key \"success\" is used to\n",
        "            trigger early stopping.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "        \"\"\"\n",
        "        Produce the next observation and prior from the current observation and\n",
        "        list of actions so far. Observations must be 1-D np.float32 vectors.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        actions : np.ndarray (dtype=np.int32)\n",
        "            Actions selected so far, shape (batch_size, current_length)\n",
        "\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Previous observation, shape (batch_size, OBS_DIM).\n",
        "\n",
        "        already_finished : np.ndarray (dtype=bool)\n",
        "            Whether the object has *already* been completed.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        next_obs : np.ndarray (dtype=np.float32)\n",
        "            The next observation, shape (batch_size, OBS_DIM).\n",
        "\n",
        "        prior : np.ndarray (dtype=np.float32)\n",
        "            Prior for selecting the next token, shape (batch_size,\n",
        "            self.library.L).\n",
        "\n",
        "        finished : np.ndarray (dtype=bool)\n",
        "            Whether the object has *ever* been completed.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset_task(self):\n",
        "        \"\"\"\n",
        "        Create the starting observation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Starting observation, shape (batch_size, OBS_DIM).\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class HierarchicalTask(Task):\n",
        "    \"\"\"\n",
        "    A Task in which the search space is a binary tree. Observations include\n",
        "    the previous action, the parent, the sibling, and/or the number of dangling\n",
        "    (unselected) nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    OBS_DIM = 4 # action, parent, sibling, dangling\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Task).__init__()\n",
        "\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "\n",
        "        dangling = obs[:, 3] # Shape of obs: (?, 4)\n",
        "        action = actions[:, -1] # Current action\n",
        "        lib = self.library\n",
        "\n",
        "        # Compute parents and siblings\n",
        "        parent, sibling = parents_siblings(actions,\n",
        "                                           arities=lib.arities,\n",
        "                                           parent_adjust=lib.parent_adjust,\n",
        "                                           empty_parent=lib.EMPTY_PARENT,\n",
        "                                           empty_sibling=lib.EMPTY_SIBLING)\n",
        "\n",
        "        # Compute dangling\n",
        "        dangling += lib.arities[action] - 1\n",
        "\n",
        "        # Compute finished\n",
        "        just_finished = (dangling == 0) # Trees that completed _this_ time step\n",
        "        # [batch_size]\n",
        "        finished = np.logical_or(just_finished,\n",
        "                                 already_finished)\n",
        "\n",
        "        # Compute priors\n",
        "        prior = self.prior(actions, parent, sibling, dangling, finished) # (?, n_choices)\n",
        "\n",
        "        # Combine observation dimensions\n",
        "        next_obs = np.stack([action, parent, sibling, dangling], axis=1) # (?, 4)\n",
        "        next_obs = next_obs.astype(np.float32)\n",
        "\n",
        "        return next_obs, prior, finished\n",
        "\n",
        "    def reset_task(self, prior):\n",
        "        \"\"\"\n",
        "        Returns the initial observation: empty action, parent, and sibling, and\n",
        "        dangling is 1.\n",
        "        \"\"\"\n",
        "\n",
        "        self.prior = prior\n",
        "\n",
        "        # Order of observations: action, parent, sibling, dangling\n",
        "        initial_obs = np.array([self.library.EMPTY_ACTION,\n",
        "                                self.library.EMPTY_PARENT,\n",
        "                                self.library.EMPTY_SIBLING,\n",
        "                                1],\n",
        "                               dtype=np.float32)\n",
        "        return initial_obs\n",
        "\n",
        "\n",
        "class SequentialTask(Task):\n",
        "    \"\"\"\n",
        "    A Task in which the search space is a (possibly variable-length) sequence.\n",
        "    The observation is simply the previous action.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_task(task_type, **config_task):\n",
        "    \"\"\"\n",
        "    Factory function for Task object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    task_type : str\n",
        "        Type of task:\n",
        "        \"regression\" : Symbolic regression task.\n",
        "        \"control\" : Episodic reinforcement learning task.\n",
        "        \"binding\": AbAg binding affinity optimization task.\n",
        "\n",
        "    config_task : kwargs\n",
        "        Task-specific arguments. See specifications of task_dict.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    task : Task\n",
        "        Task object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Lazy import of task factory functions\n",
        "    if task_type == 'binding':\n",
        "        from dso.task.binding.binding import BindingTask\n",
        "        task_class = BindingTask\n",
        "    elif task_type == \"regression\":\n",
        "        from dso.task.regression.regression import RegressionTask\n",
        "        task_class = RegressionTask\n",
        "    elif task_type == \"control\":\n",
        "        from dso.task.control.control import ControlTask\n",
        "        task_class = ControlTask\n",
        "    else:\n",
        "        # Custom task import\n",
        "        task_class = import_custom_source(task_type)\n",
        "        assert issubclass(task_class, Task), \\\n",
        "            \"Custom task {} must subclass dso.task.Task.\".format(task_class)\n",
        "\n",
        "    task = task_class(**config_task)\n",
        "    return task\n",
        "\n",
        "\n",
        "def set_task(config_task):\n",
        "    \"\"\"Helper function to make set the Program class Task and execute function\n",
        "    from task config.\"\"\"\n",
        "\n",
        "    # Use of protected functions is the same for all tasks, so it's handled separately\n",
        "    protected = config_task[\"protected\"] if \"protected\" in config_task else False\n",
        "\n",
        "    Program.set_execute(protected)\n",
        "    task = make_task(**config_task)\n",
        "    Program.set_task(task)\n",
        "\n",
        "class LanguageModel(object):\n",
        "    def __init__(self, vocabulary_size, embedding_size, num_layers, num_hidden, mode='train'):\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.x = tf.compat.v1.placeholder(tf.int32, [None, None], name=\"x\") # whole seq + seq len\n",
        "        self.keep_prob = tf.compat.v1.placeholder(tf.float32, [], name=\"keep_prob\")\n",
        "        self.batch_size = tf.compat.v1.shape(self.x)[0]\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.lm_input = self.x[:, :-2]\n",
        "            self.seq_len = self.x[:, -1]\n",
        "        elif mode == 'predict':\n",
        "            self.lm_input = self.x[:,:]\n",
        "            self.seq_len = tf.reduce_sum(tf.sign(self.lm_input), 1)\n",
        "\n",
        "        # Embedding (optional)\n",
        "        with tf.name_scope(\"embedding\"):\n",
        "            init_embeddings = tf.random.uniform([vocabulary_size, self.embedding_size])\n",
        "            embeddings = tf.compat.v1.get_variable(\"embeddings\", initializer=init_embeddings)\n",
        "            lm_input_emb = tf.nn.embedding_lookup(embeddings, self.lm_input)\n",
        "\n",
        "        with tf.compat.v1.variable_scope(\"rnn\"):\n",
        "            def make_cell():\n",
        "                cell = BasicRNNCell(self.num_hidden)  # Or use LSTM(...) for better performance\n",
        "                cell = Dropout(1 - self.keep_prob)(cell)\n",
        "                return cell\n",
        "\n",
        "            cell = RNN([make_cell() for _ in range(self.num_layers)])\n",
        "\n",
        "            self.initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
        "            rnn_outputs, self.last_state = tf.nn.dynamic_rnn(\n",
        "                cell=cell,\n",
        "                initial_state=self.initial_state,\n",
        "                inputs=lm_input_emb,  # Assuming you're using embeddings\n",
        "                sequence_length=self.seq_len,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        with tf.name_scope(\"output\"):\n",
        "            self.logits = Dense(vocabulary_size)(rnn_outputs)  # Use tf.layers.dense for TF < 2.0\n",
        "\n",
        "        with tf.name_scope(\"loss\"):\n",
        "            if mode == \"train\":\n",
        "                target = self.x[:, 1:-1]\n",
        "            elif mode == \"predict\":\n",
        "                target = self.x[:, :]\n",
        "\n",
        "            self.loss = SparseCategoricalCrossentropy(from_logits=True)(target, self.logits)\n",
        "\n",
        "class DeepSymbolicOptimizer():\n",
        "    \"\"\"\n",
        "    Deep symbolic optimization model. Includes model hyperparameters and\n",
        "    training configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    config : dict or str\n",
        "        Config dictionary or path to JSON.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    config : dict\n",
        "        Configuration parameters for training.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    train\n",
        "        Builds and trains the model according to config.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.set_config(config)\n",
        "        self.sess = None\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        # Clear the cache and reset the compute graph\n",
        "        Program.clear_cache()\n",
        "        tf.reset_default_graph()\n",
        "\n",
        "        # Generate objects needed for training and set seeds\n",
        "        self.pool = self.make_pool_and_set_task()\n",
        "        self.set_seeds() # Must be called _after_ resetting graph and _after_ setting task\n",
        "\n",
        "        # Limit TF to single thread to prevent \"resource not available\" errors in parallelized runs\n",
        "        session_config = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "        self.sess = tf.Session(config=session_config)\n",
        "\n",
        "        # Setup logdirs and output files\n",
        "        self.output_file = self.make_output_file()\n",
        "        self.save_config()\n",
        "\n",
        "        # Prepare training parameters\n",
        "        self.prior = self.make_prior()\n",
        "        self.state_manager = self.make_state_manager()\n",
        "        self.policy = self.make_policy()\n",
        "        self.policy_optimizer = self.make_policy_optimizer()\n",
        "        self.gp_controller = self.make_gp_controller()\n",
        "        self.logger = self.make_logger()\n",
        "        self.trainer = self.make_trainer()\n",
        "        self.checkpoint = self.make_checkpoint()\n",
        "\n",
        "    def train_one_step(self, override=None):\n",
        "        \"\"\"\n",
        "        Train one iteration.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup the model\n",
        "        if self.sess is None:\n",
        "            self.setup()\n",
        "\n",
        "        # Run one step\n",
        "        assert not self.trainer.done, \"Training has already completed!\"\n",
        "        self.trainer.run_one_step(override)\n",
        "\n",
        "        # Maybe save next checkpoint\n",
        "        self.checkpoint.update()\n",
        "\n",
        "        # If complete, return summary\n",
        "        if self.trainer.done:\n",
        "            return self.finish()\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train the model until completion.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup the model\n",
        "        self.setup()\n",
        "\n",
        "        # Train the model until done\n",
        "        while not self.trainer.done:\n",
        "            result = self.train_one_step()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def finish(self):\n",
        "        \"\"\"\n",
        "        After training completes, finish up and return summary dict.\n",
        "        \"\"\"\n",
        "\n",
        "        # Return statistics of best Program\n",
        "        p = self.trainer.p_r_best\n",
        "        result = {\"seed\" : self.config_experiment[\"seed\"]} # Seed listed first\n",
        "        result.update({\"r\" : p.r})\n",
        "        result.update(p.evaluate)\n",
        "        result.update({\n",
        "            \"expression\" : repr(p.sympy_expr),\n",
        "            \"traversal\" : repr(p),\n",
        "            \"program\" : p\n",
        "        })\n",
        "\n",
        "        # Save all results available only after all iterations are finished. Also return metrics to be added to the summary file\n",
        "        results_add = self.logger.save_results(self.pool, self.trainer.nevals)\n",
        "        result.update(results_add)\n",
        "\n",
        "        # Close the pool\n",
        "        if self.pool is not None:\n",
        "            self.pool.close()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def set_config(self, config):\n",
        "        config = load_config(config)\n",
        "\n",
        "        self.config = defaultdict(dict, config)\n",
        "        self.config_task = self.config[\"task\"]\n",
        "        self.config_prior = self.config[\"prior\"]\n",
        "        self.config_logger = self.config[\"logging\"]\n",
        "        self.config_training = self.config[\"training\"]\n",
        "        self.config_state_manager = self.config[\"state_manager\"]\n",
        "        self.config_policy = self.config[\"policy\"]\n",
        "        self.config_policy_optimizer = self.config[\"policy_optimizer\"]\n",
        "        self.config_gp_meld = self.config[\"gp_meld\"]\n",
        "        self.config_experiment = self.config[\"experiment\"]\n",
        "        self.config_checkpoint = self.config[\"checkpoint\"]\n",
        "\n",
        "    def save_config(self):\n",
        "        # Save the config file\n",
        "        if self.output_file is not None:\n",
        "            path = os.path.join(self.config_experiment[\"save_path\"],\n",
        "                                \"config.json\")\n",
        "            # With run.py, config.json may already exist. To avoid race\n",
        "            # conditions, only record the starting seed. Use a backup seed\n",
        "            # in case this worker's seed differs.\n",
        "            backup_seed = self.config_experiment[\"seed\"]\n",
        "            if not os.path.exists(path):\n",
        "                if \"starting_seed\" in self.config_experiment:\n",
        "                    self.config_experiment[\"seed\"] = self.config_experiment[\"starting_seed\"]\n",
        "                    del self.config_experiment[\"starting_seed\"]\n",
        "                with open(path, 'w') as f:\n",
        "                    json.dump(self.config, f, indent=3)\n",
        "            self.config_experiment[\"seed\"] = backup_seed\n",
        "\n",
        "    def set_seeds(self):\n",
        "        \"\"\"\n",
        "        Set the tensorflow, numpy, and random module seeds based on the seed\n",
        "        specified in config. If there is no seed or it is None, a time-based\n",
        "        seed is used instead and is written to config.\n",
        "        \"\"\"\n",
        "\n",
        "        seed = self.config_experiment.get(\"seed\")\n",
        "\n",
        "        # Default uses current time in milliseconds, modulo 1e9\n",
        "        if seed is None:\n",
        "            seed = round(time() * 1000) % int(1e9)\n",
        "            self.config_experiment[\"seed\"] = seed\n",
        "\n",
        "        # Shift the seed based on task name\n",
        "        # This ensures a specified seed doesn't have similarities across different task names\n",
        "        task_name = Program.task.name\n",
        "        shifted_seed = seed + zlib.adler32(task_name.encode(\"utf-8\"))\n",
        "\n",
        "        # Set the seeds using the shifted seed\n",
        "        tf.set_random_seed(shifted_seed)\n",
        "        np.random.seed(shifted_seed)\n",
        "        random.seed(shifted_seed)\n",
        "\n",
        "    def make_prior(self):\n",
        "        prior = make_prior(Program.library, self.config_prior)\n",
        "        return prior\n",
        "\n",
        "    def make_state_manager(self):\n",
        "        state_manager = make_state_manager(self.config_state_manager)\n",
        "        return state_manager\n",
        "\n",
        "    def make_trainer(self):\n",
        "        trainer = Trainer(self.sess,\n",
        "                          self.policy,\n",
        "                          self.policy_optimizer,\n",
        "                          self.gp_controller,\n",
        "                          self.logger,\n",
        "                          self.pool,\n",
        "                          **self.config_training)\n",
        "        return trainer\n",
        "\n",
        "    def make_logger(self):\n",
        "        logger = StatsLogger(self.sess,\n",
        "                             self.output_file,\n",
        "                             **self.config_logger)\n",
        "        return logger\n",
        "\n",
        "    def make_checkpoint(self):\n",
        "        checkpoint = Checkpoint(self,\n",
        "                                **self.config_checkpoint)\n",
        "        return checkpoint\n",
        "\n",
        "    def make_policy_optimizer(self):\n",
        "        policy_optimizer = make_policy_optimizer(self.sess,\n",
        "                                                 self.policy,\n",
        "                                                 **self.config_policy_optimizer)\n",
        "        return policy_optimizer\n",
        "\n",
        "    def make_policy(self):\n",
        "        policy = make_policy(self.sess,\n",
        "                             self.prior,\n",
        "                             self.state_manager,\n",
        "                             **self.config_policy)\n",
        "        return policy\n",
        "\n",
        "    def make_gp_controller(self):\n",
        "        if self.config_gp_meld.pop(\"run_gp_meld\", False):\n",
        "            from dso.gp.gp_controller import GPController\n",
        "            gp_controller = GPController(self.prior,\n",
        "                                         self.config_prior,\n",
        "                                         **self.config_gp_meld)\n",
        "        else:\n",
        "            gp_controller = None\n",
        "        return gp_controller\n",
        "\n",
        "    def make_pool_and_set_task(self):\n",
        "        # Create the pool and set the Task for each worker\n",
        "\n",
        "        # Set complexity and const optimizer here so pool can access them\n",
        "        # Set the complexity function\n",
        "        complexity = self.config_training[\"complexity\"]\n",
        "        Program.set_complexity(complexity)\n",
        "\n",
        "        # Set the constant optimizer\n",
        "        const_optimizer = self.config_training[\"const_optimizer\"]\n",
        "        const_params = self.config_training[\"const_params\"]\n",
        "        const_params = const_params if const_params is not None else {}\n",
        "        Program.set_const_optimizer(const_optimizer, **const_params)\n",
        "\n",
        "        pool = None\n",
        "        n_cores_batch = self.config_training.get(\"n_cores_batch\")\n",
        "        if n_cores_batch is not None:\n",
        "            if n_cores_batch == -1:\n",
        "                n_cores_batch = cpu_count()\n",
        "            if n_cores_batch > 1:\n",
        "                pool = Pool(n_cores_batch,\n",
        "                            initializer=set_task,\n",
        "                            initargs=(self.config_task,))\n",
        "\n",
        "        # Set the Task for the parent process\n",
        "        set_task(self.config_task)\n",
        "\n",
        "        return pool\n",
        "\n",
        "    def make_output_file(self):\n",
        "        \"\"\"Generates an output filename\"\"\"\n",
        "\n",
        "        # If logdir is not provided (e.g. for pytest), results are not saved\n",
        "        if self.config_experiment.get(\"logdir\") is None:\n",
        "            self.save_path = None\n",
        "            print(\"WARNING: logdir not provided. Results will not be saved to file.\")\n",
        "            return None\n",
        "\n",
        "        # When using run.py, timestamp is already generated\n",
        "        timestamp = self.config_experiment.get(\"timestamp\")\n",
        "        if timestamp is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "            self.config_experiment[\"timestamp\"] = timestamp\n",
        "\n",
        "        # Generate save path\n",
        "        task_name = Program.task.name\n",
        "        if self.config_experiment[\"exp_name\"] is None:\n",
        "            save_path = os.path.join(\n",
        "                self.config_experiment[\"logdir\"],\n",
        "                '_'.join([task_name, timestamp]))\n",
        "        else:\n",
        "            save_path = os.path.join(\n",
        "                self.config_experiment[\"logdir\"],\n",
        "                self.config_experiment[\"exp_name\"])\n",
        "\n",
        "        self.config_experiment[\"task_name\"] = task_name\n",
        "        self.config_experiment[\"save_path\"] = save_path\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        seed = self.config_experiment[\"seed\"]\n",
        "        output_file = os.path.join(save_path,\n",
        "                                   \"dso_{}_{}.csv\".format(task_name, seed))\n",
        "\n",
        "        self.save_path = save_path\n",
        "\n",
        "        return output_file\n",
        "\n",
        "    def save(self, save_path=None):\n",
        "        self.checkpoint.save(save_path)\n",
        "\n",
        "    def load(self, load_path):\n",
        "        self.checkpoint.load(load_path)\n",
        "\n",
        "# Configuration for DSO\n",
        "config = {\n",
        "    \"experiment\": {\n",
        "        \"seed\": 42,\n",
        "        \"save_path\": \"/mnt/data/your_save_directory\",\n",
        "        \"exp_name\": \"DSO_Example\",\n",
        "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "    },\n",
        "    \"task\": {\n",
        "        \"task_type\": \"regression\",\n",
        "        \"dataset\": \"/content/train_feature.csv\",\n",
        "        \"validation_dataset\": \"/content/validation_feature.csv\",\n",
        "        \"function_set\": [\"add\", \"sub\", \"mul\", \"div\", \"sin\", \"cos\", \"exp\", \"log\"],\n",
        "        \"metric\": \"inv_nrmse\",\n",
        "        \"metric_params\": [1.0],\n",
        "        \"threshold\": 1e-12,\n",
        "        \"protected\": False,\n",
        "        \"reward_noise\": 0.0,\n",
        "        \"reward_noise_type\": \"r\",\n",
        "        \"normalize_variance\": False\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"n_samples\": 2000000,\n",
        "        \"batch_size\": 1000,\n",
        "        \"epsilon\": 0.05,\n",
        "        \"n_cores_batch\": 1\n",
        "    },\n",
        "    \"policy_optimizer\": {\n",
        "        \"learning_rate\": 0.0005,\n",
        "        \"entropy_weight\": 0.03,\n",
        "        \"entropy_gamma\": 0.7\n",
        "    },\n",
        "    \"prior\": {\n",
        "        \"length\": {\"min_\": 4, \"max_\": 64, \"on\": True},\n",
        "        \"repeat\": {\"tokens\": \"const\", \"max_\": 3, \"on\": True},\n",
        "        \"inverse\": {\"on\": True},\n",
        "        \"trig\": {\"on\": True},\n",
        "        \"const\": {\"on\": True},\n",
        "        \"no_inputs\": {\"on\": True},\n",
        "        \"uniform_arity\": {\"on\": True},\n",
        "        \"soft_length\": {\"loc\": 10, \"scale\": 5, \"on\": True},\n",
        "        \"domain_range\": {\"on\": False}\n",
        "    }\n",
        "    \"rnn\": {\n",
        "        \"vocabulary_size\": 10000,\n",
        "        \"embedding_size\": 300,\n",
        "        \"num_layers\": 2,\n",
        "        \"num_hidden\": 128,\n",
        "        \"mode\": 'train'\n",
        "    }\n",
        "}\n",
        "\n",
        "def main():\n",
        "    # Data loading logic\n",
        "    train_features = pd.read_csv(\"/mnt/data/train_feature.csv\").values\n",
        "    train_labels = pd.read_csv(\"/mnt/data/train_label.csv\").values\n",
        "\n",
        "    # Instantiate the RNN model\n",
        "    rnn_model = LanguageModel(**config[\"rnn\"])\n",
        "\n",
        "    # Create the task instance\n",
        "    if config[\"task\"][\"task_type\"] == \"regression\":\n",
        "        task = RegressionTask(rnn_model, (train_features, train_labels))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported task type\")\n",
        "\n",
        "    # Initialize the controller and optimizer\n",
        "    optimizer_config = {}  # Placeholder for actual optimizer config\n",
        "    optimizer = DeepSymbolicOptimizer(config=optimizer_config)\n",
        "    optimizer.setup()  # Setup all components and dependencies\n",
        "\n",
        "    # Run the training process\n",
        "    result = optimizer.train()\n",
        "\n",
        "    # Output the results\n",
        "    print(\"Training completed with result:\", result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "S_qtf85jxEmA",
        "outputId": "3824b8fb-c881-4402-ff35-a5d3e26f4f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Task() takes no arguments",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-cbdc93c3fa7c>\u001b[0m in \u001b[0;36m<cell line: 641>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-cbdc93c3fa7c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0;31m# Initialize the task and controller with the config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mcontroller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRnnController\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepSymbolicOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Task() takes no arguments"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RNN, LSTM, Dropout, Dense\n",
        "from tensorflow.compat.v1.nn.rnn_cell import BasicRNNCell\n",
        "\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "po4xNlog4e2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==1.16  # This installs the last TensorFlow 1.x version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29fHbtMC97vA",
        "outputId": "4204a9b9-281f-4eac-d524-d9a9ff88bdef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.16 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.16\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#polyfit\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import linalg, optimize, stats\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from itertools import compress\n",
        "\n",
        "class PolyRegressorMixin:\n",
        "    \"\"\"\n",
        "    Defines auxiliary functions to be used by DSO's specialized regressors\n",
        "    \"\"\"\n",
        "    def np_array_signature(self, X):\n",
        "        \"\"\"\n",
        "        Computes simplified hash of matrix X (m rows, n columns, m > n) for polynomial fitting purposes.\n",
        "        Parameters\n",
        "        ==========\n",
        "        X : ndarray\n",
        "            X data\n",
        "\n",
        "        Returns\n",
        "        =======\n",
        "        result : int\n",
        "            Simplified hash of X.\n",
        "        \"\"\"\n",
        "        return hash((X.shape,                                               # array shape\n",
        "                     X.diagonal().tobytes(),                                # main (top) diagonal\n",
        "                     X.diagonal(offset=X.shape[1]-X.shape[0]).tobytes()))   # lowest diagonal\n",
        "\n",
        "    def delete_oldest_pair(self, dictionary):\n",
        "        \"\"\"\n",
        "        Deletes oldest (key, value) pair from dictionary.\n",
        "        Takes advantage of ordered dictionaries in Python 3.6 and newer.\n",
        "        \"\"\"\n",
        "        dictionary.pop(next(iter(dictionary)))\n",
        "\n",
        "    def zero_out_ls_terms(self, cLS, XtX_inv, zero_out_indices):\n",
        "        \"\"\"\n",
        "        Fast recomputation of least-squares fit when zeroing-out terms in the regression\n",
        "        Solves:  [ XtX_inv   indexing^T ] [ c ] == [ Xt * y ]\n",
        "                 [ indexing      0      ] [ z ]    [    0   ]\n",
        "        which corresponds to the optimality conditions of:\n",
        "                max_c || X c - y || : indexing * c = 0\n",
        "        \"\"\"\n",
        "        # 1. form D = XtX_inv * indexing^T = (indexing * XtX_inv)^T = XtX_inv[indexing,:]^T\n",
        "        D = np.ascontiguousarray(XtX_inv[zero_out_indices,:].transpose())\n",
        "        # 2. form E = indexing * D = D[indexing,:]\n",
        "        E = D[zero_out_indices,:]\n",
        "        # NOTE: E is just a minor of XtX_inv, hence it is symmetric and positive definite\n",
        "        # 3. solve linear system E * z = cLS[indexing]\n",
        "        z = scipy.linalg.solve(E, cLS[zero_out_indices], assume_a=\"pos\")    # take advantage D is PD\n",
        "        # 4. compute solution with zero-ed out components and return\n",
        "        return cLS - np.matmul(D, z)\n",
        "\n",
        "    def regression_p_values(self, X, XtX_inv, y, c):\n",
        "        \"\"\"\n",
        "        Computes p-values using t-Test (null hyphotesis: c_i == 0)\n",
        "        \"\"\"\n",
        "        yhat = np.matmul(X, c)\n",
        "        df = len(X) - X.shape[1]\n",
        "        mse = sum((y - yhat)**2)/df\n",
        "        sd_err = np.sqrt(mse * XtX_inv.diagonal())\n",
        "        t_vals = c/sd_err\n",
        "        return 2 * (1 - stats.t.cdf(np.abs(t_vals), df))\n",
        "\n",
        "\n",
        "class DSOLeastSquaresData:\n",
        "    \"\"\"\n",
        "    Holds Gram inverse and pseudo-inverse\n",
        "    \"\"\"\n",
        "    def __init__(self, X, compute_inv=False):\n",
        "        if X.shape[0] < X.shape[1]:\n",
        "            raise AssertionError(\"X should have more rows than columns.\")\n",
        "        self.X_pinv = scipy.linalg.pinv(X)\n",
        "        if compute_inv:\n",
        "            XtX = np.matmul(X.transpose(), X)\n",
        "            if not np.isfinite(np.linalg.cond(XtX)):\n",
        "                raise AssertionError(\"X^t * X should always be invertible.\")\n",
        "            self.XtX_inv = scipy.linalg.inv(XtX)\n",
        "        else:\n",
        "            self.XtX_inv = None\n",
        "\n",
        "class DSOLeastSquaresRegressor(PolyRegressorMixin):\n",
        "    \"\"\"\n",
        "    Solve the problem min_{c} || X*c - y || by applying the psuedo-inverse\n",
        "            c = (X^T*X)^{-1} * X^T * y\n",
        "    \"\"\"\n",
        "    def __init__(self, cutoff_p_value=1.0, n_max_terms=None, coef_tol=1E-12):\n",
        "        # include intercept_ just to match with sklearn regressors\n",
        "        self.intercept_ = 0.0\n",
        "        self.coef_ = None\n",
        "        self.n_max_records = 10\n",
        "        self.data_dict = {}\n",
        "        if isinstance(cutoff_p_value, float) and \\\n",
        "           cutoff_p_value > 0.0 and cutoff_p_value <= 1.0:\n",
        "            self.cutoff_p_value_ = cutoff_p_value\n",
        "        else:\n",
        "            raise ValueError(\"cutoff p-value should be in (0., 1.]\")\n",
        "        if (isinstance(n_max_terms, int) and n_max_terms >= 2) or n_max_terms is None:\n",
        "           # 2 terms: constant + term\n",
        "            self.n_max_terms_ = n_max_terms\n",
        "        elif isinstance(n_max_terms, int):\n",
        "            raise ValueError(\"maximum number of terms should be >= 2\")\n",
        "        else:\n",
        "            raise TypeError(\"n_max_terms should be int or None\")\n",
        "        self.coef_tol_ = coef_tol\n",
        "\n",
        "    def fit(self, X, y, X_signature=None):\n",
        "        \"\"\"\n",
        "        Linear fit between X (data) and y (observations)\n",
        "        \"\"\"\n",
        "        # check if data is cached, if not add it to the data_dict\n",
        "        if X_signature is None:\n",
        "            X_signature = self.np_array_signature(X)\n",
        "        if X_signature not in self.data_dict.keys():\n",
        "            while len(self.data_dict) >= self.n_max_records:\n",
        "                self.delete_oldest_pair(self.data_dict)\n",
        "            self.data_dict[X_signature] = DSOLeastSquaresData(X, self.cutoff_p_value_ < 1.0 or\n",
        "                                                                 self.n_max_terms_ is not None)\n",
        "        # perform regression\n",
        "        lsd = self.data_dict[X_signature]\n",
        "        self.coef_ = np.matmul(lsd.X_pinv, y)\n",
        "        # if necessary, enforce p-value cutoff and maximum number of terms equal to zero\n",
        "        if self.cutoff_p_value_ < 1.0 or \\\n",
        "           (self.n_max_terms_ is not None and \\\n",
        "            np.count_nonzero(np.abs(self.coef_) > self.coef_tol_) > self.n_max_terms_):\n",
        "            # compute p-values for all coefficients\n",
        "            p_values = self.regression_p_values(X, lsd.XtX_inv, y, self.coef_)\n",
        "            # sort coefficients from smallets to largest p-value\n",
        "            perm = np.argsort(p_values)\n",
        "            # compute number of terms to keep\n",
        "            n_terms = next((x[0] for x in enumerate(perm) if p_values[x[1]] > self.cutoff_p_value_),\n",
        "                           len(p_values))\n",
        "            if self.n_max_terms_ is not None:\n",
        "                n_terms = np.minimum(n_terms, self.n_max_terms_)\n",
        "            # zero-out coefficients with largest p-values\n",
        "            if n_terms < len(self.coef_):\n",
        "                zero_out_indices = np.sort(perm[n_terms:])\n",
        "                self.coef_ = self.zero_out_ls_terms(self.coef_, lsd.XtX_inv, zero_out_indices)\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"\n",
        "        Reset memory allocated to pseudo-inverses\n",
        "        \"\"\"\n",
        "        self.data_dict.clear()\n",
        "\n",
        "\n",
        "class DSOLassoRegressorData:\n",
        "    \"\"\"\n",
        "    Holds information useful for multiple calls to DSOLassoRegressor\n",
        "    \"\"\"\n",
        "    def __init__(self, X):\n",
        "        self.XtX_inv = scipy.linalg.inv(np.matmul(X.transpose(), X))\n",
        "        self.X_pinv = np.matmul(self.XtX_inv, X.transpose())\n",
        "        self.n_obs = X.shape[0]\n",
        "        self.n_params = X.shape[1]\n",
        "\n",
        "\n",
        "class DSOLassoRegressor(PolyRegressorMixin):\n",
        "    \"\"\"\n",
        "    Computes Lasso for X, y with gamma weighted L1 regularization, i.e. finds optimum beta for\n",
        "        min_{beta} (1/2 * 1/var(y) * 1/n_obs * || y - X * beta ||^2_2 + gamma * 1/n_params * || beta ||_1)\n",
        "\n",
        "    Implementation solves dual Lasso problem.\n",
        "    \"\"\"\n",
        "    def __init__(self, gamma=0.1, comp_tol=1E-4, rtrn_constrnd_ls=True):\n",
        "        # include intercept_ just to match with sklearn regressors\n",
        "        self.intercept_ = 0.0\n",
        "        self.coef_ = None\n",
        "        self.gamma_ = gamma         # L1 weight -- standarized\n",
        "        self.comp_tol_ = comp_tol   # tolerance for complementarity slackness\n",
        "        self.rtrn_constrnd_ls_ = rtrn_constrnd_ls       # return re-optimized sparse least-squares\n",
        "        self.data_dict = {}\n",
        "        self.n_max_records = 10\n",
        "\n",
        "    def fit(self, X, y, X_signature=None):\n",
        "        # check if signature is provided, compute signature otherwise\n",
        "        if X_signature is None:\n",
        "            X_signature = self.np_array_signature(X)\n",
        "        # if signature does not appear in dict, compute and store lasso regressor data\n",
        "        if X_signature not in self.data_dict.keys():\n",
        "            while len(self.data_dict) >= self.n_max_records:\n",
        "                self.delete_oldest_pair(self.data_dict)\n",
        "            self.data_dict[X_signature] = DSOLassoRegressorData(X)\n",
        "        # perform lasso fit\n",
        "        ldata = self.data_dict[X_signature]\n",
        "        self.coef_ = self.dual_lasso(ldata.XtX_inv, ldata.X_pinv,\n",
        "                                     ldata.n_obs, ldata.n_params, y)\n",
        "\n",
        "    def dual_lasso(self, XtX_inv, X_pinv, n_obs, n_params, y):\n",
        "        # compute program parameters\n",
        "        beta_LS = np.matmul(X_pinv, y)  # least squares solution\n",
        "        rho_bnd = n_obs/n_params * np.var(y) * self.gamma_\n",
        "\n",
        "        # currently only scipy.minimize is supported as the solver\n",
        "        # objective function and derivatives\n",
        "        f_obj = lambda rho : 1/2 * np.dot(rho, np.matmul(XtX_inv, rho)) - np.dot(beta_LS, rho)\n",
        "        g_obj = lambda rho : np.matmul(XtX_inv, rho) - beta_LS\n",
        "        # define initial guess\n",
        "        rho_init = rho_bnd * np.ones(n_params)\n",
        "        rho_init[beta_LS > 0.0] *= -1.0\n",
        "        # call scipy minimize\n",
        "        bnds = scipy.optimize.Bounds(-rho_bnd * np.ones(n_params), rho_bnd * np.ones(n_params))\n",
        "        res = scipy.optimize.minimize(f_obj, rho_init, jac=g_obj, bounds=bnds)\n",
        "        if not res.success:\n",
        "            raise Exception(\"failed to solve dual lasso problem.\")\n",
        "        rho_opt = res.x\n",
        "\n",
        "        if self.rtrn_constrnd_ls_:\n",
        "            # determine indexes to zero-out\n",
        "            zero_out_indices = [i for i in range(n_params) if\n",
        "                                0.25 * (1 + rho_opt[i]/rho_bnd) * (1 - rho_opt[i]/rho_bnd) > self.comp_tol_]\n",
        "            # recompute least squares with zero-ed out coefficients\n",
        "            beta_cLS = self.zero_out_ls_terms(beta_LS, XtX_inv, zero_out_indices)\n",
        "            beta_cLS[zero_out_indices] = 0.0    # these will be zero up to floating point precision\n",
        "            return beta_cLS\n",
        "        else:\n",
        "            # compute lasso regressor parameters\n",
        "            beta_Lasso = beta_LS - np.matmul(XtX_inv, rho_opt)\n",
        "            # crash (dual) interior interior point solution\n",
        "            for i in range(n_params):\n",
        "                if 0.25 * (1 + rho_opt[i]/rho_bnd) * (1 - rho_opt[i]/rho_bnd) > self.comp_tol_:\n",
        "                    beta_Lasso[i] = 0.0\n",
        "            # return solution\n",
        "            return beta_Lasso\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"\n",
        "        Reset memory allocated to Gram inverse and pseudo inverse\n",
        "        \"\"\"\n",
        "        self.data_dict.clear()\n",
        "\n",
        "\n",
        "regressors = {\n",
        "        \"linear_regression\": LinearRegression,\n",
        "        \"lasso\": Lasso,\n",
        "        \"ridge\": Ridge,\n",
        "        \"dso_least_squares\" : DSOLeastSquaresRegressor,\n",
        "        \"dso_lasso\" : DSOLassoRegressor,\n",
        "    }\n",
        "\n",
        "inverse_function_map = {\n",
        "    \"add\" : np.subtract,\n",
        "    \"sub\" : np.add,\n",
        "    \"mul\" : np.divide,\n",
        "    \"div\" : np.multiply,\n",
        "    \"sin\" : np.arcsin,\n",
        "    \"cos\" : np.arccos,\n",
        "    \"tan\" : np.arctan,\n",
        "    \"exp\" : np.log,\n",
        "    \"log\" : np.exp,\n",
        "    \"sqrt\" : np.square,\n",
        "    \"n2\" : np.sqrt,\n",
        "    \"n3\" : np.cbrt,\n",
        "    \"abs\" : np.abs,\n",
        "    \"tanh\" : np.arctanh,\n",
        "    \"inv\" : np.reciprocal\n",
        "}\n",
        "\n",
        "\n",
        "def partial_execute(traversal, X):\n",
        "    \"\"\"\n",
        "    Evaluate from terminal nodes all the branches that has no 'poly' token.\n",
        "    If some (function) value in the partial execution is not finite, None is returned.\n",
        "    \"\"\"\n",
        "    apply_stack = []\n",
        "    for node in traversal:\n",
        "        apply_stack.append([node])\n",
        "        while len(apply_stack[-1]) == apply_stack[-1][0].arity + 1:\n",
        "            token = apply_stack[-1][0]\n",
        "            terminals = apply_stack[-1][1:]\n",
        "            if isinstance(token, Polynomial):\n",
        "                intermediate_result = \"poly\"\n",
        "            elif token.input_var is not None:\n",
        "                intermediate_result = X[:, token.input_var]\n",
        "            else:\n",
        "                if all(isinstance(t, np.ndarray) for t in terminals):\n",
        "                    if isinstance(token, StateChecker):\n",
        "                        token.set_state_value(X[:, token.state_index])\n",
        "                    intermediate_result = token(*terminals)\n",
        "\n",
        "                    if not np.isfinite(intermediate_result).all():\n",
        "                        return None\n",
        "                else:\n",
        "                    intermediate_result = [token, *terminals]\n",
        "\n",
        "            if len(apply_stack) != 1:\n",
        "                apply_stack.pop()\n",
        "                apply_stack[-1].append(intermediate_result)\n",
        "            else:\n",
        "                return intermediate_result\n",
        "\n",
        "\n",
        "def recursive_inversion(intermediate_result, y):\n",
        "    \"\"\"\n",
        "    Obtain the 'y data' for 'poly' token by inverting tokens starting from root.\n",
        "    For tokens of arity 2, find out the child that has been evaluated (there must be\n",
        "    one and only one), and get the value of the other child, until 'poly' is reached.\n",
        "\n",
        "    If some entry of y is not finite, None is returned.\n",
        "    \"\"\"\n",
        "    if not np.isfinite(y).all():\n",
        "        return None\n",
        "    if intermediate_result == \"poly\":\n",
        "        return y\n",
        "\n",
        "    assert len(intermediate_result) < 4\n",
        "    func = intermediate_result[0]\n",
        "    if func.arity == 1:\n",
        "        out = inverse_function_map[func.name](y)\n",
        "        return recursive_inversion(intermediate_result[1], out)\n",
        "    else:\n",
        "        if isinstance(intermediate_result[1], np.ndarray):\n",
        "            if func.name == \"sub\" or func.name == \"div\":\n",
        "                out = func(intermediate_result[1], y)\n",
        "            else:\n",
        "                out = inverse_function_map[func.name](y, intermediate_result[1])\n",
        "            return recursive_inversion(intermediate_result[2], out)\n",
        "        else:\n",
        "            out = inverse_function_map[func.name](y, intermediate_result[2])\n",
        "            return recursive_inversion(intermediate_result[1], out)\n",
        "\n",
        "\n",
        "def make_poly_data(traversal, X, y):\n",
        "    \"\"\"\n",
        "    Obtain the 'y data' for 'poly' token in two steps. First is a bottom-up pass of the\n",
        "    expression tree starting from terminal nodes, all the branches that can be evaluated\n",
        "    will be evaluated. Effectively this creates a single chain of unary functions with the\n",
        "    terminal token being the 'poly' token. The second step is a top-down pass inverting\n",
        "    all the unary functions in partial_results starting from the root.\n",
        "\n",
        "    If some (function) value in the partial execution or recursive inversion is not finite,\n",
        "    None is returned.\n",
        "    \"\"\"\n",
        "    partial_results = partial_execute(traversal, X)\n",
        "    return None if partial_results is None else recursive_inversion(partial_results, y)\n",
        "\n",
        "\n",
        "def nonnegative_int_tuples_to_sum(length, given_sum):\n",
        "    \"\"\"\n",
        "    generate all tuples of nonnegative integers that are of size length such that sum of entries equals given_sum\n",
        "    https://stackoverflow.com/questions/7748442/generate-all-possible-lists-of-length-n-that-sum-to-s-in-python\n",
        "    \"\"\"\n",
        "    if length == 1:\n",
        "        yield (given_sum,)\n",
        "    else:\n",
        "        for value in range(given_sum + 1):\n",
        "            for permutation in nonnegative_int_tuples_to_sum(length - 1, given_sum - value):\n",
        "                yield (value,) + permutation\n",
        "\n",
        "\n",
        "def generate_all_exponents(n_input_var, degree):\n",
        "    \"\"\"\n",
        "    Generate a list of tuples of exponents corresponding to all monomials of n_input_var\n",
        "    variables of degree at most degree.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for monomial_degree in range(degree + 1):\n",
        "        out.extend(list(nonnegative_int_tuples_to_sum(n_input_var, monomial_degree)))\n",
        "    return out\n",
        "\n",
        "\n",
        "class PolyOptimizerData(PolyRegressorMixin):\n",
        "    \"\"\"\n",
        "    Helper class to process and hold data passed to the polynomial optimizer\n",
        "    \"\"\"\n",
        "    def __init__(self, X, degree, X_signature_=None):\n",
        "        \"\"\"\n",
        "        Generate and store the data for all the monomials (basis for poly).\n",
        "        This allows dso to skip repeated generation of monomials' data for\n",
        "        the same X data during training.\n",
        "\n",
        "        Parameters\n",
        "        ==========\n",
        "        X : ndarray\n",
        "            X data\n",
        "        degree: int\n",
        "            The (maximal) degree of the polynomials used to fit the data.\n",
        "        \"\"\"\n",
        "        self.all_exponents = generate_all_exponents(X.shape[1], degree)\n",
        "        self.all_monomials_data = Polynomial.eval_monomials(X, self.all_exponents)\n",
        "        if X_signature_ is None:\n",
        "            self.X_signature = self.np_array_signature(X)\n",
        "        else:\n",
        "            self.X_signature = X_signature_\n",
        "\n",
        "\n",
        "class PolyOptimizer(PolyRegressorMixin):\n",
        "    def __init__(self, degree, coef_tol, regressor, regressor_params):\n",
        "        \"\"\"\n",
        "        Optimizer for fitting a polynomial in traversals to given datasets.\n",
        "\n",
        "        Parameters\n",
        "        ==========\n",
        "        degree : int\n",
        "            The (maximal) degree of the polynomials used to fit the data.\n",
        "\n",
        "        coef_tol : float\n",
        "            Cutoff value for the coefficients of polynomials. Coefficients\n",
        "            with magnitude less than this value will be regarded as 0.\n",
        "\n",
        "        regressor : str\n",
        "            Key to dictionary regressors. Supported options are 'lasso',\n",
        "            'ridge', and 'linear_regression'.\n",
        "\n",
        "        regressor_params : dict\n",
        "            Parameters for the regressor. See sklearn for more information.\n",
        "        \"\"\"\n",
        "        self.degree = degree\n",
        "        self.coef_tol = coef_tol\n",
        "        self.regressor = regressors[regressor](**regressor_params)\n",
        "        self.data_dict = dict()\n",
        "        self.n_max_records = 10\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit a polnomial to the dataset (X, y) based on the regressor.\n",
        "        Parameters\n",
        "        ==========\n",
        "        X : ndarray\n",
        "            X data\n",
        "        y : ndarray\n",
        "            y data\n",
        "\n",
        "        Returns\n",
        "        =======\n",
        "        result : Polynomial(Token)\n",
        "            The polynomial token of which the underlying polynomial best fits the dataset (X, y)\n",
        "        \"\"\"\n",
        "        X_signature = self.np_array_signature(X)\n",
        "        if X_signature not in self.data_dict.keys():\n",
        "            while len(self.data_dict) >= self.n_max_records:\n",
        "                self.delete_oldest_pair(self.data_dict)\n",
        "            self.data_dict[X_signature] = PolyOptimizerData(X, self.degree, X_signature)\n",
        "\n",
        "        # reference to PolyOptimizerData object (to avoid multiple lookups)\n",
        "        pod = self.data_dict[X_signature]\n",
        "\n",
        "        try:\n",
        "            # perform fit; pass monomial data signature if using custom DSO optimizers\n",
        "            if isinstance(self.regressor, (DSOLeastSquaresRegressor,)):\n",
        "                self.regressor.fit(pod.all_monomials_data, y, pod.X_signature)\n",
        "            else:\n",
        "                self.regressor.fit(pod.all_monomials_data, y)\n",
        "        except: # the only thing we have seen is ValueError\n",
        "            return Polynomial([(0,)*X.shape[1]], np.ones(1))\n",
        "\n",
        "        # Correct the coefficient of the constant term when regressor.intercept_ is nonzero.\n",
        "        # This can happen when fit_intercept in regressor_params is True.\n",
        "        if self.regressor.intercept_ != 0.0:\n",
        "            self.regressor.coef_[0] += self.regressor.intercept_\n",
        "\n",
        "        if np.isfinite(self.regressor.coef_).all():\n",
        "            mask = np.abs(self.regressor.coef_) >= self.coef_tol\n",
        "            if np.count_nonzero(mask) == 0:\n",
        "                # fit succesful, but all coefficients are zero\n",
        "                return Polynomial([(0,)*X.shape[1]], np.ones(0))\n",
        "            return Polynomial(list(compress(pod.all_exponents, mask)), self.regressor.coef_[mask])\n",
        "\n",
        "        return Polynomial([(0,)*X.shape[1]], np.ones(1))\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"\n",
        "        Reset memory allocated to exponents and monomials data, and to cached regressor data\n",
        "        \"\"\"\n",
        "        self.data_dict.clear()\n",
        "        if isinstance(self.regressor, (DSOLeastSquaresRegressor, DSOLassoRegressor)):\n",
        "            self.regressor.clear()\n",
        "\n",
        "\n",
        "\n",
        "class PolyGenerator(object):\n",
        "    def __init__(self, degree, n_input_var):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        degree : int\n",
        "            Maximal degree of the polynomials to be generated.\n",
        "        coef : int\n",
        "            Number of input (independent) variables.\n",
        "        \"\"\"\n",
        "        self.all_exponents = generate_all_exponents(n_input_var, degree)\n",
        "\n",
        "    def generate(self, n_terms_mean=2, n_terms_sd=1,\n",
        "                 coef_mean=0, coef_sd=10, coef_precision=2):\n",
        "        \"\"\"\n",
        "        Generate a Polynomial token. The number of terms and the coefficients of the\n",
        "        terms are sampled from normal distributions based on the input parameters.\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_terms_mean : int\n",
        "            Mean of the normal distribution from which number of terms is sampled.\n",
        "        n_terms_sd : int\n",
        "            Standard deviation of the normal distribution from which number of terms is sampled.\n",
        "        coef_mean : float\n",
        "            Mean of the normal distribution from which the coefficents are sampled.\n",
        "        coef_sd : float\n",
        "            Standard deviation of the normal distribution from which the coefficents are sampled.\n",
        "        coef_precision : int\n",
        "            Number of decimal places of the coefficients in the generated polynomial.\n",
        "\n",
        "        Returns\n",
        "        =======\n",
        "        result : Polynomial(Token)\n",
        "            The generated polynomial token\n",
        "        \"\"\"\n",
        "        n_terms = int(max(1, np.random.normal(n_terms_mean, n_terms_sd)))\n",
        "        n_terms = min(n_terms, len(self.all_exponents))\n",
        "        coefs = np.random.normal(coef_mean, coef_sd, n_terms)\n",
        "        coefs = np.around(coefs, decimals=coef_precision)\n",
        "        coef_pos = np.random.choice(len(self.all_exponents), n_terms, replace=False)\n",
        "        return Polynomial([self.all_exponents[pos] for pos in coef_pos], coefs)"
      ],
      "metadata": {
        "id": "adPOORz_Cob4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function\n",
        "\"\"\"Common Tokens used for executable Programs.\"\"\"\n",
        "import re\n",
        "import numpy as np\n",
        "from fractions import Fraction\n",
        "\n",
        "\n",
        "\n",
        "GAMMA = 0.57721566490153286060651209008240243104215933593992\n",
        "\n",
        "\n",
        "\"\"\"Define custom unprotected operators\"\"\"\n",
        "def logabs(x1):\n",
        "    \"\"\"Closure of log for non-positive arguments.\"\"\"\n",
        "    return np.log(np.abs(x1))\n",
        "\n",
        "def expneg(x1):\n",
        "    return np.exp(-x1)\n",
        "\n",
        "def n3(x1):\n",
        "    return np.power(x1, 3)\n",
        "\n",
        "def n4(x1):\n",
        "    return np.power(x1, 4)\n",
        "\n",
        "def sigmoid(x1):\n",
        "    return 1 / (1 + np.exp(-x1))\n",
        "\n",
        "def harmonic(x1):\n",
        "    if all(val.is_integer() for val in x1):\n",
        "        return np.array([sum(Fraction(1, d) for d in range(1, int(val)+1)) for val in x1], dtype=np.float32)\n",
        "    else:\n",
        "        return GAMMA + np.log(x1) + 0.5/x1 - 1./(12*x1**2) + 1./(120*x1**4)\n",
        "\n",
        "\n",
        "# Annotate unprotected ops\n",
        "unprotected_ops = [\n",
        "    # Binary operators\n",
        "    Token(np.add, \"add\", arity=2, complexity=1),\n",
        "    Token(np.subtract, \"sub\", arity=2, complexity=1),\n",
        "    Token(np.multiply, \"mul\", arity=2, complexity=1),\n",
        "    Token(np.divide, \"div\", arity=2, complexity=2),\n",
        "\n",
        "    # Built-in unary operators\n",
        "    Token(np.sin, \"sin\", arity=1, complexity=3),\n",
        "    Token(np.cos, \"cos\", arity=1, complexity=3),\n",
        "    Token(np.tan, \"tan\", arity=1, complexity=4),\n",
        "    Token(np.exp, \"exp\", arity=1, complexity=4),\n",
        "    Token(np.log, \"log\", arity=1, complexity=4),\n",
        "    Token(np.sqrt, \"sqrt\", arity=1, complexity=4),\n",
        "    Token(np.square, \"n2\", arity=1, complexity=2),\n",
        "    Token(np.negative, \"neg\", arity=1, complexity=1),\n",
        "    Token(np.abs, \"abs\", arity=1, complexity=2),\n",
        "    Token(np.maximum, \"max\", arity=1, complexity=4),\n",
        "    Token(np.minimum, \"min\", arity=1, complexity=4),\n",
        "    Token(np.tanh, \"tanh\", arity=1, complexity=4),\n",
        "    Token(np.reciprocal, \"inv\", arity=1, complexity=2),\n",
        "\n",
        "    # Custom unary operators\n",
        "    Token(logabs, \"logabs\", arity=1, complexity=4),\n",
        "    Token(expneg, \"expneg\", arity=1, complexity=4),\n",
        "    Token(n3, \"n3\", arity=1, complexity=3),\n",
        "    Token(n4, \"n4\", arity=1, complexity=3),\n",
        "    Token(sigmoid, \"sigmoid\", arity=1, complexity=4),\n",
        "    Token(harmonic, \"harmonic\", arity=1, complexity=4)\n",
        "]\n",
        "\n",
        "\n",
        "\"\"\"Define custom protected operators\"\"\"\n",
        "def protected_div(x1, x2):\n",
        "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
        "        return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n",
        "\n",
        "def protected_exp(x1):\n",
        "    with np.errstate(over='ignore'):\n",
        "        return np.where(x1 < 100, np.exp(x1), 0.0)\n",
        "\n",
        "def protected_log(x1):\n",
        "    \"\"\"Closure of log for non-positive arguments.\"\"\"\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        return np.where(np.abs(x1) > 0.001, np.log(np.abs(x1)), 0.)\n",
        "\n",
        "def protected_sqrt(x1):\n",
        "    \"\"\"Closure of sqrt for negative arguments.\"\"\"\n",
        "    return np.sqrt(np.abs(x1))\n",
        "\n",
        "def protected_inv(x1):\n",
        "    \"\"\"Closure of inverse for zero arguments.\"\"\"\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        return np.where(np.abs(x1) > 0.001, 1. / x1, 0.)\n",
        "\n",
        "def protected_expneg(x1):\n",
        "    with np.errstate(over='ignore'):\n",
        "        return np.where(x1 > -100, np.exp(-x1), 0.0)\n",
        "\n",
        "def protected_n2(x1):\n",
        "    with np.errstate(over='ignore'):\n",
        "        return np.where(np.abs(x1) < 1e6, np.square(x1), 0.0)\n",
        "\n",
        "def protected_n3(x1):\n",
        "    with np.errstate(over='ignore'):\n",
        "        return np.where(np.abs(x1) < 1e6, np.power(x1, 3), 0.0)\n",
        "\n",
        "def protected_n4(x1):\n",
        "    with np.errstate(over='ignore'):\n",
        "        return np.where(np.abs(x1) < 1e6, np.power(x1, 4), 0.0)\n",
        "\n",
        "def protected_sigmoid(x1):\n",
        "    return 1 / (1 + protected_expneg(x1))\n",
        "\n",
        "# Annotate protected ops\n",
        "protected_ops = [\n",
        "    # Protected binary operators\n",
        "    Token(protected_div, \"div\", arity=2, complexity=2),\n",
        "\n",
        "    # Protected unary operators\n",
        "    Token(protected_exp, \"exp\", arity=1, complexity=4),\n",
        "    Token(protected_log, \"log\", arity=1, complexity=4),\n",
        "    Token(protected_log, \"logabs\", arity=1, complexity=4), # Protected logabs is support, but redundant\n",
        "    Token(protected_sqrt, \"sqrt\", arity=1, complexity=4),\n",
        "    Token(protected_inv, \"inv\", arity=1, complexity=2),\n",
        "    Token(protected_expneg, \"expneg\", arity=1, complexity=4),\n",
        "    Token(protected_n2, \"n2\", arity=1, complexity=2),\n",
        "    Token(protected_n3, \"n3\", arity=1, complexity=3),\n",
        "    Token(protected_n4, \"n4\", arity=1, complexity=3),\n",
        "    Token(protected_sigmoid, \"sigmoid\", arity=1, complexity=4)\n",
        "]\n",
        "\n",
        "# Add unprotected ops to function map\n",
        "function_map = {\n",
        "    op.name : op for op in unprotected_ops\n",
        "    }\n",
        "\n",
        "# Add protected ops to function map\n",
        "function_map.update({\n",
        "    \"protected_{}\".format(op.name) : op for op in protected_ops\n",
        "    })\n",
        "\n",
        "TERMINAL_TOKENS = set([op.name for op in function_map.values() if op.arity == 0])\n",
        "UNARY_TOKENS    = set([op.name for op in function_map.values() if op.arity == 1])\n",
        "BINARY_TOKENS   = set([op.name for op in function_map.values() if op.arity == 2])\n",
        "\n",
        "\n",
        "def create_state_checkers(n_states, threshold_set):\n",
        "    \"\"\"\n",
        "    Helper function to create StateChecker Tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_states : int\n",
        "        Number of state variables.\n",
        "\n",
        "    threshold_set : list or list of lists\n",
        "        A list of constants [t1, t2, ..., tn] for constructing StateChecker (si < tj),\n",
        "        or a list of lists of constants [[t11, t12, t1n], [t21, t22, ..., t2m], ...].\n",
        "        In the latter case, the i-th list contains the thresholds for state variable si for\n",
        "        constructing StateChecker (si < tij). The sizes of the threshold lists can be different.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    if isinstance(threshold_set[0], list):\n",
        "        assert len(threshold_set) == n_states, \\\n",
        "            \"If threshold_set is a list of lists, its length must equal n_states.\"\n",
        "    else:\n",
        "        threshold_set = [threshold_set]*n_states\n",
        "\n",
        "    for i, thresholds in enumerate(threshold_set):\n",
        "        assert all([U.is_float(t) for t in thresholds]), \\\n",
        "            \"threshold_set must contain only real constant numbers.\"\n",
        "        tokens.extend([StateChecker(i, t) for t in thresholds])\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def create_tokens(n_input_var, function_set, protected, decision_tree_threshold_set=None):\n",
        "    \"\"\"\n",
        "    Helper function to create Tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_input_var : int\n",
        "        Number of input variable Tokens.\n",
        "\n",
        "    function_set : list\n",
        "        Names of registered Tokens, or floats that will create new Tokens.\n",
        "\n",
        "    protected : bool\n",
        "        Whether to use protected versions of registered Tokens.\n",
        "\n",
        "    decision_tree_threshold_set : list or list of lists\n",
        "        A list of constants [t1, t2, ..., tn] for constructing nodes (xi < tj) in decision trees,\n",
        "        or a list of lists of constants [[t11, t12, t1n], [t21, t22, ..., t2m], ...].\n",
        "        In the latter case, the i-th list contains the thresholds for input variable xi for constructing\n",
        "        nodes (xi < tij) in decision trees. The sizes of the threshold lists can be different.\n",
        "    \"\"\"\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    # Create input variable Tokens\n",
        "    for i in range(n_input_var):\n",
        "        token = Token(name=\"x{}\".format(i + 1), arity=0, complexity=1,\n",
        "                      function=None, input_var=i)\n",
        "        tokens.append(token)\n",
        "\n",
        "    for op in function_set:\n",
        "\n",
        "        # Registered Token\n",
        "        if op in function_map:\n",
        "            # Overwrite available protected operators\n",
        "            if protected and not op.startswith(\"protected_\"):\n",
        "                protected_op = \"protected_{}\".format(op)\n",
        "                if protected_op in function_map:\n",
        "                    op = protected_op\n",
        "\n",
        "            token = function_map[op]\n",
        "\n",
        "        # Hard-coded floating-point constant\n",
        "        elif U.is_float(op):\n",
        "            token = HardCodedConstant(op)\n",
        "\n",
        "        # Constant placeholder (to-be-optimized)\n",
        "        elif op == \"const\":\n",
        "            token = PlaceholderConstant()\n",
        "\n",
        "        elif op == \"poly\":\n",
        "            token = Polynomial()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Operation {} not recognized.\".format(op))\n",
        "\n",
        "        tokens.append(token)\n",
        "\n",
        "    if decision_tree_threshold_set is not None and len(decision_tree_threshold_set) > 0:\n",
        "        state_checkers = create_state_checkers(n_input_var, decision_tree_threshold_set)\n",
        "        tokens.extend(state_checkers)\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "i4m6jFqgDp6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        " # Assuming you have this\n",
        "\n",
        "class BenchmarkDataset:\n",
        "    def __init__(self, name, benchmark_source=\"benchmarks.csv\", root=None, noise=0.0, seed=0):\n",
        "        self.name = name\n",
        "        self.seed = seed\n",
        "        self.noise = noise\n",
        "\n",
        "        # Load benchmark data (adjust if your setup is different)\n",
        "        if root is None:\n",
        "            root = \"/content/benchmarks.csv\"  # Replace with the correct path\n",
        "        benchmark_path = os.path.join(root, benchmark_source)\n",
        "        self.benchmark_df = pd.read_csv(benchmark_path)\n",
        "        self.row = self.benchmark_df.loc[name]\n",
        "\n",
        "        # Create symbolic expression and extract specifications\n",
        "        self.numpy_expr = self.make_numpy_expr(self.row[\"expression\"])\n",
        "        self.specs = self.extract_dataset_specs(self.row[\"train_spec\"])\n",
        "\n",
        "        # Generate X and y, add noise\n",
        "        self.X, self.y = self.build_dataset(self.specs)\n",
        "        if self.noise > 0:\n",
        "            scale = self.noise * np.std(self.y)\n",
        "            self.y += np.random.normal(loc=0, scale=scale, size=self.y.shape)\n",
        "\n",
        "    def extract_dataset_specs(self, specs):\n",
        "        specs = ast.literal_eval(specs)\n",
        "        if specs is not None:\n",
        "            specs['distribution'] = list(list(specs.items())[0][1].items())[0][0]\n",
        "            if specs['distribution'] == \"E\":\n",
        "                lower = list(list(specs.items())[0][1].items())[0][1][0]\n",
        "                upper = list(list(specs.items())[0][1].items())[0][1][1]\n",
        "                distance = upper - lower\n",
        "                specs['dataset_size'] = int(distance / list(list(specs.items())[0][1].items())[0][1][2]) + 1\n",
        "            else:\n",
        "                specs['dataset_size'] = list(list(specs.items())[0][1].items())[0][1][2]\n",
        "        return specs\n",
        "\n",
        "    def build_dataset(self, specs):\n",
        "        rng = np.random.RandomState(self.seed)\n",
        "        X = self.make_X(specs, specs['dataset_size'], rng)\n",
        "        y = self.numpy_expr(X)\n",
        "        return X, y\n",
        "\n",
        "    def make_X(self, specs, size, rng):\n",
        "        features = []\n",
        "        for i in range(1, self.row[\"variables\"] + 1):\n",
        "            if \"U\" in specs[\"x{}\".format(i)]:\n",
        "                low, high = specs[\"x{}\".format(i)][\"U\"]\n",
        "                features.append(rng.uniform(low=low, high=high, size=size))\n",
        "            else:\n",
        "                # Handle other distributions if needed\n",
        "                pass\n",
        "        return np.column_stack(features)\n",
        "\n",
        "    def make_numpy_expr(self, s):\n",
        "        \"\"\"This isn't pretty, but unlike sympy's lambdify, this ensures we use\n",
        "        our protected functions. Otherwise, some expressions may have large\n",
        "        error even if the functional form is correct due to the training set\n",
        "        not using protected functions.\"\"\"\n",
        "        # Replace function names\n",
        "        s = s.replace(\"ln(\", \"log(\")\n",
        "        s = s.replace(\"pi\", \"np.pi\")\n",
        "        s = s.replace(\"pow\", \"np.power\")\n",
        "        for k in function_map.keys():\n",
        "            s = s.replace(k + '(', \"function_map['{}'].function(\".format(k))\n",
        "        # Replace variable names\n",
        "        for i in reversed(range(self.n_input_var)):\n",
        "            old = \"x{}\".format(i+1)\n",
        "            new = \"x[:, {}]\".format(i)\n",
        "            s = s.replace(old, new)\n",
        "        #Return numpy expression\n",
        "        return lambda x : eval(s)\n",
        "\n"
      ],
      "metadata": {
        "id": "mGsCloB0FNsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BenchmarkDataset(object):\n",
        "    \"\"\"\n",
        "    Class used to generate (X, y) data from a named benchmark expression.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name : str\n",
        "        Name of benchmark expression.\n",
        "\n",
        "    benchmark_source : str, optional\n",
        "        Filename of CSV describing benchmark expressions.\n",
        "\n",
        "    root : str, optional\n",
        "        Directory containing benchmark_source and function_sets.csv.\n",
        "\n",
        "    noise : float, optional\n",
        "        If not None, Gaussian noise is added to the y values with standard\n",
        "        deviation = noise * RMS of the noiseless y training values.\n",
        "\n",
        "    seed : int, optional\n",
        "        Random number seed used to generate data. Checksum on name is added to\n",
        "        seed.\n",
        "\n",
        "    logdir : str, optional\n",
        "        Directory where experiment logfiles are saved.\n",
        "\n",
        "    backup : bool, optional\n",
        "        Save generated dataset in logdir if logdir is provided.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name, benchmark_source=\"benchmarks.csv\", root=None, noise=0.0,\n",
        "                 seed=0, logdir=None, backup=False):\n",
        "        # Set class variables\n",
        "        self.name = name\n",
        "        self.seed = seed\n",
        "        self.noise = noise if noise is not None else 0.0\n",
        "\n",
        "        # Set random number generator used for sampling X values\n",
        "        seed += zlib.adler32(name.encode(\"utf-8\")) # Different seed for each name, otherwise two benchmarks with the same domain will always have the same X values\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "\n",
        "        # Load benchmark data\n",
        "        if root is None:\n",
        "            root = resource_filename(\"dso.task\", \"regression\")\n",
        "        benchmark_path = os.path.join(root, benchmark_source)\n",
        "        benchmark_df = pd.read_csv(benchmark_path, index_col=0, encoding=\"ISO-8859-1\")\n",
        "        row = benchmark_df.loc[name]\n",
        "        self.n_input_var = row[\"variables\"]\n",
        "\n",
        "        # Create symbolic expression\n",
        "        self.numpy_expr = self.make_numpy_expr(row[\"expression\"])\n",
        "\n",
        "        # Get dataset specifications\n",
        "        self.train_spec = self.extract_dataset_specs(row[\"train_spec\"])\n",
        "        self.test_spec = self.extract_dataset_specs(row[\"test_spec\"])\n",
        "        if self.test_spec is None:\n",
        "            self.test_spec = self.train_spec\n",
        "\n",
        "        # Create X, y values - Train set\n",
        "        self.X_train, self.y_train = self.build_dataset(self.train_spec)\n",
        "        self.y_train_noiseless = self.y_train.copy()\n",
        "\n",
        "        # Create X, y values - Test set\n",
        "        self.X_test, self.y_test = self.build_dataset(self.test_spec)\n",
        "        self.y_test_noiseless = self.y_test.copy()\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        if self.noise > 0:\n",
        "            y_rms = np.sqrt(np.mean(self.y_train**2))\n",
        "            scale = self.noise * y_rms\n",
        "            self.y_train += self.rng.normal(loc=0, scale=scale, size=self.y_train.shape)\n",
        "            self.y_test += self.rng.normal(loc=0, scale=scale, size=self.y_test.shape)\n",
        "        elif self.noise < 0:\n",
        "            print('WARNING: Ignoring negative noise value: {}'.format(self.noise))\n",
        "\n",
        "        # Load default function set\n",
        "        function_set_path = os.path.join(root, \"function_sets.csv\")\n",
        "        function_set_df = pd.read_csv(function_set_path, index_col=0)\n",
        "        function_set_name = row[\"function_set\"]\n",
        "        self.function_set = function_set_df.loc[function_set_name].tolist()[0].strip().split(',')\n",
        "\n",
        "        # Prepare status output\n",
        "        output_message = '\\n-- BUILDING DATASET START -----------\\n'\n",
        "        output_message += 'Generated data for benchmark   : {}\\n'.format(name)\n",
        "        output_message += 'Benchmark path                 : {}\\n'.format(benchmark_path)\n",
        "        output_message += 'Function set                   : {} --> {}\\n'.format(function_set_name, self.function_set)\n",
        "        output_message += 'Function set path              : {}\\n'.format(function_set_path)\n",
        "        test_spec_txt = row[\"test_spec\"] if row[\"test_spec\"] != \"None\" else \"{} (Copy from train!)\".format(row[\"test_spec\"])\n",
        "        output_message += 'Dataset specifications         : \\n' \\\n",
        "                          + '        Train --> {}\\n'.format(row[\"train_spec\"]) \\\n",
        "                          + '        Test  --> {}\\n'.format(test_spec_txt)\n",
        "        random_choice_train = self.rng.randint(self.X_train.shape[0])\n",
        "        random_sample_train = \"[{}],[{}]\".format(self.X_train[random_choice_train], self.y_train[random_choice_train])\n",
        "        output_message += 'Built data set                 : \\n' \\\n",
        "                          + '        Train --> X:{}, y:{}, Sample: {}\\n'.format(self.X_train.shape, self.y_train.shape, random_sample_train)\n",
        "        if row[\"test_spec\"] is not None:\n",
        "            random_choice_test = self.rng.randint(self.X_test.shape[0])\n",
        "            random_sample_test = \"[{}],[{}]\".format(self.X_test[random_choice_test], self.y_test[random_choice_test])\n",
        "            output_message += '        Test  --> X:{}, y:{}, Sample: {}\\n'.format(self.X_test.shape, self.y_test.shape, random_sample_test)\n",
        "        if backup and logdir is not None:\n",
        "            output_message += self.save(logdir)\n",
        "        output_message += '-- BUILDING DATASET END -------------\\n'\n",
        "        print(output_message)\n",
        "\n",
        "    def extract_dataset_specs(self, specs):\n",
        "        specs = ast.literal_eval(specs)\n",
        "        if specs is not None:\n",
        "            specs['distribution'] = list(list(specs.items())[0][1].items())[0][0]\n",
        "            if specs['distribution'] == \"E\":\n",
        "                lower = list(list(specs.items())[0][1].items())[0][1][0]\n",
        "                upper = list(list(specs.items())[0][1].items())[0][1][1]\n",
        "                distance = upper - lower\n",
        "                specs['dataset_size'] = int(distance / list(list(specs.items())[0][1].items())[0][1][2]) + 1\n",
        "            else:\n",
        "                specs['dataset_size'] = list(list(specs.items())[0][1].items())[0][1][2]\n",
        "        return specs\n",
        "\n",
        "    def build_dataset(self, specs, max_iterations=1000, max_repeated_empty=100):\n",
        "        \"\"\"This function generates an (X,y) dataset by randomly sampling X\n",
        "        values in a given range and calculating the corresponding y values.\n",
        "        During generation it is checked that the generated datapoints are\n",
        "        valid within the given range, removing nan and inf values. The\n",
        "        generated dataset will be filled up to the desired dataset size or\n",
        "        the function terminates with an error.\"\"\"\n",
        "        current_size = 0\n",
        "        X_tmp = None\n",
        "        count_repeated_empty = 0\n",
        "        count_iterations = 0\n",
        "        while(current_size < specs[\"dataset_size\"]):\n",
        "            if count_iterations > max_iterations:\n",
        "                assert False, \"Dataset creation taking too long. Got {} from {}\".format(X_tmp.shape, specs)\n",
        "            missing_value_count = specs[\"dataset_size\"] - current_size\n",
        "            # Get all X values\n",
        "            X = self.make_X(specs, missing_value_count)\n",
        "            assert X.ndim == 2, \"Dataset X has wrong dimension: {} != 2\".format(X.ndim)\n",
        "            # Calculate y values\n",
        "            y = self.numpy_expr(X)\n",
        "            # Sanity check\n",
        "            X, y = self.remove_invalid(X, y)\n",
        "            if y.shape[0] == 0:\n",
        "                count_repeated_empty += 1\n",
        "                if count_repeated_empty > max_repeated_empty:\n",
        "                    assert False, \"Dataset cannot be created in the given range: {}\".format(specs)\n",
        "            # Put old and new data together if available\n",
        "            if not X_tmp is None:\n",
        "                X = np.append(X, X_tmp, axis=0)\n",
        "                y = np.append(y, y_tmp, axis=0)\n",
        "            current_size = X.shape[0]\n",
        "            # Handle \"E\" distributions\n",
        "            if X.shape[0] != specs[\"dataset_size\"] and specs['distribution'] == \"E\":\n",
        "                assert False, \"Equal distant data points cannot be created in the given range: {}\".format(specs)\n",
        "            X_tmp = X\n",
        "            y_tmp = y\n",
        "            count_iterations +=1\n",
        "        assert X.shape[0] == specs[\"dataset_size\"]\n",
        "        return X, y\n",
        "\n",
        "    def remove_invalid(self, X, y, y_limit=100):\n",
        "        \"\"\"Removes nan, infs, and out of range datapoints from a dataset.\"\"\"\n",
        "        valid = np.logical_and(y > -y_limit, y < y_limit)\n",
        "        y = y[valid]\n",
        "        X = X[valid]\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "        return X, y\n",
        "\n",
        "    def make_X(self, spec, size):\n",
        "        \"\"\"Creates X values based on provided specification.\"\"\"\n",
        "\n",
        "        features = []\n",
        "        for i in range(1, self.n_input_var + 1):\n",
        "\n",
        "            # Hierarchy: \"all\" --> \"x{}\".format(i)\n",
        "            input_var = \"x{}\".format(i)\n",
        "            if \"all\" in spec:\n",
        "                input_var = \"all\"\n",
        "            elif input_var not in spec:\n",
        "                input_var = \"x1\"\n",
        "\n",
        "            if \"U\" in spec[input_var]:\n",
        "                low, high, n = spec[input_var][\"U\"]\n",
        "                feature = self.rng.uniform(low=low, high=high, size=size)\n",
        "            elif \"E\" in spec[input_var]:\n",
        "                start, stop, step = spec[input_var][\"E\"]\n",
        "                if step > stop - start:\n",
        "                    n = step\n",
        "                else:\n",
        "                    n = int((stop - start)/step) + 1\n",
        "                feature = np.linspace(start=start, stop=stop, num=n, endpoint=True)\n",
        "            else:\n",
        "                raise ValueError(\"Did not recognize specification for {}: {}.\".format(input_var, spec[input_var]))\n",
        "            features.append(feature)\n",
        "\n",
        "        # Do multivariable combinations\n",
        "        if \"E\" in spec[input_var] and self.n_input_var > 1:\n",
        "            X = np.array(list(itertools.product(*features)))\n",
        "        else:\n",
        "            X = np.column_stack(features)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def make_numpy_expr(self, s):\n",
        "        \"\"\"This isn't pretty, but unlike sympy's lambdify, this ensures we use\n",
        "        our protected functions. Otherwise, some expressions may have large\n",
        "        error even if the functional form is correct due to the training set\n",
        "        not using protected functions.\"\"\"\n",
        "        # Replace function names\n",
        "        s = s.replace(\"ln(\", \"log(\")\n",
        "        s = s.replace(\"pi\", \"np.pi\")\n",
        "        s = s.replace(\"pow\", \"np.power\")\n",
        "        for k in function_map.keys():\n",
        "            s = s.replace(k + '(', \"function_map['{}'].function(\".format(k))\n",
        "        # Replace variable names\n",
        "        for i in reversed(range(self.n_input_var)):\n",
        "            old = \"x{}\".format(i+1)\n",
        "            new = \"x[:, {}]\".format(i)\n",
        "            s = s.replace(old, new)\n",
        "        #Return numpy expression\n",
        "        return lambda x : eval(s)\n",
        "\n",
        "    def save(self, logdir='./'):\n",
        "        \"\"\"Saves the dataset to a specified location.\"\"\"\n",
        "        save_path = os.path.join(logdir,'data_{}_n{:.2f}_s{}.csv'.format(\n",
        "                self.name, self.noise, self.seed))\n",
        "        try:\n",
        "            os.makedirs(logdir, exist_ok=True)\n",
        "            np.savetxt(\n",
        "                save_path,\n",
        "                np.concatenate(\n",
        "                    (\n",
        "                        np.hstack((self.X_train, self.y_train[..., np.newaxis])),\n",
        "                        np.hstack((self.X_test, self.y_test[..., np.newaxis]))\n",
        "                    ), axis=0),\n",
        "                delimiter=',', fmt='%1.5f'\n",
        "            )\n",
        "            return 'Saved dataset to               : {}\\n'.format(save_path)\n",
        "        except:\n",
        "            import sys\n",
        "            e = sys.exc_info()[0]\n",
        "            print(\"WARNING: Could not save dataset: {}\".format(e))\n",
        "\n",
        "    def plot(self, logdir='./'):\n",
        "        \"\"\"Plot Dataset with underlying ground truth.\"\"\"\n",
        "        if self.X_train.shape[1] == 1:\n",
        "            from matplotlib import pyplot as plt\n",
        "            save_path = os.path.join(logdir,'plot_{}_n{:.2f}_s{}.png'.format(\n",
        "                    self.name, self.noise, self.seed))\n",
        "\n",
        "            # Draw ground truth expression\n",
        "            bounds = list(list(self.train_spec.values())[0].values())[0][:2]\n",
        "            x = np.linspace(bounds[0], bounds[1], endpoint=True, num=100)\n",
        "            y = self.numpy_expr(x[:, None])\n",
        "            plt.plot(x, y, color='red', linestyle='dashed')\n",
        "            # Draw the actual points\n",
        "            plt.scatter(self.X_train, self.y_train)\n",
        "            # Add a title\n",
        "            plt.title(\n",
        "                \"{} N:{} S:{}\".format(\n",
        "                    self.name, self.noise, self.seed),\n",
        "                fontsize=7)\n",
        "            try:\n",
        "                os.makedirs(logdir, exist_ok=True)\n",
        "                plt.savefig(save_path)\n",
        "                print('Saved plot to                  : {}'.format(save_path))\n",
        "            except:\n",
        "                import sys\n",
        "                e = sys.exc_info()[0]\n",
        "                print(\"WARNING: Could not plot dataset: {}\".format(e))\n",
        "            plt.close()\n",
        "        else:\n",
        "            print(\"WARNING: Plotting only supported for 2D datasets.\")\n",
        "\n",
        "\n",
        "@click.command()\n",
        "@click.argument(\"benchmark_source\", default=\"benchmarks.csv\")\n",
        "@click.option('--plot', is_flag=True)\n",
        "@click.option('--save_csv', is_flag=True)\n",
        "@click.option('--sweep', is_flag=True)\n",
        "def main(benchmark_source, plot, save_csv, sweep):\n",
        "    \"\"\"Plots all benchmark expressions.\"\"\"\n",
        "\n",
        "    regression_path = resource_filename(\"dso.task\", \"regression/\")\n",
        "    benchmark_path = os.path.join(regression_path, benchmark_source)\n",
        "    save_dir = os.path.join(regression_path, 'log')\n",
        "    df = pd.read_csv(benchmark_path, encoding=\"ISO-8859-1\")\n",
        "    names = df[\"name\"].to_list()\n",
        "    for name in names:\n",
        "\n",
        "        if not name.startswith(\"Nguyen\") and not name.startswith(\"Constant\") and not name.startswith(\"Custom\"):\n",
        "            continue\n",
        "\n",
        "        datasets = []\n",
        "\n",
        "        # Noiseless\n",
        "        d = BenchmarkDataset(\n",
        "            name=name,\n",
        "            benchmark_source=benchmark_source)\n",
        "        datasets.append(d)\n",
        "\n",
        "        # Generate all combinations of noise levels and dataset size multipliers\n",
        "        if sweep and name.startswith(\"Nguyen\"):\n",
        "            noises = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]\n",
        "            for noise in noises:\n",
        "                d = BenchmarkDataset(\n",
        "                    name=name,\n",
        "                    benchmark_source=benchmark_source,\n",
        "                    noise=noise,\n",
        "                    backup=save_csv,\n",
        "                    logdir=save_dir)\n",
        "                datasets.append(d)\n",
        "\n",
        "        # Plot and/or save datasets\n",
        "        for dataset in datasets:\n",
        "            if plot and dataset.X_train.shape[1] == 1:\n",
        "                dataset.plot(save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "QcINpW1qD-Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RegressionTask(HierarchicalTask):\n",
        "\n",
        "  task = RegressionTask(function_set=[\"add\", \"sub\", \"mul\"],\n",
        "                      dataset=\"/content/Nguyen-1.csv\",\n",
        "                      metric=\"neg_nrmse\")\n",
        "\n",
        "  def __init__(self, function_set, dataset, metric=\"inv_nrmse\",\n",
        "                 metric_params=(1.0,), extra_metric_test=None,\n",
        "                 extra_metric_test_params=(), reward_noise=0.0,\n",
        "                 reward_noise_type=\"r\", threshold=1e-12,\n",
        "                 normalize_variance=False, protected=False,\n",
        "                 decision_tree_threshold_set=None,\n",
        "                 poly_optimizer_params=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        function_set : list or None\n",
        "            List of allowable functions. If None, uses function_set according to\n",
        "            benchmark dataset.\n",
        "\n",
        "        dataset : dict, str, or tuple\n",
        "            If dict: .dataset.BenchmarkDataset kwargs.\n",
        "            If str ending with .csv: filename of dataset.\n",
        "            If other str: name of benchmark dataset.\n",
        "            If tuple: (X, y) data\n",
        "\n",
        "        metric : str\n",
        "            Name of reward function metric to use.\n",
        "\n",
        "        metric_params : list\n",
        "            List of metric-specific parameters.\n",
        "\n",
        "        extra_metric_test : str\n",
        "            Name of extra function metric to use for testing.\n",
        "\n",
        "        extra_metric_test_params : list\n",
        "            List of metric-specific parameters for extra test metric.\n",
        "\n",
        "        reward_noise : float\n",
        "            Noise level to use when computing reward.\n",
        "\n",
        "        reward_noise_type : \"y_hat\" or \"r\"\n",
        "            \"y_hat\" : N(0, reward_noise * y_rms_train) is added to y_hat values.\n",
        "            \"r\" : N(0, reward_noise) is added to r.\n",
        "\n",
        "        threshold : float\n",
        "            Threshold of NMSE on noiseless data used to determine success.\n",
        "\n",
        "        normalize_variance : bool\n",
        "            If True and reward_noise_type==\"r\", reward is multiplied by\n",
        "            1 / sqrt(1 + 12*reward_noise**2) (We assume r is U[0,1]).\n",
        "\n",
        "        protected : bool\n",
        "            Whether to use protected functions.\n",
        "\n",
        "        decision_tree_threshold_set : list\n",
        "            A set of constants {tj} for constructing nodes (xi < tj) in decision trees.\n",
        "\n",
        "        poly_optimizer_params : dict\n",
        "            Parameters for PolyOptimizer if poly token is in the library.\n",
        "        \"\"\"\n",
        "\n",
        "        super(HierarchicalTask).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        Configure (X, y) train/test data. There are four supported use cases:\n",
        "        (1) named benchmark, (2) benchmark config, (3) filename, and (4) direct\n",
        "        (X, y) data.\n",
        "        \"\"\"\n",
        "        self.X_test = self.y_test = self.y_test_noiseless = None\n",
        "\n",
        "        # Case 1: Named benchmark dataset (shortcut for Case 2)\n",
        "        if isinstance(dataset, str) and not dataset.endswith(\".csv\"):\n",
        "            dataset = {\"name\" : dataset}\n",
        "\n",
        "        # Case 2: Benchmark dataset config\n",
        "        if isinstance(dataset, dict):\n",
        "            benchmark = BenchmarkDataset(**dataset)\n",
        "            self.X_train = benchmark.X_train\n",
        "            self.y_train = benchmark.y_train\n",
        "            self.X_test = benchmark.X_test\n",
        "            self.y_test = benchmark.y_test\n",
        "            self.y_test_noiseless = benchmark.y_test_noiseless\n",
        "            self.name = benchmark.name\n",
        "\n",
        "            # For benchmarks, always use the benchmark function_set.\n",
        "            # Issue a warning if the user tried to supply a different one.\n",
        "            if function_set is not None and function_set != benchmark.function_set:\n",
        "                print(\"WARNING: function_set provided when running benchmark \"\n",
        "                      \"problem. The provided function_set will be ignored; the \"\n",
        "                      \"benchmark function_set will be used instead.\\nProvided \"\n",
        "                      \"function_set:\\n  {}\\nBenchmark function_set:\\n  {}.\"\n",
        "                      .format(function_set, benchmark.function_set))\n",
        "            function_set = benchmark.function_set\n",
        "\n",
        "        # Case 3: Dataset filename\n",
        "        elif isinstance(dataset, str) and dataset.endswith(\"csv\"):\n",
        "            df = pd.read_csv(dataset, header=None) # Assuming data file does not have header rows\n",
        "            self.X_train = df.values[:, :-1]\n",
        "            self.y_train = df.values[:, -1]\n",
        "            self.name = dataset.replace(\"/\", \"_\")[:-4]\n",
        "\n",
        "        # Case 4: sklearn-like (X, y) data\n",
        "        elif isinstance(dataset, tuple):\n",
        "            self.X_train = dataset[0]\n",
        "            self.y_train = dataset[1]\n",
        "            self.name = \"regression\"\n",
        "\n",
        "        # If not specified, set test data equal to the training data\n",
        "        if self.X_test is None:\n",
        "            self.X_test = self.X_train\n",
        "            self.y_test = self.y_train\n",
        "            self.y_test_noiseless = self.y_test\n",
        "\n",
        "        # Save time by only computing data variances once\n",
        "        self.var_y_test = np.var(self.y_test)\n",
        "        self.var_y_test_noiseless = np.var(self.y_test_noiseless)\n",
        "\n",
        "        \"\"\"\n",
        "        Configure train/test reward metrics.\n",
        "        \"\"\"\n",
        "        self.threshold = threshold\n",
        "        self.metric, self.invalid_reward, self.max_reward = make_regression_metric(metric, self.y_train, *metric_params)\n",
        "        self.extra_metric_test = extra_metric_test\n",
        "        if extra_metric_test is not None:\n",
        "            self.metric_test, _, _ = make_regression_metric(extra_metric_test, self.y_test, *extra_metric_test_params)\n",
        "        else:\n",
        "            self.metric_test = None\n",
        "\n",
        "        \"\"\"\n",
        "        Configure reward noise.\n",
        "        \"\"\"\n",
        "        self.reward_noise = reward_noise\n",
        "        self.reward_noise_type = reward_noise_type\n",
        "        self.normalize_variance = normalize_variance\n",
        "        assert reward_noise >= 0.0, \"Reward noise must be non-negative.\"\n",
        "        if reward_noise > 0:\n",
        "            assert reward_noise_type in [\"y_hat\", \"r\"], \"Reward noise type not recognized.\"\n",
        "            self.rng = np.random.RandomState(0)\n",
        "            y_rms_train = np.sqrt(np.mean(self.y_train ** 2))\n",
        "            if reward_noise_type == \"y_hat\":\n",
        "                self.scale = reward_noise * y_rms_train\n",
        "            elif reward_noise_type == \"r\":\n",
        "                self.scale = reward_noise\n",
        "        else:\n",
        "            self.rng = None\n",
        "            self.scale = None\n",
        "\n",
        "        # Set the Library\n",
        "        tokens = create_tokens(n_input_var=self.X_train.shape[1],\n",
        "                               function_set=function_set,\n",
        "                               protected=protected,\n",
        "                               decision_tree_threshold_set=decision_tree_threshold_set)\n",
        "        self.library = Library(tokens)\n",
        "\n",
        "        # Set stochastic flag\n",
        "        self.stochastic = reward_noise > 0.0\n",
        "\n",
        "        # Set neg_nrmse as the metric for const optimization\n",
        "        self.const_opt_metric, _, _ = make_regression_metric(\"neg_nrmse\", self.y_train)\n",
        "\n",
        "        # Function to optimize polynomial tokens\n",
        "        if \"poly\" in self.library.names:\n",
        "            if poly_optimizer_params is None:\n",
        "                poly_optimizer_params = {\n",
        "                        \"degree\": 3,\n",
        "                        \"coef_tol\": 1e-6,\n",
        "                        \"regressor\": \"dso_least_squares\",\n",
        "                        \"regressor_params\": {}\n",
        "                    }\n",
        "\n",
        "            self.poly_optimizer = PolyOptimizer(**poly_optimizer_params)\n",
        "\n",
        "  def reward_function(self, p, optimizing=False):\n",
        "        # fit a polynomial if p contains a 'poly' token\n",
        "        if p.poly_pos is not None:\n",
        "            assert len(p.const_pos) == 0, \"A program cannot contain 'poly' and 'const' tokens at the same time\"\n",
        "            poly_data_y = make_poly_data(p.traversal, self.X_train, self.y_train)\n",
        "            if poly_data_y is None:  # invalid function evaluations (nan or inf) appeared in make_poly_data\n",
        "                p.traversal[p.poly_pos] = Polynomial([(0,)*self.X_train.shape[1]], np.ones(1))\n",
        "            else:\n",
        "                p.traversal[p.poly_pos] = self.poly_optimizer.fit(self.X_train, poly_data_y)\n",
        "\n",
        "        # Compute estimated values\n",
        "        y_hat = p.execute(self.X_train)\n",
        "\n",
        "        # For invalid expressions, return invalid_reward\n",
        "        if p.invalid:\n",
        "            return -1.0 if optimizing else self.invalid_reward\n",
        "\n",
        "        # Observation noise\n",
        "        # For reward_noise_type == \"y_hat\", success must always be checked to\n",
        "        # ensure success cases aren't overlooked due to noise. If successful,\n",
        "        # return max_reward.\n",
        "        if self.reward_noise and self.reward_noise_type == \"y_hat\":\n",
        "            if p.evaluate.get(\"success\"):\n",
        "                return self.max_reward\n",
        "            y_hat += self.rng.normal(loc=0, scale=self.scale, size=y_hat.shape)\n",
        "\n",
        "        # Compute and return neg_nrmse for constant optimization\n",
        "        if optimizing:\n",
        "            return self.const_opt_metric(self.y_train, y_hat)\n",
        "\n",
        "        # Compute metric\n",
        "        r = self.metric(self.y_train, y_hat)\n",
        "\n",
        "        # Direct reward noise\n",
        "        # For reward_noise_type == \"r\", success can for ~max_reward metrics be\n",
        "        # confirmed before adding noise. If successful, must return np.inf to\n",
        "        # avoid overlooking success cases.\n",
        "        if self.reward_noise and self.reward_noise_type == \"r\":\n",
        "            if r >= self.max_reward - 1e-5 and p.evaluate.get(\"success\"):\n",
        "                return np.inf\n",
        "            r += self.rng.normal(loc=0, scale=self.scale)\n",
        "            if self.normalize_variance:\n",
        "                r /= np.sqrt(1 + 12 * self.scale ** 2)\n",
        "\n",
        "        return r\n",
        "\n",
        "  def evaluate(self, p):\n",
        "\n",
        "        # Compute predictions on test data\n",
        "        y_hat = p.execute(self.X_test)\n",
        "        if p.invalid:\n",
        "            nmse_test = None\n",
        "            nmse_test_noiseless = None\n",
        "            success = False\n",
        "\n",
        "        else:\n",
        "            # NMSE on test data (used to report final error)\n",
        "            nmse_test = np.mean((self.y_test - y_hat) ** 2) / self.var_y_test\n",
        "\n",
        "            # NMSE on noiseless test data (used to determine recovery)\n",
        "            nmse_test_noiseless = np.mean((self.y_test_noiseless - y_hat) ** 2) / self.var_y_test_noiseless\n",
        "\n",
        "            # Success is defined by NMSE on noiseless test data below a threshold\n",
        "            success = nmse_test_noiseless < self.threshold\n",
        "\n",
        "        info = {\n",
        "            \"nmse_test\" : nmse_test,\n",
        "            \"nmse_test_noiseless\" : nmse_test_noiseless,\n",
        "            \"success\" : success\n",
        "        }\n",
        "\n",
        "        if self.metric_test is not None:\n",
        "            if p.invalid:\n",
        "                m_test = None\n",
        "                m_test_noiseless = None\n",
        "            else:\n",
        "                m_test = self.metric_test(self.y_test, y_hat)\n",
        "                m_test_noiseless = self.metric_test(self.y_test_noiseless, y_hat)\n",
        "\n",
        "            info.update({\n",
        "                self.extra_metric_test : m_test,\n",
        "                self.extra_metric_test + '_noiseless' : m_test_noiseless\n",
        "            })\n",
        "\n",
        "        return info\n",
        "\n",
        "\n",
        "def make_regression_metric(name, y_train, *args):\n",
        "    \"\"\"\n",
        "    Factory function for a regression metric. This includes a closures for\n",
        "    metric parameters and the variance of the training data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    name : str\n",
        "        Name of metric. See all_metrics for supported metrics.\n",
        "\n",
        "    args : args\n",
        "        Metric-specific parameters\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    metric : function\n",
        "        Regression metric mapping true and estimated values to a scalar.\n",
        "\n",
        "    invalid_reward: float or None\n",
        "        Reward value to use for invalid expression. If None, the training\n",
        "        algorithm must handle it, e.g. by rejecting the sample.\n",
        "\n",
        "    max_reward: float\n",
        "        Maximum possible reward under this metric.\n",
        "    \"\"\"\n",
        "\n",
        "    var_y = np.var(y_train)\n",
        "\n",
        "    all_metrics = {\n",
        "\n",
        "        # Negative mean squared error\n",
        "        # Range: [-inf, 0]\n",
        "        # Value = -var(y) when y_hat == mean(y)\n",
        "        \"neg_mse\" :     (lambda y, y_hat : -np.mean((y - y_hat)**2),\n",
        "                        0),\n",
        "\n",
        "        # Negative root mean squared error\n",
        "        # Range: [-inf, 0]\n",
        "        # Value = -sqrt(var(y)) when y_hat == mean(y)\n",
        "        \"neg_rmse\" :     (lambda y, y_hat : -np.sqrt(np.mean((y - y_hat)**2)),\n",
        "                        0),\n",
        "\n",
        "        # Negative normalized mean squared error\n",
        "        # Range: [-inf, 0]\n",
        "        # Value = -1 when y_hat == mean(y)\n",
        "        \"neg_nmse\" :    (lambda y, y_hat : -np.mean((y - y_hat)**2)/var_y,\n",
        "                        0),\n",
        "\n",
        "        # Negative normalized root mean squared error\n",
        "        # Range: [-inf, 0]\n",
        "        # Value = -1 when y_hat == mean(y)\n",
        "        \"neg_nrmse\" :   (lambda y, y_hat : -np.sqrt(np.mean((y - y_hat)**2)/var_y),\n",
        "                        0),\n",
        "\n",
        "        # (Protected) negative log mean squared error\n",
        "        # Range: [-inf, 0]\n",
        "        # Value = -log(1 + var(y)) when y_hat == mean(y)\n",
        "        \"neglog_mse\" : (lambda y, y_hat : -np.log(1 + np.mean((y - y_hat)**2)),\n",
        "                        0),\n",
        "\n",
        "        # (Protected) inverse mean squared error\n",
        "        # Range: [0, 1]\n",
        "        # Value = 1/(1 + args[0]*var(y)) when y_hat == mean(y)\n",
        "        \"inv_mse\" : (lambda y, y_hat : 1/(1 + args[0]*np.mean((y - y_hat)**2)),\n",
        "                        1),\n",
        "\n",
        "        # (Protected) inverse normalized mean squared error\n",
        "        # Range: [0, 1]\n",
        "        # Value = 1/(1 + args[0]) when y_hat == mean(y)\n",
        "        \"inv_nmse\" :    (lambda y, y_hat : 1/(1 + args[0]*np.mean((y - y_hat)**2)/var_y),\n",
        "                        1),\n",
        "\n",
        "        # (Protected) inverse normalized root mean squared error\n",
        "        # Range: [0, 1]\n",
        "        # Value = 1/(1 + args[0]) when y_hat == mean(y)\n",
        "        \"inv_nrmse\" :    (lambda y, y_hat : 1/(1 + args[0]*np.sqrt(np.mean((y - y_hat)**2)/var_y)),\n",
        "                        1),\n",
        "\n",
        "        # Fraction of predicted points within p0*abs(y) + p1 band of the true value\n",
        "        # Range: [0, 1]\n",
        "        \"fraction\" :    (lambda y, y_hat : np.mean(abs(y - y_hat) < args[0]*abs(y) + args[1]),\n",
        "                        2),\n",
        "\n",
        "        # Pearson correlation coefficient\n",
        "        # Range: [0, 1]\n",
        "        \"pearson\" :     (lambda y, y_hat : scipy.stats.pearsonr(y, y_hat)[0],\n",
        "                        0),\n",
        "\n",
        "        # Spearman correlation coefficient\n",
        "        # Range: [0, 1]\n",
        "        \"spearman\" :    (lambda y, y_hat : scipy.stats.spearmanr(y, y_hat)[0],\n",
        "                        0)\n",
        "    }\n",
        "\n",
        "    assert name in all_metrics, \"Unrecognized reward function name.\"\n",
        "    assert len(args) == all_metrics[name][1], \"For {}, expected {} reward function parameters; received {}.\".format(name,all_metrics[name][1], len(args))\n",
        "    metric = all_metrics[name][0]\n",
        "\n",
        "    # For negative MSE-based rewards, invalid reward is the value of the reward function when y_hat = mean(y)\n",
        "    # For inverse MSE-based rewards, invalid reward is 0.0\n",
        "    # For non-MSE-based rewards, invalid reward is the minimum value of the reward function's range\n",
        "    all_invalid_rewards = {\n",
        "        \"neg_mse\" : -var_y,\n",
        "        \"neg_rmse\" : -np.sqrt(var_y),\n",
        "        \"neg_nmse\" : -1.0,\n",
        "        \"neg_nrmse\" : -1.0,\n",
        "        \"neglog_mse\" : -np.log(1 + var_y),\n",
        "        \"inv_mse\" : 0.0, #1/(1 + args[0]*var_y),\n",
        "        \"inv_nmse\" : 0.0, #1/(1 + args[0]),\n",
        "        \"inv_nrmse\" : 0.0, #1/(1 + args[0]),\n",
        "        \"fraction\" : 0.0,\n",
        "        \"pearson\" : 0.0,\n",
        "        \"spearman\" : 0.0\n",
        "    }\n",
        "    invalid_reward = all_invalid_rewards[name]\n",
        "\n",
        "    all_max_rewards = {\n",
        "        \"neg_mse\" : 0.0,\n",
        "        \"neg_rmse\" : 0.0,\n",
        "        \"neg_nmse\" : 0.0,\n",
        "        \"neg_nrmse\" : 0.0,\n",
        "        \"neglog_mse\" : 0.0,\n",
        "        \"inv_mse\" : 1.0,\n",
        "        \"inv_nmse\" : 1.0,\n",
        "        \"inv_nrmse\" : 1.0,\n",
        "        \"fraction\" : 1.0,\n",
        "        \"pearson\" : 1.0,\n",
        "        \"spearman\" : 1.0\n",
        "    }\n",
        "    max_reward = all_max_rewards[name]\n",
        "\n",
        "    return metric, invalid_reward, max_reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ZOpkVvBxCNxX",
        "outputId": "b518a705-8a4a-4485-a102-74c1e68defdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "For neg_nrmse, expected 0 reward function parameters; received 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-8b11adaf2296>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRegressionTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHierarchicalTask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   task = RegressionTask(function_set=[\"add\", \"sub\", \"mul\"], \n",
            "\u001b[0;32m<ipython-input-98-8b11adaf2296>\u001b[0m in \u001b[0;36mRegressionTask\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRegressionTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHierarchicalTask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   task = RegressionTask(function_set=[\"add\", \"sub\", \"mul\"], \n\u001b[0m\u001b[1;32m     10\u001b[0m                       \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/Nguyen-1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       metric=\"neg_nrmse\") \n",
            "\u001b[0;32m<ipython-input-85-87af0bbacc88>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, function_set, dataset, metric, metric_params, extra_metric_test, extra_metric_test_params, reward_noise, reward_noise_type, threshold, normalize_variance, protected, decision_tree_threshold_set, poly_optimizer_params)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvalid_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_regression_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmetric_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_metric_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_metric_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextra_metric_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-87af0bbacc88>\u001b[0m in \u001b[0;36mmake_regression_metric\u001b[0;34m(name, y_train, *args)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unrecognized reward function name.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"For {}, expected {} reward function parameters; received {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: For neg_nrmse, expected 0 reward function parameters; received 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from abc import ABC, abstractmethod\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RNN, LSTM, Dropout, Dense\n",
        "from tensorflow.compat.v1.nn.rnn_cell import BasicRNNCell\n",
        "\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import os\n",
        "# This will give you the current working directory of the notebook\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "config_file = '/content/config_common.json'\n",
        "\n",
        "def get_base_config(task, language_prior):\n",
        "    config_path = os.path.join(current_directory, config_file)\n",
        "    with open(config_path, 'r', encoding='utf-8') as file:\n",
        "        base_config = json.load(file)\n",
        "    return base_config\n",
        "# Define your Task and LanguageModel classes here\n",
        "\n",
        "# Define your DeepSymbolicOptimizer class here\n",
        "\n",
        "# Define or import additional necessary classes or methods\n",
        "class Task(ABC):\n",
        "    \"\"\"\n",
        "    Object specifying a symbolic search task.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    library : Library\n",
        "        Library of Tokens.\n",
        "\n",
        "    stochastic : bool\n",
        "        Whether the reward function of the task is stochastic.\n",
        "\n",
        "    task_type : str\n",
        "        Task type: regression, control, or binding.\n",
        "\n",
        "    name : str\n",
        "        Unique name for instance of this task.\n",
        "    \"\"\"\n",
        "\n",
        "    task_type = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def reward_function(self, program, optimizing=False):\n",
        "        \"\"\"\n",
        "        The reward function for this task.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        program : dso.program.Program\n",
        "\n",
        "            The Program to compute reward of.\n",
        "\n",
        "        optimizing : bool\n",
        "\n",
        "            Whether the reward is computed for PlaceholderConstant optimization.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        reward : float\n",
        "\n",
        "            Fitness/reward of the program.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, program):\n",
        "        \"\"\"\n",
        "        The evaluation metric for this task.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        program : dso.program.Program\n",
        "\n",
        "            The Program to evaluate.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        info : dict\n",
        "\n",
        "            Dictionary of evaluation metrics. Special key \"success\" is used to\n",
        "            trigger early stopping.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "        \"\"\"\n",
        "        Produce the next observation and prior from the current observation and\n",
        "        list of actions so far. Observations must be 1-D np.float32 vectors.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        actions : np.ndarray (dtype=np.int32)\n",
        "            Actions selected so far, shape (batch_size, current_length)\n",
        "\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Previous observation, shape (batch_size, OBS_DIM).\n",
        "\n",
        "        already_finished : np.ndarray (dtype=bool)\n",
        "            Whether the object has *already* been completed.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        next_obs : np.ndarray (dtype=np.float32)\n",
        "            The next observation, shape (batch_size, OBS_DIM).\n",
        "\n",
        "        prior : np.ndarray (dtype=np.float32)\n",
        "            Prior for selecting the next token, shape (batch_size,\n",
        "            self.library.L).\n",
        "\n",
        "        finished : np.ndarray (dtype=bool)\n",
        "            Whether the object has *ever* been completed.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset_task(self):\n",
        "        \"\"\"\n",
        "        Create the starting observation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        obs : np.ndarray (dtype=np.float32)\n",
        "            Starting observation, shape (batch_size, OBS_DIM).\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class HierarchicalTask(Task):\n",
        "    \"\"\"\n",
        "    A Task in which the search space is a binary tree. Observations include\n",
        "    the previous action, the parent, the sibling, and/or the number of dangling\n",
        "    (unselected) nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    OBS_DIM = 4 # action, parent, sibling, dangling\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Task).__init__()\n",
        "\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "\n",
        "        dangling = obs[:, 3] # Shape of obs: (?, 4)\n",
        "        action = actions[:, -1] # Current action\n",
        "        lib = self.library\n",
        "\n",
        "        # Compute parents and siblings\n",
        "        parent, sibling = parents_siblings(actions,\n",
        "                                           arities=lib.arities,\n",
        "                                           parent_adjust=lib.parent_adjust,\n",
        "                                           empty_parent=lib.EMPTY_PARENT,\n",
        "                                           empty_sibling=lib.EMPTY_SIBLING)\n",
        "\n",
        "        # Compute dangling\n",
        "        dangling += lib.arities[action] - 1\n",
        "\n",
        "        # Compute finished\n",
        "        just_finished = (dangling == 0) # Trees that completed _this_ time step\n",
        "        # [batch_size]\n",
        "        finished = np.logical_or(just_finished,\n",
        "                                 already_finished)\n",
        "\n",
        "        # Compute priors\n",
        "        prior = self.prior(actions, parent, sibling, dangling, finished) # (?, n_choices)\n",
        "\n",
        "        # Combine observation dimensions\n",
        "        next_obs = np.stack([action, parent, sibling, dangling], axis=1) # (?, 4)\n",
        "        next_obs = next_obs.astype(np.float32)\n",
        "\n",
        "        return next_obs, prior, finished\n",
        "\n",
        "    def reset_task(self, prior):\n",
        "        \"\"\"\n",
        "        Returns the initial observation: empty action, parent, and sibling, and\n",
        "        dangling is 1.\n",
        "        \"\"\"\n",
        "\n",
        "        self.prior = prior\n",
        "\n",
        "        # Order of observations: action, parent, sibling, dangling\n",
        "        initial_obs = np.array([self.library.EMPTY_ACTION,\n",
        "                                self.library.EMPTY_PARENT,\n",
        "                                self.library.EMPTY_SIBLING,\n",
        "                                1],\n",
        "                               dtype=np.float32)\n",
        "        return initial_obs\n",
        "\n",
        "\n",
        "class SequentialTask(Task):\n",
        "    \"\"\"\n",
        "    A Task in which the search space is a (possibly variable-length) sequence.\n",
        "    The observation is simply the previous action.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_task(task_type, **config_task):\n",
        "    \"\"\"\n",
        "    Factory function for Task object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    task_type : str\n",
        "        Type of task:\n",
        "        \"regression\" : Symbolic regression task.\n",
        "        \"control\" : Episodic reinforcement learning task.\n",
        "        \"binding\": AbAg binding affinity optimization task.\n",
        "\n",
        "    config_task : kwargs\n",
        "        Task-specific arguments. See specifications of task_dict.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    task : Task\n",
        "        Task object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Lazy import of task factory functions\n",
        "    if task_type == 'binding':\n",
        "        from dso.task.binding.binding import BindingTask\n",
        "        task_class = BindingTask\n",
        "    elif task_type == \"regression\":\n",
        "        from dso.task.regression.regression import RegressionTask\n",
        "        task_class = RegressionTask\n",
        "    elif task_type == \"control\":\n",
        "        from dso.task.control.control import ControlTask\n",
        "        task_class = ControlTask\n",
        "    else:\n",
        "        # Custom task import\n",
        "        task_class = import_custom_source(task_type)\n",
        "        assert issubclass(task_class, Task), \\\n",
        "            \"Custom task {} must subclass dso.task.Task.\".format(task_class)\n",
        "\n",
        "    task = task_class(**config_task)\n",
        "    return task\n",
        "\n",
        "\n",
        "def set_task(config_task):\n",
        "    \"\"\"Helper function to make set the Program class Task and execute function\n",
        "    from task config.\"\"\"\n",
        "\n",
        "    # Use of protected functions is the same for all tasks, so it's handled separately\n",
        "    protected = config_task[\"protected\"] if \"protected\" in config_task else False\n",
        "\n",
        "    Program.set_execute(protected)\n",
        "    task = make_task(**config_task)\n",
        "    Program.set_task(task)\n",
        "\n",
        "class LanguageModel(object):\n",
        "    def __init__(self, vocabulary_size, embedding_size, num_layers, num_hidden, mode='train'):\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.inputs = tf.placeholder(tf.int32, [None, None], name=\"inputs\")  # Batch size x sequence length\n",
        "        self.keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
        "\n",
        "        with tf.variable_scope(\"embedding\"):\n",
        "            self.embedding = tf.get_variable(\"embedding\", [vocabulary_size, embedding_size])\n",
        "            self.inputs_embedded = tf.nn.embedding_lookup(self.embedding, self.inputs)\n",
        "\n",
        "        with tf.variable_scope(\"rnn\"):\n",
        "            cells = [tf.nn.rnn_cell.BasicRNNCell(num_hidden) for _ in range(num_layers)]\n",
        "            cells = [tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=self.keep_prob) for cell in cells]\n",
        "            self.cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
        "            self.initial_state = self.cell.zero_state(tf.shape(self.inputs)[0], tf.float32)\n",
        "            self.outputs, self.final_state = tf.nn.dynamic_rnn(self.cell, self.inputs_embedded,\n",
        "                                                               initial_state=self.initial_state)\n",
        "\n",
        "        with tf.variable_scope(\"output\"):\n",
        "            self.logits = tf.layers.dense(self.outputs, vocabulary_size)\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.targets = tf.placeholder(tf.int32, [None, None], name=\"targets\")\n",
        "            self.loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.targets, logits=self.logits)\n",
        "            self.cost = tf.reduce_mean(self.loss)\n",
        "\n",
        "class DeepSymbolicOptimizer():\n",
        "    \"\"\"\n",
        "    Deep symbolic optimization model. Includes model hyperparameters and\n",
        "    training configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    config : dict or str\n",
        "        Config dictionary or path to JSON.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    config : dict\n",
        "        Configuration parameters for training.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    train\n",
        "        Builds and trains the model according to config.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.set_config(config)\n",
        "        self.sess = None\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        # Clear the cache and reset the compute graph\n",
        "        Program.clear_cache()\n",
        "        tf.reset_default_graph()\n",
        "\n",
        "        # Generate objects needed for training and set seeds\n",
        "        self.pool = self.make_pool_and_set_task()\n",
        "        self.set_seeds() # Must be called _after_ resetting graph and _after_ setting task\n",
        "\n",
        "        # Limit TF to single thread to prevent \"resource not available\" errors in parallelized runs\n",
        "        session_config = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "        self.sess = tf.Session(config=session_config)\n",
        "\n",
        "        # Setup logdirs and output files\n",
        "        self.output_file = self.make_output_file()\n",
        "        self.save_config()\n",
        "\n",
        "        # Prepare training parameters\n",
        "        self.prior = self.make_prior()\n",
        "        self.state_manager = self.make_state_manager()\n",
        "        self.policy = self.make_policy()\n",
        "        self.policy_optimizer = self.make_policy_optimizer()\n",
        "        self.gp_controller = self.make_gp_controller()\n",
        "        self.logger = self.make_logger()\n",
        "        self.trainer = self.make_trainer()\n",
        "        self.checkpoint = self.make_checkpoint()\n",
        "\n",
        "    def train_one_step(self, override=None):\n",
        "        \"\"\"\n",
        "        Train one iteration.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup the model\n",
        "        if self.sess is None:\n",
        "            self.setup()\n",
        "\n",
        "        # Run one step\n",
        "        assert not self.trainer.done, \"Training has already completed!\"\n",
        "        self.trainer.run_one_step(override)\n",
        "\n",
        "        # Maybe save next checkpoint\n",
        "        self.checkpoint.update()\n",
        "\n",
        "        # If complete, return summary\n",
        "        if self.trainer.done:\n",
        "            return self.finish()\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train the model until completion.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup the model\n",
        "        self.setup()\n",
        "\n",
        "        # Train the model until done\n",
        "        while not self.trainer.done:\n",
        "            result = self.train_one_step()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def finish(self):\n",
        "        \"\"\"\n",
        "        After training completes, finish up and return summary dict.\n",
        "        \"\"\"\n",
        "\n",
        "        # Return statistics of best Program\n",
        "        p = self.trainer.p_r_best\n",
        "        result = {\"seed\" : self.config_experiment[\"seed\"]} # Seed listed first\n",
        "        result.update({\"r\" : p.r})\n",
        "        result.update(p.evaluate)\n",
        "        result.update({\n",
        "            \"expression\" : repr(p.sympy_expr),\n",
        "            \"traversal\" : repr(p),\n",
        "            \"program\" : p\n",
        "        })\n",
        "\n",
        "        # Save all results available only after all iterations are finished. Also return metrics to be added to the summary file\n",
        "        results_add = self.logger.save_results(self.pool, self.trainer.nevals)\n",
        "        result.update(results_add)\n",
        "\n",
        "        # Close the pool\n",
        "        if self.pool is not None:\n",
        "            self.pool.close()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def set_config(self, config):\n",
        "        config = load_config(config)\n",
        "\n",
        "        self.config = defaultdict(dict, config)\n",
        "        self.config_task = self.config[\"task\"]\n",
        "        self.config_prior = self.config[\"prior\"]\n",
        "        self.config_logger = self.config[\"logging\"]\n",
        "        self.config_training = self.config[\"training\"]\n",
        "        self.config_state_manager = self.config[\"state_manager\"]\n",
        "        self.config_policy = self.config[\"policy\"]\n",
        "        self.config_policy_optimizer = self.config[\"policy_optimizer\"]\n",
        "        self.config_gp_meld = self.config[\"gp_meld\"]\n",
        "        self.config_experiment = self.config[\"experiment\"]\n",
        "        self.config_checkpoint = self.config[\"checkpoint\"]\n",
        "\n",
        "    def save_config(self):\n",
        "        # Save the config file\n",
        "        if self.output_file is not None:\n",
        "            path = os.path.join(self.config_experiment[\"save_path\"],\n",
        "                                \"config.json\")\n",
        "            # With run.py, config.json may already exist. To avoid race\n",
        "            # conditions, only record the starting seed. Use a backup seed\n",
        "            # in case this worker's seed differs.\n",
        "            backup_seed = self.config_experiment[\"seed\"]\n",
        "            if not os.path.exists(path):\n",
        "                if \"starting_seed\" in self.config_experiment:\n",
        "                    self.config_experiment[\"seed\"] = self.config_experiment[\"starting_seed\"]\n",
        "                    del self.config_experiment[\"starting_seed\"]\n",
        "                with open(path, 'w') as f:\n",
        "                    json.dump(self.config, f, indent=3)\n",
        "            self.config_experiment[\"seed\"] = backup_seed\n",
        "\n",
        "    def set_seeds(self):\n",
        "        \"\"\"\n",
        "        Set the tensorflow, numpy, and random module seeds based on the seed\n",
        "        specified in config. If there is no seed or it is None, a time-based\n",
        "        seed is used instead and is written to config.\n",
        "        \"\"\"\n",
        "\n",
        "        seed = self.config_experiment.get(\"seed\")\n",
        "\n",
        "        # Default uses current time in milliseconds, modulo 1e9\n",
        "        if seed is None:\n",
        "            seed = round(time() * 1000) % int(1e9)\n",
        "            self.config_experiment[\"seed\"] = seed\n",
        "\n",
        "        # Shift the seed based on task name\n",
        "        # This ensures a specified seed doesn't have similarities across different task names\n",
        "        task_name = Program.task.name\n",
        "        shifted_seed = seed + zlib.adler32(task_name.encode(\"utf-8\"))\n",
        "\n",
        "        # Set the seeds using the shifted seed\n",
        "        tf.set_random_seed(shifted_seed)\n",
        "        np.random.seed(shifted_seed)\n",
        "        random.seed(shifted_seed)\n",
        "\n",
        "    def make_prior(self):\n",
        "        prior = make_prior(Program.library, self.config_prior)\n",
        "        return prior\n",
        "\n",
        "    def make_state_manager(self):\n",
        "        state_manager = make_state_manager(self.config_state_manager)\n",
        "        return state_manager\n",
        "\n",
        "    def make_trainer(self):\n",
        "        trainer = Trainer(self.sess,\n",
        "                          self.policy,\n",
        "                          self.policy_optimizer,\n",
        "                          self.gp_controller,\n",
        "                          self.logger,\n",
        "                          self.pool,\n",
        "                          **self.config_training)\n",
        "        return trainer\n",
        "\n",
        "    def make_logger(self):\n",
        "        logger = StatsLogger(self.sess,\n",
        "                             self.output_file,\n",
        "                             **self.config_logger)\n",
        "        return logger\n",
        "\n",
        "    def make_checkpoint(self):\n",
        "        checkpoint = Checkpoint(self,\n",
        "                                **self.config_checkpoint)\n",
        "        return checkpoint\n",
        "\n",
        "    def make_policy_optimizer(self):\n",
        "        policy_optimizer = make_policy_optimizer(self.sess,\n",
        "                                                 self.policy,\n",
        "                                                 **self.config_policy_optimizer)\n",
        "        return policy_optimizer\n",
        "\n",
        "    def make_policy(self):\n",
        "        policy = make_policy(self.sess,\n",
        "                             self.prior,\n",
        "                             self.state_manager,\n",
        "                             **self.config_policy)\n",
        "        return policy\n",
        "\n",
        "    def make_gp_controller(self):\n",
        "        if self.config_gp_meld.pop(\"run_gp_meld\", False):\n",
        "            from dso.gp.gp_controller import GPController\n",
        "            gp_controller = GPController(self.prior,\n",
        "                                         self.config_prior,\n",
        "                                         **self.config_gp_meld)\n",
        "        else:\n",
        "            gp_controller = None\n",
        "        return gp_controller\n",
        "\n",
        "    def make_pool_and_set_task(self):\n",
        "        # Create the pool and set the Task for each worker\n",
        "\n",
        "        # Set complexity and const optimizer here so pool can access them\n",
        "        # Set the complexity function\n",
        "        complexity = self.config_training[\"complexity\"]\n",
        "        Program.set_complexity(complexity)\n",
        "\n",
        "        # Set the constant optimizer\n",
        "        const_optimizer = self.config_training[\"const_optimizer\"]\n",
        "        const_params = self.config_training[\"const_params\"]\n",
        "        const_params = const_params if const_params is not None else {}\n",
        "        Program.set_const_optimizer(const_optimizer, **const_params)\n",
        "\n",
        "        pool = None\n",
        "        n_cores_batch = self.config_training.get(\"n_cores_batch\")\n",
        "        if n_cores_batch is not None:\n",
        "            if n_cores_batch == -1:\n",
        "                n_cores_batch = cpu_count()\n",
        "            if n_cores_batch > 1:\n",
        "                pool = Pool(n_cores_batch,\n",
        "                            initializer=set_task,\n",
        "                            initargs=(self.config_task,))\n",
        "\n",
        "        # Set the Task for the parent process\n",
        "        set_task(self.config_task)\n",
        "\n",
        "        return pool\n",
        "\n",
        "    def make_output_file(self):\n",
        "        \"\"\"Generates an output filename\"\"\"\n",
        "\n",
        "        # If logdir is not provided (e.g. for pytest), results are not saved\n",
        "        if self.config_experiment.get(\"logdir\") is None:\n",
        "            self.save_path = None\n",
        "            print(\"WARNING: logdir not provided. Results will not be saved to file.\")\n",
        "            return None\n",
        "\n",
        "        # When using run.py, timestamp is already generated\n",
        "        timestamp = self.config_experiment.get(\"timestamp\")\n",
        "        if timestamp is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
        "            self.config_experiment[\"timestamp\"] = timestamp\n",
        "\n",
        "        # Generate save path\n",
        "        task_name = Program.task.name\n",
        "        if self.config_experiment[\"exp_name\"] is None:\n",
        "            save_path = os.path.join(\n",
        "                self.config_experiment[\"logdir\"],\n",
        "                '_'.join([task_name, timestamp]))\n",
        "        else:\n",
        "            save_path = os.path.join(\n",
        "                self.config_experiment[\"logdir\"],\n",
        "                self.config_experiment[\"exp_name\"])\n",
        "\n",
        "        self.config_experiment[\"task_name\"] = task_name\n",
        "        self.config_experiment[\"save_path\"] = save_path\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        seed = self.config_experiment[\"seed\"]\n",
        "        output_file = os.path.join(save_path,\n",
        "                                   \"dso_{}_{}.csv\".format(task_name, seed))\n",
        "\n",
        "        self.save_path = save_path\n",
        "\n",
        "        return output_file\n",
        "\n",
        "    def save(self, save_path=None):\n",
        "        self.checkpoint.save(save_path)\n",
        "\n",
        "    def load(self, load_path):\n",
        "        self.checkpoint.load(load_path)\n",
        "\n",
        "\n",
        "class RegressionTask(Task):\n",
        "    def __init__(self, model, features, labels):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def reward_function(self, program):\n",
        "        # Define how the reward is calculated using the model's predictions\n",
        "        predictions = self.model.predict(self.features)\n",
        "        return -np.mean(np.square(predictions - self.labels))\n",
        "\n",
        "    def evaluate(self, program):\n",
        "        # Define evaluation based on the task's specific metrics\n",
        "        predictions = self.model.predict(self.features)\n",
        "        return {'mse': np.mean(np.square(predictions - self.labels))}\n",
        "\n",
        "    def get_next_obs(self, actions, obs, already_finished):\n",
        "        # Logic for getting next observations if applicable\n",
        "        return obs  # Placeholder, implement as needed\n",
        "\n",
        "    def reset_task(self):\n",
        "        # Reset the task environment to an initial state\n",
        "        return np.zeros_like(self.features)  # Placeholder, implement as needed\n",
        "\n",
        "def main():\n",
        "    tf.compat.v1.reset_default_graph()  # Reset the graph to clear old variables\n",
        "    # The rest of your main function code...\n",
        "\n",
        "    # Load dataset\n",
        "    train_features = pd.read_csv(\"/content/train_feature.csv\").values\n",
        "    train_labels = pd.read_csv(\"/content/train_label.csv\").values\n",
        "\n",
        "    # Configuration for RNN model\n",
        "    rnn_config = {\n",
        "        \"vocabulary_size\": 10000,\n",
        "        \"embedding_size\": 300,\n",
        "        \"num_layers\": 2,\n",
        "        \"num_hidden\": 128,\n",
        "        \"mode\": 'train'\n",
        "    }\n",
        "\n",
        "    # Instantiate RNN model\n",
        "    rnn_model = LanguageModel(**rnn_config)\n",
        "\n",
        "    # Create Task instance\n",
        "    task = RegressionTask(rnn_model, train_features, train_labels)\n",
        "\n",
        "    # Configuration for optimizer\n",
        "    optimizer_config = {\n",
        "        # Include any specific configurations for the optimizer\n",
        "    }\n",
        "\n",
        "    # Instantiate and setup optimizer\n",
        "    optimizer = DeepSymbolicOptimizer(config=optimizer_config)\n",
        "    optimizer.setup()\n",
        "\n",
        "    # Train model\n",
        "    result = optimizer.train()\n",
        "\n",
        "    # Print final training outcome\n",
        "    print(\"Training completed with result:\", result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "1Lq7hWkt3U3-",
        "outputId": "e08aa133-286e-494f-86fc-e838015dce52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:428: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1705: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "<ipython-input-80-9374135f8bfe>:287: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.logits = tf.layers.dense(self.outputs, vocabulary_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Task type not specified. Falling back to default task type 'regression' to load config.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dso'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-78fa5be1e5a2>\u001b[0m in \u001b[0;36mset_execute\u001b[0;34m(cls, protected)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mdso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcython_execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0mexecute_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcython_execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dso'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-9374135f8bfe>\u001b[0m in \u001b[0;36m<cell line: 653>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-9374135f8bfe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;31m# Instantiate and setup optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepSymbolicOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-9374135f8bfe>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# Generate objects needed for training and set seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_pool_and_set_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Must be called _after_ resetting graph and _after_ setting task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-9374135f8bfe>\u001b[0m in \u001b[0;36mmake_pool_and_set_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# Set the Task for the parent process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mset_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-9374135f8bfe>\u001b[0m in \u001b[0;36mset_task\u001b[0;34m(config_task)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mprotected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"protected\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"protected\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_task\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-78fa5be1e5a2>\u001b[0m in \u001b[0;36mset_execute\u001b[0;34m(cls, protected)\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhave_cython\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mdso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython_execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mexecute_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mProgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhave_cython\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dso'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up your task configuration\n",
        "task_config = config.default_task_config()\n",
        "task_config[\"task\"] = \"regression\"\n",
        "task_config[\"dataset_train\"] = (train_features.values, train_labels.values)\n",
        "task_config[\"dataset_validate\"] = (validation_features.values, validation_labels.values)\n",
        "\n",
        "# Create a Task instance\n",
        "task = Task(task_config)\n",
        "\n",
        "# Set up your controller configuration\n",
        "controller_config = config.default_controller_config()\n",
        "controller_config[\"learning_rate\"] = 0.01  # Example modification\n",
        "\n",
        "# Create the RnnController instance\n",
        "controller = RnnController(task, controller_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b4N6TMQyvgcE",
        "outputId": "a028d634-e789-4aca-afea-1f453fbf35e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'config' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-76000721613f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set up your task configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtask_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_task_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtask_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtask_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_train\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtask_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_validate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
          ]
        }
      ]
    }
  ]
}